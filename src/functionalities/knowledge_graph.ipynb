{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from rdflib.namespace import RDF, RDFS, XSD\n",
    "from rdflib import Graph, Literal, URIRef\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Publication:\n",
    "    def __init__(self, title, doi, cites, num_pages, publication_date, language, pages, published_in, main_subject, instance_of, author, topic):\n",
    "        self._title = title\n",
    "        self._doi = doi\n",
    "        self._cites = cites\n",
    "        self._num_pages = num_pages\n",
    "        self._publication_date = publication_date\n",
    "        self._language = language\n",
    "        self._pages = pages\n",
    "        self._published_in = published_in\n",
    "        self._main_subject = main_subject\n",
    "        self._instance_of = instance_of\n",
    "        self._author = author\n",
    "        self._topic = topic\n",
    "\n",
    "    # Getters\n",
    "    def get_title(self):\n",
    "        return self._title\n",
    "\n",
    "    def get_doi(self):\n",
    "        return self._doi\n",
    "\n",
    "    def get_cites(self):\n",
    "        return self._cites\n",
    "\n",
    "    def get_num_pages(self):\n",
    "        return self._num_pages\n",
    "\n",
    "    def get_publication_date(self):\n",
    "        return self._publication_date\n",
    "\n",
    "    def get_language(self):\n",
    "        return self._language\n",
    "\n",
    "    def get_pages(self):\n",
    "        return self._pages\n",
    "\n",
    "    def get_published_in(self):\n",
    "        return self._published_in\n",
    "\n",
    "    def get_main_subject(self):\n",
    "        return self._main_subject\n",
    "\n",
    "    def get_instance_of(self):\n",
    "        return self._instance_of\n",
    "\n",
    "    def get_author(self):\n",
    "        return self._author\n",
    "    \n",
    "    def get_topic(self):\n",
    "        return self._topic\n",
    "\n",
    "    # Setters\n",
    "    def set_title(self, title):\n",
    "        self._title = title\n",
    "\n",
    "    def set_doi(self, doi):\n",
    "        self._doi = doi\n",
    "\n",
    "    def set_cites(self, cites):\n",
    "        self._cites = cites\n",
    "\n",
    "    def set_num_pages(self, num_pages):\n",
    "        self._num_pages = num_pages\n",
    "\n",
    "    def set_publication_date(self, publication_date):\n",
    "        self._publication_date = publication_date\n",
    "\n",
    "    def set_language(self, language):\n",
    "        self._language = language\n",
    "\n",
    "    def set_pages(self, pages):\n",
    "        self._pages = pages\n",
    "\n",
    "    def set_published_in(self, published_in):\n",
    "        self._published_in = published_in\n",
    "\n",
    "    def set_main_subject(self, main_subject):\n",
    "        self._main_subject = main_subject\n",
    "\n",
    "    def set_instance_of(self, instance_of):\n",
    "        self._instance_of = instance_of\n",
    "\n",
    "    def set_author(self, author):\n",
    "        self._author = author\n",
    "\n",
    "    def set_topic(self, topic):\n",
    "        self._topic = topic\n",
    "\n",
    "    #Other fucntions\n",
    "    def display_info(self):\n",
    "        print(\"Title:\", self._title)\n",
    "        print(\"DOI:\", self._doi)\n",
    "        print(\"Cites:\", self._cites)\n",
    "        print(\"Number of Pages:\", self._num_pages)\n",
    "        print(\"Publication Date:\", self._publication_date)\n",
    "        print(\"Language:\", self._language)\n",
    "        print(\"Pages:\", self._pages)\n",
    "        print(\"Published In:\", self._published_in)\n",
    "        print(\"Main Subject:\", self._main_subject)\n",
    "        print(\"Instance Of:\", self._instance_of)\n",
    "        print(\"Author:\", self._author)\n",
    "        print(\"Topic:\", self._topic)\n",
    "        print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A_multilevel_review_of_artificial_intelligence_in_organizations:_Implications_for_organizational_behavior_research_and_practice\n",
      "DOI: 10.1002/JOB.2735\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2023-08-02T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 159-182\n",
      "Published In: http://www.wikidata.org/entity/Q1709866\n",
      "Main Subject: N/A\n",
      "Instance Of: N/A\n",
      "Author: ['Simon Lloyd D. Restubog', 'Sang Eun Woo']\n",
      "Topic: ai learning dl deep ha gene technology human application article\n",
      "\n",
      "\n",
      "Title: A_systematic_review_of_the_applications_of_artificial_intelligence_and_machine_learning_in_autoimmune_diseases\n",
      "DOI: 10.1038/S41746-020-0229-3\n",
      "Cites: http://www.wikidata.org/entity/Q47173123\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2020-03-09T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 30\n",
      "Published In: http://www.wikidata.org/entity/Q73908508\n",
      "Main Subject: http://www.wikidata.org/entity/Q2539\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: data machine model learning disease ml study method may paper\n",
      "\n",
      "\n",
      "Title: Exploring_the_impact_of_artificial_intelligence_on_teaching_and_learning_in_higher_education\n",
      "DOI: 10.1186/S41039-017-0062-8\n",
      "Cites: http://www.wikidata.org/entity/Q36268624\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2017-11-23T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 22\n",
      "Published In: http://www.wikidata.org/entity/Q15754063\n",
      "Main Subject: http://www.wikidata.org/entity/Q11660\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: wikipedia claim system citation fraud learning one credit card increase\n",
      "\n",
      "\n",
      "Title: Deep_Learning:_Methods_and_Applications\n",
      "DOI: 10.1561/2000000039\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2014-01-01T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 197-387\n",
      "Published In: http://www.wikidata.org/entity/Q15763119\n",
      "Main Subject: http://www.wikidata.org/entity/Q197536\n",
      "Instance Of: N/A\n",
      "Author: ['Lukáš Vařeka', 'Pavel Mautner']\n",
      "Topic: ai learning dl deep ha gene technology human application article\n",
      "\n",
      "\n",
      "Title: Deep_learning\n",
      "DOI: 10.1038/NATURE14539\n",
      "Cites: http://www.wikidata.org/entity/Q55871746\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2015-05-28T00:00:00Z\n",
      "Language: http://www.wikidata.org/entity/Q1860\n",
      "Pages: 436–444\n",
      "Published In: http://www.wikidata.org/entity/Q180445\n",
      "Main Subject: http://www.wikidata.org/entity/Q197536\n",
      "Instance Of: N/A\n",
      "Author: ['Philippe Meyer', 'Vincent Noblet', 'Alex Lallement', 'C. Niederst', 'D. Jarnet', 'N. Dehaynin', 'C. Mazzara']\n",
      "Topic: \n",
      "\n",
      "\n",
      "Title: Surrogate_techniques_for_testing_fraud_detection_algorithms_in_credit_card_operations\n",
      "DOI: 10.1109/CCST.2014.6986987\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2014-10-01T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: N/A\n",
      "Published In: N/A\n",
      "Main Subject: N/A\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: model fraud wit data learning ha technique information card wikipedia\n",
      "\n",
      "\n",
      "Title: use_of_data_mining_of_to_create_of_a_fraud_prevention_and_detection_system_in_credit_card\n",
      "DOI: 10.53730/IJHS.V6NS5.10371\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2022-07-05T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 6308-6315\n",
      "Published In: http://www.wikidata.org/entity/Q96712878\n",
      "Main Subject: http://www.wikidata.org/entity/Q172491\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: model fraud wit data learning ha technique information card wikipedia\n",
      "\n",
      "\n",
      "Title: WIT:_Wikipedia-based_Image_Text_Dataset_for_Multimodal_Multilingual_Machine_Learning\n",
      "DOI: 10.1145/3404835.3463257\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2021-03-03T00:00:00Z\n",
      "Language: http://www.wikidata.org/entity/Q1860\n",
      "Pages: N/A\n",
      "Published In: N/A\n",
      "Main Subject: http://www.wikidata.org/entity/Q2539\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: model fraud wit data learning ha technique information card wikipedia\n",
      "\n",
      "\n",
      "Title: Analysis_and_prediction_for_credit_card_fraud_detection_dataset_using_data_mining_approaches\n",
      "DOI: 10.53730/IJHS.V6NS5.9534\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2022-06-23T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 4155-4173\n",
      "Published In: http://www.wikidata.org/entity/Q96712878\n",
      "Main Subject: http://www.wikidata.org/entity/Q83873\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: wikipedia claim system citation fraud learning one credit card increase\n",
      "\n",
      "\n",
      "Title: Credit_Card_Fraud_Detection_Using_Random_Forest_Classification\n",
      "DOI: 10.22214/IJRASET.2023.53990\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2023-06-30T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 2383-2390\n",
      "Published In: http://www.wikidata.org/entity/Q96710230\n",
      "Main Subject: http://www.wikidata.org/entity/Q83873\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: wikipedia claim system citation fraud learning one credit card increase\n",
      "\n",
      "\n",
      "Title: A_deep_learning-based_quality_assessment_model_of_collaboratively_edited_documents:_A_case_study_of_Wikipedia\n",
      "DOI: 10.1177/0165551519877646\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2019-10-01T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 176-191\n",
      "Published In: http://www.wikidata.org/entity/Q152047\n",
      "Main Subject: N/A\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: model fraud wit data learning ha technique information card wikipedia\n",
      "\n",
      "\n",
      "Title: Deep_learning_in_neural_networks:_an_overview\n",
      "DOI: 10.1016/J.NEUNET.2014.09.003\n",
      "Cites: http://www.wikidata.org/entity/Q29398287\n",
      "Number of Pages: 33\n",
      "Publication Date: 2014-10-13T00:00:00Z\n",
      "Language: http://www.wikidata.org/entity/Q1860\n",
      "Pages: 85-117\n",
      "Published In: http://www.wikidata.org/entity/Q15708873\n",
      "Main Subject: http://www.wikidata.org/entity/Q197536\n",
      "Instance Of: N/A\n",
      "Author: ['Thomas B. Miller']\n",
      "Topic: learning transaction model machine deep fraud network technology card algorithm\n",
      "\n",
      "\n",
      "Title: Linking_ImageNet_WordNet_Synsets_with_Wikidata\n",
      "DOI: 10.1145/3184558.3191645\n",
      "Cites: http://www.wikidata.org/entity/Q36655252\n",
      "Number of Pages: 6\n",
      "Publication Date: 2018-04-01T00:00:00Z\n",
      "Language: http://www.wikidata.org/entity/Q1860\n",
      "Pages: 1809-1814\n",
      "Published In: http://www.wikidata.org/entity/Q51885042\n",
      "Main Subject: http://www.wikidata.org/entity/Q24901201\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: ai learning data healthcare deep knowledge linkage graph wikidata wordnet\n",
      "\n",
      "\n",
      "Title: Credit_Card_Fraud_Detection_using_Logistic_Regression_Compared_with_t-SNE_to_Improve_Accuracy\n",
      "DOI: 10.55248/GENGPI.2022.3.8.37\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2022-08-17T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 1000-1004\n",
      "Published In: N/A\n",
      "Main Subject: http://www.wikidata.org/entity/Q83873\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: model fraud wit data learning ha technique information card wikipedia\n",
      "\n",
      "\n",
      "Title: An_Efficient_Deep_Learning_Classification_Model_for_Predicting_Credit_Card_Fraud_on_Skewed_Data\n",
      "DOI: 10.26735/TLYG7256\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2022-06-30T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 57-71\n",
      "Published In: http://www.wikidata.org/entity/Q96715947\n",
      "Main Subject: http://www.wikidata.org/entity/Q83873\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: learning transaction model machine deep fraud network technology card algorithm\n",
      "\n",
      "\n",
      "Title: Artificial_intelligence_machine_learning_computer-aided_diagnosis_and_radiomics:_advances_in_imaging_towards_to_precision_medicine\n",
      "DOI: 10.1590/0100-3984.2019.0049\n",
      "Cites: http://www.wikidata.org/entity/Q37615306\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2019-11-01T00:00:00Z\n",
      "Language: http://www.wikidata.org/entity/Q1860\n",
      "Pages: 387-396\n",
      "Published In: http://www.wikidata.org/entity/Q26842548\n",
      "Main Subject: http://www.wikidata.org/entity/Q2539\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: wikipedia claim system citation fraud learning one credit card increase\n",
      "\n",
      "\n",
      "Title: A_widespread_Survey_on_Machine_Learning_Techniques_and_User_Substantiation_Methods_for_Credit_Card_Fraud_Detection\n",
      "DOI: 10.1504/IJBIDM.2023.10047750\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2023-01-01T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 1\n",
      "Published In: http://www.wikidata.org/entity/Q15752768\n",
      "Main Subject: http://www.wikidata.org/entity/Q83873\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: card credit transaction fraud part customer authorized algorithm increased time\n",
      "\n",
      "\n",
      "Title: The_role_of_artificial_intelligence_in_achieving_the_Sustainable_Development_Goals\n",
      "DOI: 10.1038/S41467-019-14108-Y\n",
      "Cites: http://www.wikidata.org/entity/Q105875591\n",
      "Number of Pages: 10\n",
      "Publication Date: 2020-01-13T00:00:00Z\n",
      "Language: http://www.wikidata.org/entity/Q1860\n",
      "Pages: 233\n",
      "Published In: http://www.wikidata.org/entity/Q573880\n",
      "Main Subject: http://www.wikidata.org/entity/Q131201\n",
      "Instance Of: N/A\n",
      "Author: ['C. Nagadeepa', 'Reenu Mohan', 'Antonio Huamán-Osorio', 'Willian Josue Fernandez Celestino']\n",
      "Topic: ai development sustainable target study impact goal sdgs result enable\n",
      "\n",
      "\n",
      "Title: Credit_Card_Fraud_Detection_using_Python_&amp;_Machine_Learning_Algorithms\n",
      "DOI: 10.22214/IJRASET.2023.52242\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2023-05-31T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 3120-3128\n",
      "Published In: http://www.wikidata.org/entity/Q96710230\n",
      "Main Subject: http://www.wikidata.org/entity/Q83873\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: card credit transaction fraud part customer authorized algorithm increased time\n",
      "\n",
      "\n",
      "Title: Artificial_intelligence_and_deep_learning_in_ophthalmology\n",
      "DOI: 10.1136/BJOPHTHALMOL-2018-313173\n",
      "Cites: http://www.wikidata.org/entity/Q53872479\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2019-02-01T00:00:00Z\n",
      "Language: http://www.wikidata.org/entity/Q1860\n",
      "Pages: 167-175\n",
      "Published In: http://www.wikidata.org/entity/Q13443571\n",
      "Main Subject: http://www.wikidata.org/entity/Q2539\n",
      "Instance Of: N/A\n",
      "Author: ['Sang J. Kim', 'Michael F. Chiang']\n",
      "Topic: ai learning dl deep ha gene technology human application article\n",
      "\n",
      "\n",
      "Title: Artificial_intelligence_in_healthcare:_past_present_and_future.\n",
      "DOI: 10.1136/SVN-2017-000101\n",
      "Cites: http://www.wikidata.org/entity/Q37199212\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2017-06-21T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 230-243\n",
      "Published In: http://www.wikidata.org/entity/Q27727612\n",
      "Main Subject: http://www.wikidata.org/entity/Q11660\n",
      "Instance Of: N/A\n",
      "Author: ['Qiang Dong', 'Haipeng Shen', 'Yongjun Wang']\n",
      "Topic: ai learning data healthcare deep knowledge linkage graph wikidata wordnet\n",
      "\n",
      "\n",
      "Title: Credit_Card_Fraud_Detection_Using_Machine_Learning_and_Blockchain\n",
      "DOI: 10.22214/IJRASET.2023.52214\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2023-05-31T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 2745-2751\n",
      "Published In: http://www.wikidata.org/entity/Q96710230\n",
      "Main Subject: http://www.wikidata.org/entity/Q83873\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: learning transaction model machine deep fraud network technology card algorithm\n",
      "\n",
      "\n",
      "Title: Credit_Card_Fraud_Detection_Using_Machine_Learning_&amp;_Python\n",
      "DOI: 10.56726/IRJMETS42136\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2023-06-16T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: N/A\n",
      "Published In: N/A\n",
      "Main Subject: http://www.wikidata.org/entity/Q83873\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: card credit transaction fraud part customer authorized algorithm increased time\n",
      "\n",
      "\n",
      "Title: Applications_of_machine_learning_and_artificial_intelligence_for_Covid-19_(SARS-CoV-2)_pandemic:_A_review\n",
      "DOI: 10.1016/J.CHAOS.2020.110059\n",
      "Cites: http://www.wikidata.org/entity/Q91943997\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2020-06-25T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 110059\n",
      "Published In: http://www.wikidata.org/entity/Q15766768\n",
      "Main Subject: http://www.wikidata.org/entity/Q81068910\n",
      "Instance Of: N/A\n",
      "Author: ['Shashank G. S. Yashas', 'Yashas Vinay']\n",
      "Topic: ai learning dl deep ha gene technology human application article\n",
      "\n",
      "\n",
      "Title: Improving_Wikipedia_verifiability_with_AI\n",
      "DOI: 10.1038/S42256-023-00726-1\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2023-10-19T00:00:00Z\n",
      "Language: http://www.wikidata.org/entity/Q1860\n",
      "Pages: 1142-1148\n",
      "Published In: http://www.wikidata.org/entity/Q44062926\n",
      "Main Subject: http://www.wikidata.org/entity/Q11660\n",
      "Instance Of: N/A\n",
      "Author: ['Sebastian Riedel']\n",
      "Topic: wikipedia claim system citation fraud learning one credit card increase\n",
      "\n",
      "\n",
      "Title: Deep_Learning:_Methods_and_Applications\n",
      "DOI: 10.1561/2000000039\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2014-01-01T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 197-387\n",
      "Published In: http://www.wikidata.org/entity/Q15763119\n",
      "Main Subject: http://www.wikidata.org/entity/Q197536\n",
      "Instance Of: N/A\n",
      "Author: ['Lukáš Vařeka', 'Pavel Mautner']\n",
      "Topic: ai learning dl deep ha gene technology human application article\n",
      "\n",
      "\n",
      "Title: The_Gene_Wiki:_community_intelligence_applied_to_human_gene_annotation\n",
      "DOI: 10.1093/NAR/GKP760\n",
      "Cites: http://www.wikidata.org/entity/Q29619285\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2010-01-01T00:00:00Z\n",
      "Language: http://www.wikidata.org/entity/Q1860\n",
      "Pages: D633-9\n",
      "Published In: http://www.wikidata.org/entity/Q135122\n",
      "Main Subject: http://www.wikidata.org/entity/Q177005\n",
      "Instance Of: N/A\n",
      "Author: ['Adrian Tsang', 'René Witte']\n",
      "Topic: ai learning dl deep ha gene technology human application article\n",
      "\n",
      "\n",
      "Title: Rows_from_Many_Sources:_Enriching_row_completions_from_Wikidata_with_a_pre-trained_Language_Model\n",
      "DOI: 10.1145/3487553.3524923\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2022-04-25T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: N/A\n",
      "Published In: http://www.wikidata.org/entity/Q112275684\n",
      "Main Subject: http://www.wikidata.org/entity/Q2013\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: task row text generation knowledge additional table base using filling\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_papers = []\n",
    "author_by_doi = {}\n",
    "topic_by_doi = {}\n",
    "topic_and_prob_by_title = {}\n",
    "topic_and_prob_by_doi = {}\n",
    "possible_topics = []\n",
    "\n",
    "wikidata_res = '../../papers/wikidata/results.csv'\n",
    "openalex_res = '../../papers/openalex/results.csv'\n",
    "prob_res = '../../papers/probabilities/'\n",
    "doi_res = '../../papers/doi/'\n",
    "topic_res = '../../papers/topics/'\n",
    "\n",
    "# read authors\n",
    "with open(openalex_res, 'r') as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        line_split = line.split(',')\n",
    "        doi = line_split[0]\n",
    "        author = line_split[1]\n",
    "        author_institution = line_split[2]\n",
    "\n",
    "        if doi in author_by_doi and author not in author_by_doi[doi]:\n",
    "            author_by_doi[doi].append(author)\n",
    "        else:\n",
    "            author_by_doi[doi] = [author]\n",
    "\n",
    "# read topics\n",
    "with open(topic_res + 'topics.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        if line == '\\n':\n",
    "            continue\n",
    "        line = line.replace('\\n', '')\n",
    "        topic = line.split(\":\")[1].strip()\n",
    "        possible_topics.append(topic)\n",
    "\n",
    "# read topics and probabilities\n",
    "for filename in os.listdir(prob_res):\n",
    "    with open(prob_res + filename, 'r') as f:\n",
    "        line = f.read()\n",
    "\n",
    "        topic_start = line.find(\"Topic: [\") + len(\"Topic: [\")\n",
    "        topic_end = line.find(\"]\", topic_start)\n",
    "        prob_start = line.find(\"Probability: \") + len(\"Probability: \")\n",
    "        prob_end = line.find(\"\\n\", prob_start)\n",
    "\n",
    "        topic = line[topic_start:topic_end]\n",
    "        probabilidad = float(line[prob_start:prob_end])\n",
    "        topic_and_prob_by_title[filename] = (topic, probabilidad)\n",
    "    \n",
    "for filename in os.listdir(doi_res):\n",
    "    with open(doi_res + filename, 'r') as f:\n",
    "        if filename in topic_and_prob_by_title:\n",
    "            doi = f.read()\n",
    "            topic = topic_and_prob_by_title[filename][0]\n",
    "            probabilidad = topic_and_prob_by_title[filename][1]\n",
    "            topic_and_prob_by_doi[doi] = (topic, probabilidad)\n",
    "\n",
    "# read csv\n",
    "with open(wikidata_res, 'r') as f:\n",
    "    # skip header\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        if line.startswith('\"'):\n",
    "            title = line.split('\"')[1]\n",
    "            doi = line.split('\"')[2]\n",
    "            doi = doi.split(',')[1]\n",
    "            # change content between double quotes\n",
    "            line = line.replace(title, \"\")\n",
    "        else:    \n",
    "            line_split = line.split(',')\n",
    "            # save all atributes in paper object\n",
    "            title = line_split[0]\n",
    "            doi = line_split[1]\n",
    "            \n",
    "        line_split = line.split(',')\n",
    "\n",
    "        if doi in author_by_doi:\n",
    "            authors = author_by_doi[doi]\n",
    "        else:\n",
    "            authors = []\n",
    "\n",
    "        if doi in topic_and_prob_by_doi:\n",
    "            topic, probabilidad = topic_and_prob_by_doi[doi]\n",
    "        else:\n",
    "            topic = \"\"\n",
    "        \n",
    "        line_split[9] = line_split[9].replace('\\n', '')\n",
    "        title = title.replace(\" \", \"_\")\n",
    "        title = title.replace(\",\", \"\")\n",
    "        cleaned_topics = topic.replace(\"'\", \"\").replace(\",\", \"\")\n",
    "\n",
    "        paper = Publication(title, doi, line_split[2], line_split[3], line_split[4], line_split[5], line_split[6], line_split[7], line_split[8], line_split[9], authors, cleaned_topics)\n",
    "        list_papers.append(paper)\n",
    "        paper.display_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "http://example.org/learning, transaction, model, machine, deep, fraud, network, technology, card, algorithm does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/wikipedia, claim, system, citation, fraud, learning, one, credit, card, increase does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/model, fraud, wit, data, learning, ha, technique, information, card, wikipedia does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/ai, learning, data, healthcare, deep, knowledge, linkage, graph, wikidata, wordnet does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/task, row, text, generation, knowledge, additional, table, base, using, filling does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "http://example.org/ai, learning, dl, deep, ha, gene, technology, human, application, article does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/learning, deep, application, processing, area, information, criterion, multimodal, use, research does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/ai, development, sustainable, target, study, impact, goal, sdgs, result, enable does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/card, credit, transaction, fraud, part, customer, authorized, algorithm, increased, time does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/data, machine, model, learning, disease, ml, study, method, may, paper does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N4c960a91a9dc4922b827f62ec5370e99 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "\n",
    "g = Graph()\n",
    "\n",
    "for paper in list_papers:\n",
    "    paper_uri = URIRef(\"http://example.org/\" + paper.get_doi())\n",
    "    g.add((paper_uri, RDF.type, URIRef(\"http://schema.org/paper\")))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/title\"), Literal(paper.get_title())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/doi\"), Literal(paper.get_doi())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/cites\"), Literal(paper.get_cites())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/numPages\"), Literal(paper.get_num_pages())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/publicationDate\"), Literal(paper.get_publication_date())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/inLanguage\"), Literal(paper.get_language())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/pages\"), Literal(paper.get_pages())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/publishedIn\"), Literal(paper.get_published_in())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/mainSubject\"), Literal(paper.get_main_subject())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/author\"), Literal(paper.get_author())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/topic\"), Literal(paper.get_topic())))\n",
    "\n",
    "for topic in possible_topics:\n",
    "    topic_uri = URIRef(\"http://example.org/\" + topic)\n",
    "    g.add((topic_uri, RDF.type, URIRef(\"http://schema.org/topic\")))\n",
    "    g.add((topic_uri, URIRef(\"http://schema.org/name\"), Literal(topic)))\n",
    "\n",
    "g.serialize(destination='papers.xml', format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Namespace\n",
    "onto = Namespace(\"http://example.org/\")\n",
    "g.bind(\"onto\", onto)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        query = input(\"Enter a SPARQL query or 'exit' to finish: \")\n",
    "        if query == 'exit':\n",
    "            break\n",
    "        else:\n",
    "            for row in g.query(query):\n",
    "                print(row)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying the graph for a specific paper\n",
      "\n",
      "\n",
      "(rdflib.term.Literal('An_Efficient_Deep_Learning_Classification_Model_for_Predicting_Credit_Card_Fraud_on_Skewed_Data'), rdflib.term.Literal('learning transaction model machine deep fraud network technology card algorithm'), rdflib.term.Literal('[]'))\n"
     ]
    }
   ],
   "source": [
    "print(\"Querying the graph for a specific paper\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for result in g.query(\n",
    "    '''PREFIX schema: <http://schema.org/>\n",
    "\n",
    "    SELECT ?title ?topic ?author\n",
    "    WHERE {\n",
    "    ?paper a schema:paper ;\n",
    "        schema:doi \"10.26735/TLYG7256\" ;\n",
    "        schema:title ?title ;\n",
    "        schema:topic ?topic ;\n",
    "        schema:author ?author .\n",
    "    }'''\n",
    "):\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All possible topics:\n",
      "\n",
      "\n",
      "(rdflib.term.Literal('learning, transaction, model, machine, deep, fraud, network, technology, card, algorithm'),)\n",
      "(rdflib.term.Literal('wikipedia, claim, system, citation, fraud, learning, one, credit, card, increase'),)\n",
      "(rdflib.term.Literal('model, fraud, wit, data, learning, ha, technique, information, card, wikipedia'),)\n",
      "(rdflib.term.Literal('ai, learning, data, healthcare, deep, knowledge, linkage, graph, wikidata, wordnet'),)\n",
      "(rdflib.term.Literal('task, row, text, generation, knowledge, additional, table, base, using, filling'),)\n",
      "(rdflib.term.Literal('ai, learning, dl, deep, ha, gene, technology, human, application, article'),)\n",
      "(rdflib.term.Literal('learning, deep, application, processing, area, information, criterion, multimodal, use, research'),)\n",
      "(rdflib.term.Literal('ai, development, sustainable, target, study, impact, goal, sdgs, result, enable'),)\n",
      "(rdflib.term.Literal('card, credit, transaction, fraud, part, customer, authorized, algorithm, increased, time'),)\n",
      "(rdflib.term.Literal('data, machine, model, learning, disease, ml, study, method, may, paper'),)\n"
     ]
    }
   ],
   "source": [
    "print(\"All possible topics:\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for result in g.query(\n",
    "    '''PREFIX schema: <http://schema.org/>\n",
    "    SELECT ?topic\n",
    "    WHERE {\n",
    "        ?paper a schema:topic ;\n",
    "               schema:name ?topic .\n",
    "    }\n",
    "    '''\n",
    "):\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All papers:\n",
      "\n",
      "\n",
      "(rdflib.term.Literal('A_multilevel_review_of_artificial_intelligence_in_organizations:_Implications_for_organizational_behavior_research_and_practice'),)\n",
      "(rdflib.term.Literal('A_systematic_review_of_the_applications_of_artificial_intelligence_and_machine_learning_in_autoimmune_diseases'),)\n",
      "(rdflib.term.Literal('Exploring_the_impact_of_artificial_intelligence_on_teaching_and_learning_in_higher_education'),)\n",
      "(rdflib.term.Literal('Deep_Learning:_Methods_and_Applications'),)\n",
      "(rdflib.term.Literal('Deep_learning'),)\n",
      "(rdflib.term.Literal('Surrogate_techniques_for_testing_fraud_detection_algorithms_in_credit_card_operations'),)\n",
      "(rdflib.term.Literal('use_of_data_mining_of_to_create_of_a_fraud_prevention_and_detection_system_in_credit_card'),)\n",
      "(rdflib.term.Literal('WIT:_Wikipedia-based_Image_Text_Dataset_for_Multimodal_Multilingual_Machine_Learning'),)\n",
      "(rdflib.term.Literal('Analysis_and_prediction_for_credit_card_fraud_detection_dataset_using_data_mining_approaches'),)\n",
      "(rdflib.term.Literal('Credit_Card_Fraud_Detection_Using_Random_Forest_Classification'),)\n",
      "(rdflib.term.Literal('A_deep_learning-based_quality_assessment_model_of_collaboratively_edited_documents:_A_case_study_of_Wikipedia'),)\n",
      "(rdflib.term.Literal('Deep_learning_in_neural_networks:_an_overview'),)\n",
      "(rdflib.term.Literal('Linking_ImageNet_WordNet_Synsets_with_Wikidata'),)\n",
      "(rdflib.term.Literal('Credit_Card_Fraud_Detection_using_Logistic_Regression_Compared_with_t-SNE_to_Improve_Accuracy'),)\n",
      "(rdflib.term.Literal('An_Efficient_Deep_Learning_Classification_Model_for_Predicting_Credit_Card_Fraud_on_Skewed_Data'),)\n",
      "(rdflib.term.Literal('Artificial_intelligence_machine_learning_computer-aided_diagnosis_and_radiomics:_advances_in_imaging_towards_to_precision_medicine'),)\n",
      "(rdflib.term.Literal('A_widespread_Survey_on_Machine_Learning_Techniques_and_User_Substantiation_Methods_for_Credit_Card_Fraud_Detection'),)\n",
      "(rdflib.term.Literal('The_role_of_artificial_intelligence_in_achieving_the_Sustainable_Development_Goals'),)\n",
      "(rdflib.term.Literal('Credit_Card_Fraud_Detection_using_Python_&amp;_Machine_Learning_Algorithms'),)\n",
      "(rdflib.term.Literal('Artificial_intelligence_and_deep_learning_in_ophthalmology'),)\n",
      "(rdflib.term.Literal('Artificial_intelligence_in_healthcare:_past_present_and_future.'),)\n",
      "(rdflib.term.Literal('Credit_Card_Fraud_Detection_Using_Machine_Learning_and_Blockchain'),)\n",
      "(rdflib.term.Literal('Credit_Card_Fraud_Detection_Using_Machine_Learning_&amp;_Python'),)\n",
      "(rdflib.term.Literal('Applications_of_machine_learning_and_artificial_intelligence_for_Covid-19_(SARS-CoV-2)_pandemic:_A_review'),)\n",
      "(rdflib.term.Literal('Improving_Wikipedia_verifiability_with_AI'),)\n",
      "(rdflib.term.Literal('The_Gene_Wiki:_community_intelligence_applied_to_human_gene_annotation'),)\n",
      "(rdflib.term.Literal('Rows_from_Many_Sources:_Enriching_row_completions_from_Wikidata_with_a_pre-trained_Language_Model'),)\n"
     ]
    }
   ],
   "source": [
    "print(\"All papers:\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for result in g.query(\n",
    "    '''\n",
    "    PREFIX schema: <http://schema.org/>\n",
    "    SELECT ?title\n",
    "    WHERE {\n",
    "        ?paper a schema:paper ;\n",
    "               schema:title ?title .\n",
    "    }\n",
    "    '''\n",
    "):\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "os_group",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
