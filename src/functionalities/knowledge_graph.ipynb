{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from rdflib.namespace import RDF, RDFS, XSD\n",
    "from rdflib import Graph, Literal, URIRef\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Publication:\n",
    "    def __init__(self, title, doi, cites, num_pages, publication_date, language, pages, published_in, main_subject, instance_of, author, topic, proba_topic):\n",
    "        self._title = title\n",
    "        self._doi = doi\n",
    "        self._cites = cites\n",
    "        self._num_pages = num_pages\n",
    "        self._publication_date = publication_date\n",
    "        self._language = language\n",
    "        self._pages = pages\n",
    "        self._published_in = published_in\n",
    "        self._main_subject = main_subject\n",
    "        self._instance_of = instance_of\n",
    "        self._author = author\n",
    "        self._topic = topic\n",
    "        self._proba_topic = proba_topic\n",
    "\n",
    "    # Getters\n",
    "    def get_title(self):\n",
    "        return self._title\n",
    "\n",
    "    def get_doi(self):\n",
    "        return self._doi\n",
    "\n",
    "    def get_cites(self):\n",
    "        return self._cites\n",
    "\n",
    "    def get_num_pages(self):\n",
    "        return self._num_pages\n",
    "\n",
    "    def get_publication_date(self):\n",
    "        return self._publication_date\n",
    "\n",
    "    def get_language(self):\n",
    "        return self._language\n",
    "\n",
    "    def get_pages(self):\n",
    "        return self._pages\n",
    "\n",
    "    def get_published_in(self):\n",
    "        return self._published_in\n",
    "\n",
    "    def get_main_subject(self):\n",
    "        return self._main_subject\n",
    "\n",
    "    def get_instance_of(self):\n",
    "        return self._instance_of\n",
    "\n",
    "    def get_author(self):\n",
    "        return self._author\n",
    "    \n",
    "    def get_topic(self):\n",
    "        return self._topic\n",
    "    \n",
    "    def get_proba_topic(self):\n",
    "        return self._proba_topic\n",
    "\n",
    "    # Setters\n",
    "    def set_title(self, title):\n",
    "        self._title = title\n",
    "\n",
    "    def set_doi(self, doi):\n",
    "        self._doi = doi\n",
    "\n",
    "    def set_cites(self, cites):\n",
    "        self._cites = cites\n",
    "\n",
    "    def set_num_pages(self, num_pages):\n",
    "        self._num_pages = num_pages\n",
    "\n",
    "    def set_publication_date(self, publication_date):\n",
    "        self._publication_date = publication_date\n",
    "\n",
    "    def set_language(self, language):\n",
    "        self._language = language\n",
    "\n",
    "    def set_pages(self, pages):\n",
    "        self._pages = pages\n",
    "\n",
    "    def set_published_in(self, published_in):\n",
    "        self._published_in = published_in\n",
    "\n",
    "    def set_main_subject(self, main_subject):\n",
    "        self._main_subject = main_subject\n",
    "\n",
    "    def set_instance_of(self, instance_of):\n",
    "        self._instance_of = instance_of\n",
    "\n",
    "    def set_author(self, author):\n",
    "        self._author = author\n",
    "\n",
    "    def set_topic(self, topic):\n",
    "        self._topic = topic\n",
    "    \n",
    "    def set_proba_topic(self, proba_topic):\n",
    "        self._proba_topic = proba_topic\n",
    "\n",
    "    #Other fucntions\n",
    "    def display_info(self):\n",
    "        print(\"Title:\", self._title)\n",
    "        print(\"DOI:\", self._doi)\n",
    "        print(\"Cites:\", self._cites)\n",
    "        print(\"Number of Pages:\", self._num_pages)\n",
    "        print(\"Publication Date:\", self._publication_date)\n",
    "        print(\"Language:\", self._language)\n",
    "        print(\"Pages:\", self._pages)\n",
    "        print(\"Published In:\", self._published_in)\n",
    "        print(\"Main Subject:\", self._main_subject)\n",
    "        print(\"Instance Of:\", self._instance_of)\n",
    "        print(\"Author:\", self._author)\n",
    "        print(\"Topic:\", self._topic)\n",
    "        print(\"Probability of Topic:\", self._proba_topic)\n",
    "        print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A multilevel review of artificial intelligence in organizations: Implications for organizational behavior research and practice\n",
      "DOI: 10.1002/JOB.2735\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2023-08-02T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 159-182\n",
      "Published In: http://www.wikidata.org/entity/Q1709866\n",
      "Main Subject: N/A\n",
      "Instance Of: N/A\n",
      "Author: ['Simon Lloyd D. Restubog', 'Sang Eun Woo']\n",
      "Topic: 'ai', 'learning', 'dl', 'deep', 'ha', 'gene', 'technology', 'human', 'application', 'article'\n",
      "Probability of Topic: 0.9928\n",
      "\n",
      "\n",
      "Title: A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases\n",
      "DOI: 10.1038/S41746-020-0229-3\n",
      "Cites: http://www.wikidata.org/entity/Q47173123\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2020-03-09T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 30\n",
      "Published In: http://www.wikidata.org/entity/Q73908508\n",
      "Main Subject: http://www.wikidata.org/entity/Q2539\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: 'data', 'machine', 'model', 'learning', 'disease', 'ml', 'study', 'method', 'may', 'paper'\n",
      "Probability of Topic: 0.9944\n",
      "\n",
      "\n",
      "Title: Exploring the impact of artificial intelligence on teaching and learning in higher education\n",
      "DOI: 10.1186/S41039-017-0062-8\n",
      "Cites: http://www.wikidata.org/entity/Q36268624\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2017-11-23T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 22\n",
      "Published In: http://www.wikidata.org/entity/Q15754063\n",
      "Main Subject: http://www.wikidata.org/entity/Q11660\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: 'wikipedia', 'claim', 'system', 'citation', 'fraud', 'learning', 'one', 'credit', 'card', 'increase'\n",
      "Probability of Topic: 0.9857\n",
      "\n",
      "\n",
      "Title: Deep Learning: Methods and Applications\n",
      "DOI: 10.1561/2000000039\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2014-01-01T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 197-387\n",
      "Published In: http://www.wikidata.org/entity/Q15763119\n",
      "Main Subject: http://www.wikidata.org/entity/Q197536\n",
      "Instance Of: N/A\n",
      "Author: ['Lukáš Vařeka', 'Pavel Mautner']\n",
      "Topic: 'ai', 'learning', 'dl', 'deep', 'ha', 'gene', 'technology', 'human', 'application', 'article'\n",
      "Probability of Topic: 0.9929\n",
      "\n",
      "\n",
      "Title: Deep learning\n",
      "DOI: 10.1038/NATURE14539\n",
      "Cites: http://www.wikidata.org/entity/Q55871746\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2015-05-28T00:00:00Z\n",
      "Language: http://www.wikidata.org/entity/Q1860\n",
      "Pages: 436–444\n",
      "Published In: http://www.wikidata.org/entity/Q180445\n",
      "Main Subject: http://www.wikidata.org/entity/Q197536\n",
      "Instance Of: N/A\n",
      "Author: ['Philippe Meyer', 'Vincent Noblet', 'Alex Lallement', 'C. Niederst', 'D. Jarnet', 'N. Dehaynin', 'C. Mazzara']\n",
      "Topic: \n",
      "Probability of Topic: 0\n",
      "\n",
      "\n",
      "Title: Surrogate techniques for testing fraud detection algorithms in credit card operations\n",
      "DOI: 10.1109/CCST.2014.6986987\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2014-10-01T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: N/A\n",
      "Published In: N/A\n",
      "Main Subject: N/A\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: 'model', 'fraud', 'wit', 'data', 'learning', 'ha', 'technique', 'information', 'card', 'wikipedia'\n",
      "Probability of Topic: 0.9897\n",
      "\n",
      "\n",
      "Title: use of data mining of to create of a fraud prevention and detection system in credit card\n",
      "DOI: 10.53730/IJHS.V6NS5.10371\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2022-07-05T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 6308-6315\n",
      "Published In: http://www.wikidata.org/entity/Q96712878\n",
      "Main Subject: http://www.wikidata.org/entity/Q172491\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: 'model', 'fraud', 'wit', 'data', 'learning', 'ha', 'technique', 'information', 'card', 'wikipedia'\n",
      "Probability of Topic: 0.9868\n",
      "\n",
      "\n",
      "Title: WIT: Wikipedia-based Image Text Dataset for Multimodal Multilingual Machine Learning\n",
      "DOI: 10.1145/3404835.3463257\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2021-03-03T00:00:00Z\n",
      "Language: http://www.wikidata.org/entity/Q1860\n",
      "Pages: N/A\n",
      "Published In: N/A\n",
      "Main Subject: http://www.wikidata.org/entity/Q2539\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: 'model', 'fraud', 'wit', 'data', 'learning', 'ha', 'technique', 'information', 'card', 'wikipedia'\n",
      "Probability of Topic: 0.9933\n",
      "\n",
      "\n",
      "Title: Analysis and prediction for credit card fraud detection dataset using data mining approaches\n",
      "DOI: 10.53730/IJHS.V6NS5.9534\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2022-06-23T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 4155-4173\n",
      "Published In: http://www.wikidata.org/entity/Q96712878\n",
      "Main Subject: http://www.wikidata.org/entity/Q83873\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: 'wikipedia', 'claim', 'system', 'citation', 'fraud', 'learning', 'one', 'credit', 'card', 'increase'\n",
      "Probability of Topic: 0.9875\n",
      "\n",
      "\n",
      "Title: Credit Card Fraud Detection Using Random Forest Classification\n",
      "DOI: 10.22214/IJRASET.2023.53990\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2023-06-30T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 2383-2390\n",
      "Published In: http://www.wikidata.org/entity/Q96710230\n",
      "Main Subject: http://www.wikidata.org/entity/Q83873\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: 'wikipedia', 'claim', 'system', 'citation', 'fraud', 'learning', 'one', 'credit', 'card', 'increase'\n",
      "Probability of Topic: 0.4985\n",
      "\n",
      "\n",
      "Title: A deep learning-based quality assessment model of collaboratively edited documents: A case study of Wikipedia\n",
      "DOI: 10.1177/0165551519877646\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2019-10-01T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 176-191\n",
      "Published In: http://www.wikidata.org/entity/Q152047\n",
      "Main Subject: N/A\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: 'model', 'fraud', 'wit', 'data', 'learning', 'ha', 'technique', 'information', 'card', 'wikipedia'\n",
      "Probability of Topic: 0.9908\n",
      "\n",
      "\n",
      "Title: Deep learning in neural networks: an overview\n",
      "DOI: 10.1016/J.NEUNET.2014.09.003\n",
      "Cites: http://www.wikidata.org/entity/Q29398287\n",
      "Number of Pages: 33\n",
      "Publication Date: 2014-10-13T00:00:00Z\n",
      "Language: http://www.wikidata.org/entity/Q1860\n",
      "Pages: 85-117\n",
      "Published In: http://www.wikidata.org/entity/Q15708873\n",
      "Main Subject: http://www.wikidata.org/entity/Q197536\n",
      "Instance Of: N/A\n",
      "Author: ['Thomas B. Miller']\n",
      "Topic: 'learning', 'transaction', 'model', 'machine', 'deep', 'fraud', 'network', 'technology', 'card', 'algorithm'\n",
      "Probability of Topic: 0.9857\n",
      "\n",
      "\n",
      "Title: Linking ImageNet WordNet Synsets with Wikidata\n",
      "DOI: 10.1145/3184558.3191645\n",
      "Cites: http://www.wikidata.org/entity/Q36655252\n",
      "Number of Pages: 6\n",
      "Publication Date: 2018-04-01T00:00:00Z\n",
      "Language: http://www.wikidata.org/entity/Q1860\n",
      "Pages: 1809-1814\n",
      "Published In: http://www.wikidata.org/entity/Q51885042\n",
      "Main Subject: http://www.wikidata.org/entity/Q24901201\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: 'ai', 'learning', 'data', 'healthcare', 'deep', 'knowledge', 'linkage', 'graph', 'wikidata', 'wordnet'\n",
      "Probability of Topic: 0.9795\n",
      "\n",
      "\n",
      "Title: Credit Card Fraud Detection using Logistic Regression Compared with t-SNE to Improve Accuracy\n",
      "DOI: 10.55248/GENGPI.2022.3.8.37\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2022-08-17T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 1000-1004\n",
      "Published In: N/A\n",
      "Main Subject: http://www.wikidata.org/entity/Q83873\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: 'model', 'fraud', 'wit', 'data', 'learning', 'ha', 'technique', 'information', 'card', 'wikipedia'\n",
      "Probability of Topic: 0.9857\n",
      "\n",
      "\n",
      "Title: An Efficient Deep Learning Classification Model for Predicting Credit Card Fraud on Skewed Data\n",
      "DOI: 10.26735/TLYG7256\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2022-06-30T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 57-71\n",
      "Published In: http://www.wikidata.org/entity/Q96715947\n",
      "Main Subject: http://www.wikidata.org/entity/Q83873\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: 'learning', 'transaction', 'model', 'machine', 'deep', 'fraud', 'network', 'technology', 'card', 'algorithm'\n",
      "Probability of Topic: 0.9895\n",
      "\n",
      "\n",
      "Title: \"Artificial intelligence\n",
      "DOI:  machine learning\n",
      "Cites:  computer-aided diagnosis\n",
      "Number of Pages:  and radiomics: advances in imaging towards to precision medicine\"\n",
      "Publication Date: 10.1590/0100-3984.2019.0049\n",
      "Language: http://www.wikidata.org/entity/Q37615306\n",
      "Pages: N/A\n",
      "Published In: 2019-11-01T00:00:00Z\n",
      "Main Subject: http://www.wikidata.org/entity/Q1860\n",
      "Instance Of: 387-396\n",
      "Author: []\n",
      "Topic: \n",
      "Probability of Topic: 0\n",
      "\n",
      "\n",
      "Title: A widespread Survey on Machine Learning Techniques and User Substantiation Methods for Credit Card Fraud Detection\n",
      "DOI: 10.1504/IJBIDM.2023.10047750\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2023-01-01T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 1\n",
      "Published In: http://www.wikidata.org/entity/Q15752768\n",
      "Main Subject: http://www.wikidata.org/entity/Q83873\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: 'card', 'credit', 'transaction', 'fraud', 'part', 'customer', 'authorized', 'algorithm', 'increased', 'time'\n",
      "Probability of Topic: 0.9909\n",
      "\n",
      "\n",
      "Title: The role of artificial intelligence in achieving the Sustainable Development Goals\n",
      "DOI: 10.1038/S41467-019-14108-Y\n",
      "Cites: http://www.wikidata.org/entity/Q105875591\n",
      "Number of Pages: 10\n",
      "Publication Date: 2020-01-13T00:00:00Z\n",
      "Language: http://www.wikidata.org/entity/Q1860\n",
      "Pages: 233\n",
      "Published In: http://www.wikidata.org/entity/Q573880\n",
      "Main Subject: http://www.wikidata.org/entity/Q131201\n",
      "Instance Of: N/A\n",
      "Author: ['C. Nagadeepa', 'Reenu Mohan', 'Antonio Huamán-Osorio', 'Willian Josue Fernandez Celestino']\n",
      "Topic: 'ai', 'development', 'sustainable', 'target', 'study', 'impact', 'goal', 'sdgs', 'result', 'enable'\n",
      "Probability of Topic: 0.9955\n",
      "\n",
      "\n",
      "Title: Credit Card Fraud Detection using Python &amp; Machine Learning Algorithms\n",
      "DOI: 10.22214/IJRASET.2023.52242\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2023-05-31T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 3120-3128\n",
      "Published In: http://www.wikidata.org/entity/Q96710230\n",
      "Main Subject: http://www.wikidata.org/entity/Q83873\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: 'card', 'credit', 'transaction', 'fraud', 'part', 'customer', 'authorized', 'algorithm', 'increased', 'time'\n",
      "Probability of Topic: 0.7308\n",
      "\n",
      "\n",
      "Title: Artificial intelligence and deep learning in ophthalmology\n",
      "DOI: 10.1136/BJOPHTHALMOL-2018-313173\n",
      "Cites: http://www.wikidata.org/entity/Q53872479\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2019-02-01T00:00:00Z\n",
      "Language: http://www.wikidata.org/entity/Q1860\n",
      "Pages: 167-175\n",
      "Published In: http://www.wikidata.org/entity/Q13443571\n",
      "Main Subject: http://www.wikidata.org/entity/Q2539\n",
      "Instance Of: N/A\n",
      "Author: ['Sang J. Kim', 'Michael F. Chiang']\n",
      "Topic: 'ai', 'learning', 'dl', 'deep', 'ha', 'gene', 'technology', 'human', 'application', 'article'\n",
      "Probability of Topic: 0.9895\n",
      "\n",
      "\n",
      "Title: \"Artificial intelligence in healthcare: past\n",
      "DOI:  present and future.\"\n",
      "Cites: 10.1136/SVN-2017-000101\n",
      "Number of Pages: http://www.wikidata.org/entity/Q37199212\n",
      "Publication Date: N/A\n",
      "Language: 2017-06-21T00:00:00Z\n",
      "Pages: N/A\n",
      "Published In: 230-243\n",
      "Main Subject: http://www.wikidata.org/entity/Q27727612\n",
      "Instance Of: http://www.wikidata.org/entity/Q11660\n",
      "Author: []\n",
      "Topic: \n",
      "Probability of Topic: 0\n",
      "\n",
      "\n",
      "Title: Credit Card Fraud Detection Using Machine Learning and Blockchain\n",
      "DOI: 10.22214/IJRASET.2023.52214\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2023-05-31T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 2745-2751\n",
      "Published In: http://www.wikidata.org/entity/Q96710230\n",
      "Main Subject: http://www.wikidata.org/entity/Q83873\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: 'learning', 'transaction', 'model', 'machine', 'deep', 'fraud', 'network', 'technology', 'card', 'algorithm'\n",
      "Probability of Topic: 0.992\n",
      "\n",
      "\n",
      "Title: Credit Card Fraud Detection Using Machine Learning &amp; Python\n",
      "DOI: 10.56726/IRJMETS42136\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2023-06-16T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: N/A\n",
      "Published In: N/A\n",
      "Main Subject: http://www.wikidata.org/entity/Q83873\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: 'card', 'credit', 'transaction', 'fraud', 'part', 'customer', 'authorized', 'algorithm', 'increased', 'time'\n",
      "Probability of Topic: 0.99\n",
      "\n",
      "\n",
      "Title: Applications of machine learning and artificial intelligence for Covid-19 (SARS-CoV-2) pandemic: A review\n",
      "DOI: 10.1016/J.CHAOS.2020.110059\n",
      "Cites: http://www.wikidata.org/entity/Q91943997\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2020-06-25T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 110059\n",
      "Published In: http://www.wikidata.org/entity/Q15766768\n",
      "Main Subject: http://www.wikidata.org/entity/Q81068910\n",
      "Instance Of: N/A\n",
      "Author: ['Shashank G. S. Yashas', 'Yashas Vinay']\n",
      "Topic: 'ai', 'learning', 'dl', 'deep', 'ha', 'gene', 'technology', 'human', 'application', 'article'\n",
      "Probability of Topic: 0.9942\n",
      "\n",
      "\n",
      "Title: Improving Wikipedia verifiability with AI\n",
      "DOI: 10.1038/S42256-023-00726-1\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2023-10-19T00:00:00Z\n",
      "Language: http://www.wikidata.org/entity/Q1860\n",
      "Pages: 1142-1148\n",
      "Published In: http://www.wikidata.org/entity/Q44062926\n",
      "Main Subject: http://www.wikidata.org/entity/Q11660\n",
      "Instance Of: N/A\n",
      "Author: ['Sebastian Riedel']\n",
      "Topic: 'wikipedia', 'claim', 'system', 'citation', 'fraud', 'learning', 'one', 'credit', 'card', 'increase'\n",
      "Probability of Topic: 0.9956\n",
      "\n",
      "\n",
      "Title: Deep Learning: Methods and Applications\n",
      "DOI: 10.1561/2000000039\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2014-01-01T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: 197-387\n",
      "Published In: http://www.wikidata.org/entity/Q15763119\n",
      "Main Subject: http://www.wikidata.org/entity/Q197536\n",
      "Instance Of: N/A\n",
      "Author: ['Lukáš Vařeka', 'Pavel Mautner']\n",
      "Topic: 'ai', 'learning', 'dl', 'deep', 'ha', 'gene', 'technology', 'human', 'application', 'article'\n",
      "Probability of Topic: 0.9929\n",
      "\n",
      "\n",
      "Title: The Gene Wiki: community intelligence applied to human gene annotation\n",
      "DOI: 10.1093/NAR/GKP760\n",
      "Cites: http://www.wikidata.org/entity/Q29619285\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2010-01-01T00:00:00Z\n",
      "Language: http://www.wikidata.org/entity/Q1860\n",
      "Pages: D633-9\n",
      "Published In: http://www.wikidata.org/entity/Q135122\n",
      "Main Subject: http://www.wikidata.org/entity/Q177005\n",
      "Instance Of: N/A\n",
      "Author: ['Adrian Tsang', 'René Witte']\n",
      "Topic: 'ai', 'learning', 'dl', 'deep', 'ha', 'gene', 'technology', 'human', 'application', 'article'\n",
      "Probability of Topic: 0.9911\n",
      "\n",
      "\n",
      "Title: Rows from Many Sources: Enriching row completions from Wikidata with a pre-trained Language Model\n",
      "DOI: 10.1145/3487553.3524923\n",
      "Cites: N/A\n",
      "Number of Pages: N/A\n",
      "Publication Date: 2022-04-25T00:00:00Z\n",
      "Language: N/A\n",
      "Pages: N/A\n",
      "Published In: http://www.wikidata.org/entity/Q112275684\n",
      "Main Subject: http://www.wikidata.org/entity/Q2013\n",
      "Instance Of: N/A\n",
      "Author: []\n",
      "Topic: 'task', 'row', 'text', 'generation', 'knowledge', 'additional', 'table', 'base', 'using', 'filling'\n",
      "Probability of Topic: 0.9911\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_papers = []\n",
    "author_by_doi = {}\n",
    "topic_by_doi = {}\n",
    "topic_and_prob_by_title = {}\n",
    "topic_and_prob_by_doi = {}\n",
    "possible_topics = []\n",
    "\n",
    "wikidata_res = '../../papers/wikidata/results.csv'\n",
    "openalex_res = '../../papers/openalex/results.csv'\n",
    "prob_res = '../../papers/probabilities/'\n",
    "doi_res = '../../papers/doi/'\n",
    "topic_res = '../../papers/topics/'\n",
    "\n",
    "# read authors\n",
    "with open(openalex_res, 'r') as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        line_split = line.split(',')\n",
    "        doi = line_split[0]\n",
    "        author = line_split[1]\n",
    "        author_institution = line_split[2]\n",
    "\n",
    "        if doi in author_by_doi and author not in author_by_doi[doi]:\n",
    "            author_by_doi[doi].append(author)\n",
    "        else:\n",
    "            author_by_doi[doi] = [author]\n",
    "\n",
    "# read topics\n",
    "with open(topic_res + 'topics.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        if line == '\\n':\n",
    "            continue\n",
    "        line = line.replace('\\n', '')\n",
    "        topic = line.split(\":\")[1].strip()\n",
    "        possible_topics.append(topic)\n",
    "\n",
    "# read topics and probabilities\n",
    "for filename in os.listdir(prob_res):\n",
    "    with open(prob_res + filename, 'r') as f:\n",
    "        line = f.read()\n",
    "\n",
    "        topic_start = line.find(\"Topic: [\") + len(\"Topic: [\")\n",
    "        topic_end = line.find(\"]\", topic_start)\n",
    "        prob_start = line.find(\"Probability: \") + len(\"Probability: \")\n",
    "        prob_end = line.find(\"\\n\", prob_start)\n",
    "\n",
    "        topic = line[topic_start:topic_end]\n",
    "        probabilidad = float(line[prob_start:prob_end])\n",
    "        topic_and_prob_by_title[filename] = (topic, probabilidad)\n",
    "    \n",
    "for filename in os.listdir(doi_res):\n",
    "    with open(doi_res + filename, 'r') as f:\n",
    "        if filename in topic_and_prob_by_title:\n",
    "            doi = f.read()\n",
    "            topic = topic_and_prob_by_title[filename][0]\n",
    "            probabilidad = topic_and_prob_by_title[filename][1]\n",
    "            topic_and_prob_by_doi[doi] = (topic, probabilidad)\n",
    "\n",
    "# read csv\n",
    "with open(wikidata_res, 'r') as f:\n",
    "    # skip header\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        line_split = line.split(',')\n",
    "        # save all atributes in paper object\n",
    "        doi = line_split[1]\n",
    "        if doi in author_by_doi:\n",
    "            authors = author_by_doi[doi]\n",
    "        else:\n",
    "            authors = []\n",
    "\n",
    "        if doi in topic_and_prob_by_doi:\n",
    "            topic, probabilidad = topic_and_prob_by_doi[doi]\n",
    "        else:\n",
    "            topic = \"\"\n",
    "            probabilidad = 0\n",
    "        \n",
    "        line_split[9] = line_split[9].replace('\\n', '')\n",
    "        paper = Publication(line_split[0], line_split[1], line_split[2], line_split[3], line_split[4], line_split[5], line_split[6], line_split[7], line_split[8], line_split[9], authors, topic, probabilidad)\n",
    "        list_papers.append(paper)\n",
    "        paper.display_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "http://example.org/ machine learning does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/ present and future.\" does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/learning, transaction, model, machine, deep, fraud, network, technology, card, algorithm does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/wikipedia, claim, system, citation, fraud, learning, one, credit, card, increase does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/model, fraud, wit, data, learning, ha, technique, information, card, wikipedia does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/ai, learning, data, healthcare, deep, knowledge, linkage, graph, wikidata, wordnet does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/task, row, text, generation, knowledge, additional, table, base, using, filling does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/ai, learning, dl, deep, ha, gene, technology, human, application, article does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/learning, deep, application, processing, area, information, criterion, multimodal, use, research does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/ai, development, sustainable, target, study, impact, goal, sdgs, result, enable does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/card, credit, transaction, fraud, part, customer, authorized, algorithm, increased, time does not look like a valid URI, trying to serialize this will break.\n",
      "http://example.org/data, machine, model, learning, disease, ml, study, method, may, paper does not look like a valid URI, trying to serialize this will break.\n"
     ]
    }
   ],
   "source": [
    "g = Graph()\n",
    "\n",
    "for paper in list_papers:\n",
    "    paper_uri = URIRef(\"http://example.org/\" + paper.get_doi())\n",
    "    g.add((paper_uri, RDF.type, URIRef(\"http://schema.org/PaperArticle\")))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/title\"), Literal(paper.get_title())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/doi\"), Literal(paper.get_doi())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/cites\"), Literal(paper.get_cites())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/numPages\"), Literal(paper.get_num_pages())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/publicationDate\"), Literal(paper.get_publication_date())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/inLanguage\"), Literal(paper.get_language())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/pages\"), Literal(paper.get_pages())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/publishedIn\"), Literal(paper.get_published_in())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/mainSubject\"), Literal(paper.get_main_subject())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/author\"), Literal(paper.get_author())))\n",
    "    g.add((paper_uri, URIRef(\"http://schema.org/topic\"), Literal(paper.get_topic())))\n",
    "\n",
    "for topic in possible_topics:\n",
    "    topic_uri = URIRef(\"http://example.org/\" + topic)\n",
    "    g.add((topic_uri, RDF.type, URIRef(\"http://schema.org/topic\")))\n",
    "    g.add((topic_uri, URIRef(\"http://schema.org/name\"), Literal(topic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "http://OSGroup.com/res/doi machine learning does not look like a valid URI, trying to serialize this will break.\n",
      "http://OSGroup.com/res/paper/\"Artificial_intelligence does not look like a valid URI, trying to serialize this will break.\n",
      "http://OSGroup.com/res/doi present and future.\" does not look like a valid URI, trying to serialize this will break.\n",
      "http://OSGroup.com/res/paper/\"Artificial_intelligence_in_healthcare:_past does not look like a valid URI, trying to serialize this will break.\n"
     ]
    }
   ],
   "source": [
    "g = Graph()\n",
    "\n",
    "for paper in list_papers:\n",
    "    # add doi\n",
    "    relacion = URIRef(\"http://OSGroup.com/def/prop#/has_doi\")\n",
    "    objeto = URIRef(\"http://OSGroup.com/res/doi\" + paper.get_doi())\n",
    "    g.add((URIRef(\"http://OSGroup.com/res/paper/\" + paper.get_title().replace(\" \", \"_\")), relacion, objeto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Namespace\n",
    "onto = Namespace(\"http://example.org/\")\n",
    "g.bind(\"onto\", onto)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        query = input(\"Enter a SPARQL query or 'exit' to finish: \")\n",
    "        if query == 'exit':\n",
    "            break\n",
    "        else:\n",
    "            for row in g.query(query):\n",
    "                print(row)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying the graph for a specific paper\n",
      "\n",
      "\n",
      "(rdflib.term.Literal('An Efficient Deep Learning Classification Model for Predicting Credit Card Fraud on Skewed Data'), rdflib.term.Literal(\"'learning', 'transaction', 'model', 'machine', 'deep', 'fraud', 'network', 'technology', 'card', 'algorithm'\"), rdflib.term.Literal('[]'))\n"
     ]
    }
   ],
   "source": [
    "print(\"Querying the graph for a specific paper\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for result in g.query(\n",
    "    '''PREFIX schema: <http://schema.org/>\n",
    "\n",
    "    SELECT ?title ?topic ?author\n",
    "    WHERE {\n",
    "    ?paper a schema:PaperArticle ;\n",
    "        schema:doi \"10.26735/TLYG7256\" ;\n",
    "        schema:title ?title ;\n",
    "        schema:topic ?topic ;\n",
    "        schema:author ?author .\n",
    "    }'''\n",
    "):\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All possible topics:\n",
      "\n",
      "\n",
      "(rdflib.term.Literal('learning, transaction, model, machine, deep, fraud, network, technology, card, algorithm'),)\n",
      "(rdflib.term.Literal('wikipedia, claim, system, citation, fraud, learning, one, credit, card, increase'),)\n",
      "(rdflib.term.Literal('model, fraud, wit, data, learning, ha, technique, information, card, wikipedia'),)\n",
      "(rdflib.term.Literal('ai, learning, data, healthcare, deep, knowledge, linkage, graph, wikidata, wordnet'),)\n",
      "(rdflib.term.Literal('task, row, text, generation, knowledge, additional, table, base, using, filling'),)\n",
      "(rdflib.term.Literal('ai, learning, dl, deep, ha, gene, technology, human, application, article'),)\n",
      "(rdflib.term.Literal('learning, deep, application, processing, area, information, criterion, multimodal, use, research'),)\n",
      "(rdflib.term.Literal('ai, development, sustainable, target, study, impact, goal, sdgs, result, enable'),)\n",
      "(rdflib.term.Literal('card, credit, transaction, fraud, part, customer, authorized, algorithm, increased, time'),)\n",
      "(rdflib.term.Literal('data, machine, model, learning, disease, ml, study, method, may, paper'),)\n"
     ]
    }
   ],
   "source": [
    "print(\"All possible topics:\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for result in g.query(\n",
    "    '''PREFIX schema: <http://schema.org/>\n",
    "    SELECT ?topic\n",
    "    WHERE {\n",
    "        ?paper a schema:topic ;\n",
    "               schema:name ?topic .\n",
    "    }\n",
    "    '''\n",
    "):\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All papers:\n",
      "\n",
      "\n",
      "(rdflib.term.Literal('A multilevel review of artificial intelligence in organizations: Implications for organizational behavior research and practice'),)\n",
      "(rdflib.term.Literal('A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases'),)\n",
      "(rdflib.term.Literal('Exploring the impact of artificial intelligence on teaching and learning in higher education'),)\n",
      "(rdflib.term.Literal('Deep Learning: Methods and Applications'),)\n",
      "(rdflib.term.Literal('Deep learning'),)\n",
      "(rdflib.term.Literal('Surrogate techniques for testing fraud detection algorithms in credit card operations'),)\n",
      "(rdflib.term.Literal('use of data mining of to create of a fraud prevention and detection system in credit card'),)\n",
      "(rdflib.term.Literal('WIT: Wikipedia-based Image Text Dataset for Multimodal Multilingual Machine Learning'),)\n",
      "(rdflib.term.Literal('Analysis and prediction for credit card fraud detection dataset using data mining approaches'),)\n",
      "(rdflib.term.Literal('Credit Card Fraud Detection Using Random Forest Classification'),)\n",
      "(rdflib.term.Literal('A deep learning-based quality assessment model of collaboratively edited documents: A case study of Wikipedia'),)\n",
      "(rdflib.term.Literal('Deep learning in neural networks: an overview'),)\n",
      "(rdflib.term.Literal('Linking ImageNet WordNet Synsets with Wikidata'),)\n",
      "(rdflib.term.Literal('Credit Card Fraud Detection using Logistic Regression Compared with t-SNE to Improve Accuracy'),)\n",
      "(rdflib.term.Literal('An Efficient Deep Learning Classification Model for Predicting Credit Card Fraud on Skewed Data'),)\n",
      "(rdflib.term.Literal('\"Artificial intelligence'),)\n",
      "(rdflib.term.Literal('A widespread Survey on Machine Learning Techniques and User Substantiation Methods for Credit Card Fraud Detection'),)\n",
      "(rdflib.term.Literal('The role of artificial intelligence in achieving the Sustainable Development Goals'),)\n",
      "(rdflib.term.Literal('Credit Card Fraud Detection using Python &amp; Machine Learning Algorithms'),)\n",
      "(rdflib.term.Literal('Artificial intelligence and deep learning in ophthalmology'),)\n",
      "(rdflib.term.Literal('\"Artificial intelligence in healthcare: past'),)\n",
      "(rdflib.term.Literal('Credit Card Fraud Detection Using Machine Learning and Blockchain'),)\n",
      "(rdflib.term.Literal('Credit Card Fraud Detection Using Machine Learning &amp; Python'),)\n",
      "(rdflib.term.Literal('Applications of machine learning and artificial intelligence for Covid-19 (SARS-CoV-2) pandemic: A review'),)\n",
      "(rdflib.term.Literal('Improving Wikipedia verifiability with AI'),)\n",
      "(rdflib.term.Literal('The Gene Wiki: community intelligence applied to human gene annotation'),)\n",
      "(rdflib.term.Literal('Rows from Many Sources: Enriching row completions from Wikidata with a pre-trained Language Model'),)\n"
     ]
    }
   ],
   "source": [
    "print(\"All papers:\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for result in g.query(\n",
    "    '''\n",
    "    PREFIX schema: <http://schema.org/>\n",
    "    SELECT ?title\n",
    "    WHERE {\n",
    "        ?paper a schema:PaperArticle ;\n",
    "               schema:title ?title .\n",
    "    }\n",
    "    '''\n",
    "):\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "os_group",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
