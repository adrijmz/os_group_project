<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Rows from Many Sources: Enriching row completions from Wikidata with a pre-trained Language Model</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-04-14">14 Apr 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Carina</forename><surname>Negreanu</surname></persName>
							<email>cnegreanu@microsoft.com</email>
						</author>
						<author>
							<persName><forename type="first">Alperen</forename><surname>Karaoglu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shuang</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Fabian</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Gordon</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jack</forename><surname>Williams</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Jack Williams Microsoft Research Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Harbin Institute of Technology Harbin</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Microsoft Research Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Microsoft Research Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Microsoft Research Beijing</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Rows from Many Sources: Enriching row completions from Wikidata with a pre-trained Language Model</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-04-14">14 Apr 2022</date>
						</imprint>
					</monogr>
					<idno type="MD5">242DD1C82CDC01B28E096D8D03CD3376</idno>
					<idno type="DOI">10.1145/3487553.3524923</idno>
					<idno type="arXiv">arXiv:2204.07014v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2024-05-06T15:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>knowledge base linking</term>
					<term>natural language applications</term>
					<term>language models</term>
					<term>semantic knowledge</term>
					<term>free text generation</term>
					<term>tabular data</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Row completion is the task of augmenting a given table of text and numbers with additional, relevant rows. The task divides into two steps: subject suggestion, the task of populating the main column; and gap filling, the task of populating the remaining columns. We present state-of-the-art results for subject suggestion and gap filling measured on a standard benchmark (WikiTables).</p><p>Our idea is to solve this task by harmoniously combining knowledge base table interpretation and free text generation. We interpret the table using the knowledge base to suggest new rows and generate metadata like headers through property linking. To improve candidate diversity, we synthesize additional rows using free text generation via GPT-3, and crucially, we exploit the metadata we interpret to produce better prompts for text generation. Finally, we verify that the additional synthesized content can be linked to the knowledge base or a trusted web source such as Wikipedia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>• Information systems → Language models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Row completion is the task of suggesting new complete rows for a given table. Its purpose is to help users gain confidence in the completeness of their data. Row completion is a table enhancement that is particularly important for spreadsheet intelligence, because it is a step towards unlocking a multitude of other intelligent features that require good quality data, such as data insights and chart recommendations.</p><p>Row completion divides into three standard steps that we illustrate using the example in Figure <ref type="figure" target="#fig_0">1</ref>. To the best of our knowledge, the overall task of row completion is new, although each of its three steps has been studied independently. The top table is the input table; the bottom table is the linked table with a suggested row.</p><p>Step 1: Table <ref type="table">Interpretation</ref> We link the data in the input table to a knowledge base (KB), such as DBpedia <ref type="bibr" target="#b0">[1]</ref> or Wikidata <ref type="bibr" target="#b27">[28]</ref>. Table interpretation itself decomposes into three sub-tasks as proposed in <ref type="bibr" target="#b1">[2]</ref>: column type identification, entity linking and property linking. The figure shows in green the entities and properties from Wikidata (using the English labels as proxies for the unique numeric identifiers, and "?" denotes an unlinked property).</p><p>Step 2: Subject Suggestion We predict additional primary entities described in the table, a task we refer to as subject suggestion, since it determines the primary subject of the row and not the complete row.</p><p>Our figure shows in blue a single suggested subject: the entity "Kendrick Lamar". In practice, subject suggestion generates an ordered set of entities.</p><p>Step 3: Gap Filling We fill in the remainder of the row, a particular case of gap filling. Our figure shows in purple the properties of "Kendrick Lamar" filled by our algorithm.</p><p>The goal of this paper is to dramatically expand the scope of subject suggestion and gap filling by sourcing entities and properties from relatively uncurated web sources. Our target is Wikidata, the largest, fastest growing, and most up to date open knowledge base.</p><p>To achieve this goal, we need to go beyond methods aimed at structured datasets like DBpedia or WikiTables, which inherit structure from their source Wikipedia, highly curated by humans.</p><p>Our key new idea is to rely on prompting an existing pre-trained language model during subject suggestion (Step 2) and gap filling <ref type="bibr">(</ref>Step 3) to source entity and property candidates by free text generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Challenges for</head><p>Step 2: Subject Suggestion with Wikidata. Subject suggestion first involves generating a set of potential candidates and then ranking them. EntiTables <ref type="bibr" target="#b35">[36]</ref>, the current state of the art in candidate generation for subject suggestion, sources candidates from DBpedia and WikiTables. Although highly valuable, both sources are extracted from Wikipedia limiting the diversity.</p><p>To suggest from Wikidata we need to address two significant challenges. The first is that Wikidata has a weak type ontology.</p><p>Existing approaches to subject suggestion, such as Entitables <ref type="bibr" target="#b35">[36]</ref>, rely on a well-defined type ontology to construct search indexes to find candidates. Unfortunately, Wikidata lacks such a well-defined type ontology, and does not require users to provide complete information when entering a new entity, leading to a significant number of missing properties <ref type="bibr" target="#b13">[14]</ref>. For example, the type of Cat and Lion in DBpedia is "Mammal", while in Wikidata, a Cat is an instance of "organisms known by a particular common name" (analogous to its type), and a Lion is an instance of "taxon". We take a new approach where we start from multi-relational entity embeddings (such as Pytorch BigGraph (PBG) embeddings <ref type="bibr" target="#b16">[17]</ref>) of the seeds and create a candidate set from their nearest neighbours that share a subset of properties linked from the table. In doing so, we can handle Wikidata's steep growth by avoiding expensive computations over the whole entity space. Furthermore, PBG embeddings can be updated efficiently which makes them an ideal candidate for data that evolves rapidly over time.</p><p>The second challenge for subject suggestion from Wikidata is that directly using KB embeddings for subject suggestion can have low recall. While Wikidata is vast, it remains incomplete which can lead to sparse regions in the embedding space as PBG trains on an input graph by ingesting its list of edges, each identified by its source and target entities and, possibly, a relation type. Thus, for some entities our initial approach might not have sufficient recall and we diversify our candidates by using free text generation. Generative language models like GPT-3 <ref type="bibr" target="#b3">[4]</ref> or Codex <ref type="bibr" target="#b4">[5]</ref> are trained on enormous datasets extracted from the web, and capture a rich knowledge of co-occurrence information. Augmenting knowledge base subject suggestion using a language model is an enticing way to find new candidates, however prompting GPT-3 using the input table alone delivers poor results. Our approach is to exploit the table metadata we interpret in Step 1 to craft structured prompts.</p><p>For example, in Figure <ref type="figure" target="#fig_0">1</ref> we use the linked properties to create the prompt "Kanye West has pseudonym Yeezy and has date of birth 1977". Thus, we treat the large language model as a source of knowledge (that needs to be verified) which we query by synthesizing the tabular context. Our approach shows that good quality queries can be constructed for relational tables so we do not have to fine-tune the language model to understand the information in the table.</p><p>Turning to candidate ranking for subject suggestion, prior art, such as Table2Vec <ref type="bibr" target="#b34">[35]</ref> or more recently Tabbie <ref type="bibr" target="#b11">[12]</ref>, ranks via entity similarity (between seed entities and candidates) using knowledge base and table similarity statistics. They make use of tabular representations (static embeddings <ref type="bibr" target="#b34">[35]</ref> or BERT-based representations <ref type="bibr" target="#b11">[12]</ref>) which require significant training and/or fine-tuning (e.g. <ref type="bibr" target="#b11">[12]</ref> estimates total emissions at 300kg of 𝐶𝑂 2 for this task). We propose building a classifier over features that are generated with metadata already available from the base models (e.g. GPT-3 and PBG) without further training or fine-tuning. As we have a large set of candidates relative to the number of suggestions we want to offer we classify using outlier detectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Challenges for</head><p>Step 3: Gap Filling with Wikidata. In Step 3, we want to fill in the remainder of the row once we have a subject suggestion. Recent state of the art for this task is achieved by TURL <ref type="bibr" target="#b5">[6]</ref>, a different table representation approach that learns contextualized representations on relational tables by masked entity retrieval. It sources fills from other WikiTables. In our work we fill gaps by using other sources such as Wikidata. Unfortunately, KB sparsity directly affects gap filling as either the information we would like to retrieve doesn't exist (the entity's property value is missing) or there is not enough information to link the column to a property. To overcome this challenge we extend gap filling to include information from multiple sources such as news, Wikipedia articles or any other reliable web sources. Similarly to subject suggestion we use GPT-3 to generate potential candidates. The difference between the two approaches is that instead of trying to verify the candidates by linking back to Wikidata we attempt to ground the generations in a broader range of sources. Assigning provenance to a generation is insufficient to assess whether the generation should be a fill. We need to also use the context from the source to determine if the generation is consistent with the table. For example, if we had a table about athletes we could use GPT-3 to fill in the missing eyecolour information. If one of the generations is "brown" we need to verify that the colour refers to eye colour and not hair colour.</p><p>The overall contribution of the paper is to establish a new stateof-the-art for row completion, and its key steps of subject suggestion and gap filling, by using language models in those two steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Various aspects of Row Completion have been previously studied and in this section we will provide an overview. For candidate generation previous work has proposed sourcing candidates from a Knowledge Base such as DBpedia or Freebase ( <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b35">[36]</ref>), or use free text ( <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b21">[22]</ref>) or use structured text such as web tables ( <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b35">[36]</ref>) or web queries ( <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b29">[30]</ref>). As several approaches we focus on multi source candidates and our work is closest to <ref type="bibr" target="#b35">[36]</ref> and <ref type="bibr" target="#b34">[35]</ref>.</p><p>When extracting candidates from KBs prior art favours DBpedia where comparing types and categories between all entities leads to good candidate generation. This approach works well for well curated KBs, but in the case of Wikidata we found that it is less effective considering its flexible ontology. To this point, recent work <ref type="bibr" target="#b38">[39]</ref> proposes category generation for sets of entities.</p><p>For ranking candidates, previous work uses various model classes, for example Machine Learning approaches ( <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b11">[12]</ref>), probabilistic approaches ( <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b7">[8]</ref>), graph theory approaches ( <ref type="bibr" target="#b42">[43]</ref>), and human-in-the-loop approaches ( <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b6">[7]</ref>). Our pipeline uses Machine Learning components as we include free text generation and use the output of an unsupervised outlier detector as a ranking function. Unlike previous work we do not train or fine-tune the language model or the embeddings on tabular data. Due to the lack of a large corpus of varied data (the datasets are primarily synthetic or carefully curated) we are wary of generalization. Nonetheless recent deep learning tabular representation models (such as <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b5">[6]</ref> or <ref type="bibr" target="#b32">[33]</ref>) show improvements by better encoding the tabular context.</p><p>A related area of study is set expansion, an instance of subject suggestion specialized to one column tables without headers, or lists. Relevant work in this space that tackles ambiguity and semantic drift includes <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b34">[35]</ref> and <ref type="bibr" target="#b21">[22]</ref>.</p><p>For the gap filling task <ref type="bibr" target="#b36">[37]</ref> aims to fill in gaps in tables with multisource candidates (from DBpedia and tables) and their algorithms for tabular sources get improved upon by recent work <ref type="bibr" target="#b5">[6]</ref>. Our work extends to unstructured text sources (like Wikipedia or news articles) for significant recall and precision gains.</p><p>Tangential emerging research areas that are relevant to our work are knowledge acquisition via pre-trained language models and prompt-engineering. Prior work (such as <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b15">[16]</ref> or <ref type="bibr" target="#b47">[48]</ref>) uses the knowledge within pre-trained language models for QA, fact checking or truthful generation. Significant efforts have focused on building better prompts and a representative collection can be found in a recent survey <ref type="bibr" target="#b18">[19]</ref>. To our knowledge we are the first to focus on prompt engineering for tabular data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TASKS</head><p>In this section, we formally define the tabular data interpretation and augmentation problem. We start by describing the tabular data and knowledge base (KB), then formally define the task settings.</p><p>Let 𝑇 range over relational tables of the form {𝑡 The knowledge base (KB) studied in our work follows RDF (Resource Description Framework) standard which consists of a terminological component (TBox) and an assertion component (ABox). Let E = {𝑒 1 , ..., 𝑒 | E | } be the set of all entities in the KB. The TBox defines the schema structure of the KB including type ontology T and properties set P. The type ontology T = {𝜏 1 , ..., 𝜏 | T | } ⊆ E consists of type definitions and a type hierarchy constructed with the subclass of relation. An entity 𝑒 ∈ E can belong to one or more types of the type ontology. Specifically, we write type (𝑒) = 𝜏 to denote an entity 𝑒 belongs to a type 𝜏 ∈ T . The properties set P = {𝑝 1 , ..., 𝑝 | P | } defines the set of possible properties used to describe key attributes of an entity. The ABox is the instantiation of KB which is composed of a set of RDF triples ⟨𝑠, 𝑝, 𝑜⟩, where 𝑠 denotes a subject (an entity 𝑒 ∈ E), 𝑝 ∈ P is a property (also known as predicate or relation) and 𝑜 denotes an object (an entity 𝑒, or a data value, e.g. number, time, string etc.). We write 𝑝 (𝑒) for property lookup that returns 𝑜 when ⟨𝑠, 𝑝, 𝑜⟩ exists in the KB, and ⊥ otherwise. We implicitly assume that 𝑝 (𝑒) maps to zero or one target. Although tailored for our target KB, Wikidata ) be the list of entities corresponding to the left most table column, which we refer to as the main column. Subject suggestion generates a ranked list of entities 𝐸 new to be added to 𝐸. In Figure <ref type="figure" target="#fig_1">2</ref>, 2 displays suggested subjects.</p><p>Definition 4. Given table 𝑇 we extend the main column with the entity set 𝐸 new . For each 𝑒 𝑖,1 ∈ 𝐸 new gap filling returns 𝑜 𝑖,𝑗 where 𝑜 𝑖,𝑗 is either sourced from the KB via a triple ⟨𝑒 𝑖,1 , 𝑝 𝑗 , 𝑜 𝑖,𝑗 ⟩, or via a verified web source. In Figure <ref type="figure" target="#fig_1">2</ref>, 3 displays gap suggestions.</p><p>Definition 5. Row completion is the task of returning a complete new row, that is, Row completion = Subject suggestion + Gap Filling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ALGORITHMS</head><p>Given a set of candidate entities for the main column we start by trying to find the most likely mapping between relational columns and Wikidata properties. We take a similar approach to <ref type="bibr" target="#b39">[40]</ref> with the exception of two problems that we address differently: property sparseness and numerical matching. Full details of this extension can be found in Appendix A and in this section we will focus on the algorithms for Subject Suggestion and Gap Filling.</p><p>At the end of this phase our algorithm has produced the metadata shown in Step 1 in Figure <ref type="figure" target="#fig_1">2</ref>. We find the in-table properties pseudonym and date of birth and fail to link the third column. We manage to link all entities in the main column and identify possible types for them (such as human).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Subject suggestion</head><p>Algorithm 1 Subject suggestion for table 𝑇 with seeds L (sketch)</p><formula xml:id="formula_0">suggest (𝑇 , L) = C ← {𝑒 | ∀𝑖 &lt; 𝑚, 𝑒 ∈ E. distance (L 𝑖 , 𝑒) &lt; threshold } 2a 𝑃 ← {link (GPT3 (toPrompt (𝑇 [𝑖, * ] ))) | ∀𝑖 &lt; 𝑚} 2b return rank (features (𝑇 , L, C ∪ 𝑃))</formula><p>Algorithm 1 presents the high-level algorithm for subject suggestion which is represented by Step 2 in Figure <ref type="figure" target="#fig_1">2</ref>. Subject suggestion takes as input an (𝑚, 𝑛)-table 𝑇 and the linked main column L, and returns a ranked list of subjects to extend the main column. The algorithm for subject suggestion comprises two sub-tasks: candidate generation and candidate ranking.</p><p>Candidate generation. Candidate generation is an important task as ranking all candidates in Wikidata has a high computational cost and at the current rate of growth it cannot scale even with the most efficient ranking algorithms. Our novel method to create a diverse candidate set is shown in Figure <ref type="figure" target="#fig_1">2</ref>, Step 2.</p><p>First, we source KB candidates using the PBG embedding space (Step 2a). Similar to Word2Vec, PBG generates multi-relation embeddings by maximizing the (transformed) similarity score for existing RDF triples while minimizing it for non-existent ones. The similarity is measured by cosine distance (TransE) or dot product distance (RESCAL, DistMult, ComplEx) over transformed vectors for the source and object. The transformations considered are linear transformations (RESCAL), translations (TransE) and complex multiplication (DistMult, ComplEx). A viable candidate is a neighbor of at least one of the seeds present, shares at least one type in common with the seeds, and has some of the in-table properties.</p><p>A key assumption in our work is that using nearest neighbors in PBG is meaningful for generation via similarity. We have found that requiring full property overlap is too restrictive for our choice of KB considering the property sparseness in Wikidata. In some cases (for example when the type is human) we need to further limit the number of candidate generations so we constrain by demanding all in-table properties to be present. If we have a small number of seeds (our current setup), we search for the nearest neighbors of each seed. We can extend this approach for very large tables when we might want to keep extra seeds by checking if we can find clusters in the seed space. Using PBG embeddings has a few important strong points. We did not have to train a new set of embeddings on relevant tabular data to build a space that is representative for our setup (as proposed in <ref type="bibr" target="#b34">[35]</ref>) because the embedding space is already constructed based on the relations between entities. We also do not have to worry about restricting our search to a fixed number of hops. By transitivity if the RDFs ⟨𝑠, 𝑝, 𝑜⟩ and ⟨𝑠, 𝑝, 𝑜 ′ ⟩ exist then o and o' will likely be neighbors (and similarly for ⟨s, p, o⟩ and ⟨s ′ , p, o⟩) as described in <ref type="bibr" target="#b16">[17]</ref>. As a final point, PBG updates efficiently with extra data, which is important as we want to have up-to-date suggestions.</p><p>The second approach for candidate generation is to enhance the candidate pool with predictions obtained from GPT-3 free text generation (as shown in Step 2b of Figure <ref type="figure" target="#fig_1">2</ref>). GPT-3 is an autoregressive language model with 175 billion parameters that has shown promising performance in the few-shot setting. Input table 𝑇 is converted to a prompt and used to sample GPT-3, from which candidates are generated. To create the prompt for GPT-3 we extractively summarize the seed rows given the properties identified. We create a template by concatenating the transformed ⟨s, p, o⟩ → "s has p o" that we identify on each row and we provide the text generator the template. The text generator then fills in new templates and we extract the entities from the templates. If we can link the entities to Wikidata we add them to the candidate set.</p><p>Candidate ranking. After we create a set of candidates from PBG (C) and GPT-3 (P) we want to create a ranked list. In practice, to maintain high levels of recall, the number of candidates we generate is considerably larger than the desired number of completions.</p><p>In order to address the large class imbalance we rank by using the output of an outlier detector that returns the probability that a given candidate is part of the suggestion set. The assumption that we make is that given a set of well curated features the relevant suggestions will appear as outliers in the candidate set. Our models make use of the following features:</p><p>(1) the distance to the closest seed in PBG (the choice of metric depends on the way the graph is generated e.g cosine similarity for TransE, dot product for ComplexE), (2) the percentage of properties not in the table in common with seeds, (3) minimum normalized Levenshtein distance between candidate entity label and seed entity labels, (4) the minimum string embedding (in FastText space <ref type="bibr" target="#b2">[3]</ref>) cosine distance between the candidate entity label and seed entity labels, (5) the percentage of types shared between seeds and candidate, (6) the percentage of seeds that have the candidate as a neighbor, <ref type="bibr" target="#b6">(7)</ref> the candidate generator (GPT-3, PBG or both), (8) the GPT-3 generation score (if available). We start from the toolbox proposed in <ref type="bibr" target="#b45">[46]</ref> for outlier detection algorithms. For semi-supervised and supervised systems we first use a kNN algorithm on the training data to assign table-clusters based on our feature space (and then map the test tables to a given cluster). As a supervised system we use XGBOD <ref type="bibr" target="#b43">[44]</ref>, an ensemble system that combines unsupervised outlier mining algorithms to extract representations to improve the feature space on top of which runs a supervised classifier. For each cluster we train a VAE <ref type="bibr" target="#b12">[13]</ref> on non-outliers (incorrect predictions) and find outliers using the reconstruction error (the hypothesis being that the higher the reconstruction error, the most likely a candidate is to be a viable suggestions). We also consider unsupervised methods that are proximity-based (e.g. LOF) or neural networks (e.g. MO-GAAL <ref type="bibr" target="#b19">[20]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Gap filling</head><p>Once we link the table to the KB and find good suggestions to append to the main column we can in principle easily fill in the remaining information in the table from the KB. Unfortunately, there are two cases where we cannot retrieve the information: when we cannot identify the property the column represents (for example, when the property does not exist in the KB, as shown in column four in Figure <ref type="figure" target="#fig_1">2</ref>) and when we can identify the property but the entity we are trying to fill the value for does not have the property in the KB (for example, an athlete's eye colour is not recorded).</p><p>In order to address these challenging situations we query GPT-3 for potential fills. To mitigate hallucinations we want to link the generation to at least one web source (as GPT-3 is trained on web data). Unfortunately, just linking is insufficient as we could find that although the fill is accurate it is not relevant for the table, for example GPT-3 could retrieve the correct hair colour of the athlete but we are interested in their eye colour. Our approach compares the context from the linked web source with a synthesized context that links the seed entities and their relevant values to decide if the fill is relevant. Another benefit of linking is that it provides a way to mitigate the fact that GPT-3 might suggest out of date information (as the language model is unlikely to update frequently). For example, GPT-3 could retrieve the population of the US, but the data might not be from the most recent census. When linking to a web source we could warn the user the information is out of date from the metadata of the web source. Algorithm 2 presents the algorithm for ranked gap filling which is represented by Step 3 in Figure <ref type="figure" target="#fig_1">2</ref>.</p><p>Formally, gap filling takes as input a target cell (𝑖, 𝑗) and a linked (𝑚, 𝑛)-table L, and returns a set of ranked values with provenance. Provenance is either an RDF-triple or a sourced text snippet.</p><p>Gap filling proceeds by obtaining the subject 𝑠 for the row containing the gap, and the linked property 𝑝 for the column containing the gap. Property 𝑝 can be undefined when property linking fails, for example because the underlying KB lacks the relation. When the KB contains a triple with the corresponding subject and property we immediately return this triple as the value to populate the gap, as shown in Step 3b in Figure <ref type="figure" target="#fig_1">2</ref>. If a triple does not exist (because the property or value is missing) we query GPT-3 to retrieve a set of candidates, corresponding to function rankValues.</p><p>The function rankValues takes as input a subject 𝑠, a column 𝑗, a linked (𝑚, 𝑛)-table L, and an optional property 𝑝 denoted by 𝑝?. First we define context, a loose context given the seed information. For each seed row we query Bing for representative sentences using the seed subject, the value in column 𝑗 of the row, and optional property 𝑝 as keywords by using the bing function. We then use sentence transformers to encode the information into a context. To find the most likely context shared among the seeds we compute the (cosine) similarity across encodings. All the sentences that are most similar (with similarity above a learned threshold) become the context. This process is defined by contextOfSeeds.</p><p>The next step is to iteratively sample GPT-3 for gap suggestions using a prompt created by concatenating prompts for every seed row. When the property 𝑝 is missing we use an analogy-based prompt to retrieve a set of candidates, as shown in Step 3a in Figure <ref type="figure" target="#fig_1">2</ref>. For a subject 𝑠 and value 𝑜 we construct prompt "s is to o as". When the property 𝑝 is linked we construct a prompt of the form "s has p o". The function GPT3 returns the GPT-3 suggestions that are obtain by using the prompt generated by toPrompt. We prune incorrect GPT-3 candidates by verifying against information from trustworthy sources, producing snippets, a set of sourced text snippets. Sourced snippets are obtained by linking candidate ⟨𝑠, 𝑝, 𝑜⟩ triple to Wikipedia or news articles using a web-search engine (like the Bing API). Each source snippet is scored using (cosine) similarity to context, and if the best snippet has sufficient score, the value and source is added to scoredValues.</p><p>Unlike prior approaches, our solution does not require having a two step process to first determine if a cell should be filled. We learn a rough threshold on the validation set such that candidates with scores less than the given threshold are not proposed which can lead to blank cells.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTAL EVALUATION</head><p>In this section we present our experimental results. By convention, in every table of results we indicate prior work using a citation, and all other entries are results of this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Details for reproducibility</head><p>Datasets. In this work we run extensive experiments on the standard benchmark proposed in <ref type="bibr" target="#b35">[36]</ref>, a dataset of 1000 real tables curated by humans. Most importantly this dataset is suitable for evaluation for candidates sourced either from DBpedia or Wikidata as the tables are extracted from Wikipedia (so either source should be able to retrieve all relevant suggestions). To our knowledge there are currently no benchmarks that are more extensive.</p><p>As the WikiTables dataset was curated in 2014 as part of TabEL <ref type="bibr" target="#b1">[2]</ref>, the set of ground truth suggestions can be incomplete (for example, the table about US presidents does not include Donald Trump), or some of the values are out of date (for example, the data is from a previous census). Unfortunately, extending the ground truth tables can be fairly noisy so we chose a more conservative approach: we created a set of rough table extensions by scraping Wikipedia and we checked if any of the extra entities are among the highly ranked candidates in our model. After manual validation we removed them when reporting results. We have chosen this approach in order to fairly compare with prior art which uses the data from the 2016 version of DBpedia. This problem affects at least 67 out of 1000 tables.</p><p>A second issue with the curated test set is that the main assumption in the task definition does not necessarily hold for this dataset. A significant number of tables in the test set are not strictly relational (as defined in <ref type="bibr" target="#b37">[38]</ref>). We estimate that at least 83 tables in our dataset are not strictly relational, but a join of several relational tables. To align with prior art and the standard definition of subject suggestion, we report results relative to the first column even though more properties relate to another column.</p><p>For rapid development we created a pipeline to download Wikidata dumps and load them into a Spark distributed cluster in DataBricks that accepts between 2-11 workers (Standard DS4 v2 with 28GB Memory, 8 Cores, 1.5 DBU). The full pipeline can efficiently run in Databricks and the runtime upper-bound for the full test set is 14 minutes for entity-property linking, 52 minutes for candidate generation, 11 minutes for feature generation, 6 minutes for ranking and 58 minutes for gap filling. We believe the runtime can be significantly improved as we have not focused on optimizing the pipeline. For reproducibility we use the pre-trained PBG embeddings for Wikidata<ref type="foot" target="#foot_1">2</ref> (which includes 78 million entities), the 300 dimensional, 1 million FastText Embeddings<ref type="foot" target="#foot_2">3</ref> trained with subword information on Wikipedia 2017, UMBC web base corpus and statmt.org news dataset and the Hugging Face sentence transformer with bert-base-nli-mean-tokens <ref type="foot" target="#foot_3">4</ref> .</p><p>Particulars to reproduce Candidate Generation Experiments. In order to generate GPT-3 candidates we call the API<ref type="foot" target="#foot_4">5</ref> 100 times (with 1 sentence completions) and use temperature 0.7 (we trade stability for diversity). We generate 100 raw candidates per table out of which, on average, 73 can be linked to a Wikidata entity.</p><p>For PBG generation imposing type constraints reduces the search space by a factor of 50 at the cost of limiting maximum average recall to 93.8%. Introducing the in-table property constraint reduces the space further by a factor of 2 and improves recall slightly.</p><p>Particulars to reproduce Ranking Experiments. In our work we have experimented with the available detectors in <ref type="bibr" target="#b45">[46]</ref>. In general we found that ensembles give a performance boost of 5%-7% and in particular XGBOD <ref type="bibr" target="#b43">[44]</ref> and LSCP <ref type="bibr" target="#b44">[45]</ref> perform best. We set the contamination level between 1%-6% and as we use the output just for ranking (and not classifying), we are looking for methods that are tolerant to changes in the contamination hyperparameter. For proximity based methods we are also interested in the number of neighbours and for all the methods we have tried, the results did not change drastically by changing this hyperparameter.</p><p>For unsupervised methods, MO-GAAL <ref type="bibr" target="#b19">[20]</ref> outperformed other neural network approaches, but we found that it was not particularly stable for our set of features (level of contamination and number of subgenerators had a fair impact).</p><p>Particulars to reproduce Gap Filling Experiments. For row completion we first try to retrieve the relevant RDF triples. If that is not possible we query GPT-3 under the setup previously described for candidate generation. Using the output of the gap filling generation we proceed to try to verify by linking to web sources. We call the Bing API <ref type="foot" target="#foot_5">6</ref> restricted to news and Wikipedia articles and we retain the top 10 matches. We construct the description of the page by concatenating the name and snippet fields. In our experiments we found that using the ranking of the search engine was not fruitful.</p><p>To extend the search one can use the deep links option to return related webpages that Bing found on the webpage's website or the relatedSearch option to return a list of most related queries made by other users. For our dataset this extension did not improve results. We threshold our results by showing a fill only if the source similarity score is above 0.05.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental results</head><p>Candidate generation results. Unlike previous approaches we generate candidates from Wikidata and unfortunately the prior generation algorithms are not suitable for this KB. Categories play an important role in previous approaches <ref type="bibr" target="#b35">[36]</ref>, but for the vast majority of Wikidata entities categories are not provided and thus we cannot fairly compare approaches by a direct implementation of prior art. Recent work extends categories to Wikidata <ref type="bibr" target="#b38">[39]</ref> and in our future work we will investigate leveraging this approach.</p><p>We provide a first comparison in Table <ref type="table" target="#tab_3">1</ref> by looking at the performance of our approach versus the current state of the art in candidate generation, EntiTables <ref type="bibr" target="#b35">[36]</ref>. For KB generation we consistently improve over prior art despite searching in a significantly larger space. When introducing other sources (tables versus free text) we perform significantly better for small numbers of candidates, but our advantage reduces as we increase the number of generations. We hypothesize that the discrepancy in KB size is relevant when generating many candidates. In practice, ranking significantly more than 1000 candidates is not practical so our goal is to have quality generations within 1000 candidates.</p><p>Previous approaches only report results by generating suggestions when they consider the top-k rows as seeds. We argue that unless we treat rows as an ordered collection the generation should be order agnostic. We report average recall for 3 or 4 seeds in Table <ref type="table">2</ref> and generate 5000 candidates. We have included only 3 and 4 seeds as previous models have peak performance in this case and GPT-3's prompt requires a fair amount of information. The error margin is relatively small for PBG and prior art, but significant for GPT-3. In our study we observed that GPT-3 performs very well for tables when there is an apparent order (for example, consecutive years). Our best hypothesis is that when the seeds have a certain pattern GPT-3 confidently reproduces the pattern, which is consistent with previous studies <ref type="bibr" target="#b3">[4]</ref>. By improving the prompt we have gained a significant performance boost while shrinking the variation. When we tried the same approach with GPT-2 <ref type="foot" target="#foot_6">7</ref> we did not achieve satisfactory results. We have ran secondary experiments on an annotated 100 instances, where we noticed that GPT-3 is resilient to badly worded prompts (i.e. that are not fluent), but Stability study 3 seeds 4 seeds Entitable KB <ref type="bibr" target="#b35">[36]</ref> 73.1 +/-0.1 74.9 +/-0.08 Entitables <ref type="bibr" target="#b35">[36]</ref> 91.6 +/-0.08 92.  <ref type="table">2</ref>: Subject suggestion. Average recall performance with error-bars by choosing every 3-seed/4-seed combination in top 5 rows. We limit to an average of 5000/6000 candidates per table to recover the EntiTables generations from <ref type="bibr" target="#b34">[35]</ref>. GPT-3 base uses as prompt the table as is, GPT-3 best uses our improved prompt as shown in Figure <ref type="figure" target="#fig_0">1</ref>, GPT-2 uses the same prompt as GPT-3 best and Codex uses as prompt the table as a Pandas DataFrame alongside a simple ask.</p><p>GPT-2 predictions improved (by 8%). Based on our experimentation around various prompt modifications we conclude that this approach does not generalize well for less performant language models. We also explored using Codex<ref type="foot" target="#foot_7">8</ref> , a descendant of GPT-3 for code generation. We encoded the table as a Pandas DataFrame and included it in Codex's prompt together with the ask to add more examples. The relevance of the generations decreased, but the structure quality improved (i.e. more suggestions had the correct type). We hypothesize that as Codex is trained on a significant amount of data from Github, and most examples contain toy datasets, it loses some of its capability to directly retrieve factual information.</p><p>Ranking results. For the task of table completion we test the capabilities of the ranking function by using the candidates previously generated. When comparing the generation results between the two methods we find that in the case where we restrict candidate numbers to 5000 we have only 1122 candidates in common (on average). As we want to test the ranking function we run our outlier detection algorithms over both candidate sets in Table <ref type="table">3</ref>. As baselines we include Table2Vec <ref type="bibr" target="#b34">[35]</ref> which augments the approach from EntiTables <ref type="bibr" target="#b35">[36]</ref> with static table embeddings, as well as a new enhancement of EntiTables with a new, deep learning tabular representation TABBIE<ref type="foot" target="#foot_8">9</ref>  <ref type="bibr" target="#b11">[12]</ref>.</p><p>In our work we report results only for 3 or 4 seeds as we found that the results for 2 and 5 seeds are very similar (in line with the findings of prior art). The first two rows in the table show that by extending the baseline with TABBIE's table representation we can improve upon Table2Vec. On its own, TABBIE ranks 300k entities and has a performance of 43.4/44.1 for 3/4 row seeds. When coupling it to our approach or EntiTables we restrict the classifier to the set of candidates we are considering.</p><p>In our work we have experimented with several outlier detectors including VAEs <ref type="bibr" target="#b12">[13]</ref>, MO-GAAL <ref type="bibr" target="#b19">[20]</ref> and LSCP+LOF <ref type="bibr" target="#b44">[45]</ref>, but found they perform 5-10% worse than XGBOD <ref type="bibr" target="#b43">[44]</ref>. One common result across all detectors is that they significantly over perform for our Table <ref type="table">3</ref>: Ranking for subject suggestion. Mean average precision (MAP) for subject suggestion by taking the top 3/4 rows as seeds. We report performance on the whole ground truth set and inherit a handicap from candidate generation (by comparing performance from our candidates and En-tiTable's). candidate set compared to the one from EntiTables. We hypothesize this is caused by the way we constructed our feature space to take advantage of PBG's/GPT-3 structure which does not translate as well for DBpedia entities mapped in the Wikidata space.</p><p>As shown in Table <ref type="table">3</ref>, we achieve best results when we include TABBIE's classifier scores for our candidates as an extra feature for XGBOD. We observe that the performance increase is not significant as the added feature is highly correlated with GPT-3's generation score (a Pearson Coefficient of 0.89) and medium correlated with the distance to closest seed in PBG (a Pearson Coefficient of 0.72).</p><p>Thus, we conclude that for subject suggestion using a language model to generate candidates has a significantly bigger impact than using it to encode a table when combined with KB mining. On tables that are not relational this conclusion is unlikely to hold and we leave it to future research to investigate other types of tables. The choice of language model can be impactful and our experiments suggest that the capacity of the model, and the data the model is trained on are important.</p><p>Gap Filling. For gap filling we compare against various completion methods as shown in Table <ref type="table" target="#tab_5">4</ref>. TURL <ref type="bibr" target="#b5">[6]</ref> improves gap filling with tabular data over prior art CellAutocomplete <ref type="bibr" target="#b36">[37]</ref> and we use it as a baseline. Unlike CellAutocomplete we first try to link to a KB and if that is not possible we use auxiliary methods. By including GPT-3 suggestions our method significantly improves over the direct KB retrieval baseline. Unsurprisingly, as the tables are sourced from Wikipedia we find that 82% of GPT-3 suggestions are grounded in Wikipedia but we also find that 37% can come from other sources as well (for example, BBC). As the dataset is fairly simple we find very few cases (5%) when GPT-3 generates more than 2 viable completions and it mainly generates a single viable completion (78%). An interesting case where the GPT-3 completion fails to return reasonable candidates is for numerical cells. The recall for numerical cells is 38.4% in contrast with strings for which the recall is 82.9%. By looking at the suggestions the language model returns numerical values that are of the right type (for example, it returns years when appropriate) but are hallucinations. In this dataset most numerical cells were linked by the KB, but we think that including table candidates would be beneficial in other datasets.</p><p>To link a GPT-3 completion to an article we must firt generate a loose context from the seed rows. To do so we have experimented with bag of words overlap and standard sentence embeddings as Precision/Recall Gap Filling Method Anchor P @ 1 R @ 1 P @ 3 KB Wikidata (Wd) 97. well as sentence transformers. The first two methods had similar performance and led to 78% precision and we obtained a slight improvement by introducing transformers (79.3%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS AND FUTURE WORK</head><p>The main goal of our work was to provide a system that successfully suggests new, complete rows from large, diverse sources like Wikidata or trustworthy websources. We showed that despite metadata scarcity (i.e no headers or captions) we can start from a few examples and generate the relevant metadata to a quality that is good enough to exploit by pre-trained systems such as GPT-3 or PBG.</p><p>From our studies we conclude that candidate generation is an extremely important step and language models can play a key role in improving this space. For relational tables the gains from having a rich tabular representation (that comes at a significant cost) can be surpassed by generating a high-quality set of candidates.</p><p>Limitations. Although our work has shown great potential there are still limitations that should be addressed. The current scope, relational single subject tables, is quite restrictive and further research needs to be conducted to first extend to multi subject tables and then to mixed tables (not strictly relational). As discussed in the results section we have noticed performance drops significantly for numerical properties (including dates) and we need to improve the system for such cases. Finally the system is tailored for Wikidata, but it should be extended to other KBs as well.</p><p>Future versions. An interesting direction for future work is to create a system that holistically improves subject suggestion and row completion simultaneously, for example by creating a feedback loop. We plan to investigate this option in our system's second version. Before releasing such a system in the wild, we would like to explore how we can extend our approach to be user-centric and define new measures for success.</p><p>Unfortunately, without better datasets it is hard to validate that new approaches actually improve upon prior art. Improving current datasets is a priority for our work and we will investigate annotating a large corpora.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A ACKNOWLEDGEMENT</head><p>We would like to thank Christian Canton, Chris Oslund, Nick Wilson, Lena Yeoh and Yordan Zaykov for the insightful conversations, design jams and overall support throughout our project.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B PROPERTY LINKING</head><p>Given a set of candidate entities for the main column we try to find the most likely mapping between relational columns and Wikidata properties. We take a similar approach to <ref type="bibr" target="#b39">[40]</ref> with the exception of two problems that we address differently: property sparseness and numerical matching.</p><p>In this section we first describe our generic property linking function (Algorithm 3), and then we describe our type-specific scoring functions for numeric and string values.</p><formula xml:id="formula_1">Algorithm 3 Property linking for column index 𝑗 link(𝑇 , L, 𝑗) = P ← {𝑝 ∈ P |∃𝑒 ∈ L. 𝑝 (𝑒) ≠ ⊥} scores ← {𝑝 ↦ → 𝑖 ≤𝑚 score 𝑖 𝑗 (𝑝) | 𝑝 ∈ P} scores max ← {𝑝 ↦ → 𝑛 ∈ scores | 𝑛 = max(image(scores))} scores ≈ ← {𝑝 ↦ → 𝑛 + 𝑛 ′ | ∀𝑝 ↦ → 𝑛 ∈ scores max . 𝑛 ′ = 𝑖 ≤𝑚 if score 𝑖 𝑗 (𝑝) = 0 then score * 𝑖 𝑗 (𝑝) else 0} scores ≈ max ← {𝑝 ↦ → 𝑛 ∈ scores ≈ | 𝑛 = max(image(scores ≈ ))} if scores max = {𝑝 ↦ → 𝑛} ∧ 𝑛 ≥ threshold then return 𝑝 if scores ≈ max = {𝑝 ↦ → 𝑛} ∧ 𝑛 ≥ threshold then return 𝑝 else fail "Cannot Resolve Confidently"</formula><p>Generic Property Linking. Algorithm 3 presents our generic property linking function link(𝑇 , L, 𝑗). The function link(𝑇 , L, 𝑗) accepts as input an (𝑚, 𝑛)-table 𝑇 , linked main column L, and target column index 𝑗; the function returns the linked property for column 𝑗 or fails. We write 𝑥 ← 𝑒 to denote the assignment of the value of expression 𝑒 to identifier 𝑥.</p><p>The property linking function is implicitly parametrised by two scoring functions that assign a score to a property 𝑝 for a particular cell (𝑖, 𝑗): we write score 𝑖 𝑗 (𝑝) for the exact property score, and we write score * 𝑖 𝑗 (𝑝) for the approximate property score. The implementation of score and score * depends on the type of the column we are linking: numeric or string. The concrete implementations of these functions is described later in the section.</p><p>Function link(𝑇 , L, 𝑗) proceeds as follows. First, define P to be the set of properties such that there exists an entity in main column L with that property. Define scores to be the set of property-score (𝑝 ↦ → 𝑛) mappings where 𝑝 is in P, and 𝑛 is the sum of exact property scores for all values in the target column. Define scores max to be the set of property-score (𝑝 ↦ → 𝑛) mappings where 𝑛 is the largest score in scores. Multiple properties may share the highest score, hence we record a set. Define image(𝑀) = {𝑛 | (𝑝 ↦ → 𝑛) ∈ 𝑀 }. Values as written in the table will frequently differ from the exact value as defined in the KB, hence we also compute an approximate set of scores. Define scores ≈ to be the set of propertyscore (𝑝 ↦ → 𝑛 + 𝑛 ′ ) mappings where 𝑝 is in P, 𝑛 is the exact score, and 𝑛 ′ is the approximate adjustment. The approximate adjustment is defined as the sum of approximate property scores for all values in the target column that did not match exactly. Define scores ≈ max analogously to scores max . Finally, we determine the property link using scores max and scores ≈ max . When scores max has a unique high score (is a singleton set {𝑝 ↦ → 𝑛}), and provides sufficient coverage (determined by threshold), we link using 𝑝. When that fails, we apply the same process to scores ≈ max , and if approximate matching fails, we return no match. Numeric Properties. Matching numerical-valued columns to properties is an interesting problem as standard approaches for string matching (like fuzzy matching) are not as effective. For example, consider a column about the heights of athletes. As these values can vary between measurements and various sources could report different values, linking directly to a KB would not be possible.</p><p>To address such challenges if direct matching methods are not fruitful (i.e. we cannot directly match within unit conversions) we consider the values in the columns holistically and we compare their statistics (for this paper we only consider ranges) with the statistics of the numerical properties for a given class of entities. For instance if we identify that the main column has type "athlete" we check if the values in the column match any of the numerical property values in the KB that are representative for athletes. If that is not the case we compare the statistics of the values in the column against reasonable statistics for numerical properties of athletes (e.g. if the range of our data is within 102-210 it is consistent with heights for athletes).</p><p>Formally, for numeric properties we introduce the concept of characteristic ranges. Write C 𝑝;𝜏 for the characteristic range of property 𝑝 for type 𝜏, defined as C 𝑝;𝜏 = range(characteristic(E 𝑝;𝜏 )), where E 𝑝;𝜏 = {𝑝 (𝑒)|∀𝑒 ∈ E. type (𝑒) = 𝜏, 𝑝 (𝑒) ≠ ⊥} and p is a numeric property.</p><p>The characteristic function removes the outliers from the set by using the Isolation Forest Algorithm <ref type="bibr" target="#b17">[18]</ref>. The range function returns upper and lower bounds for a set of numbers.</p><p>We now define a property scoring function for a numeric cell value 𝑡 𝑖,𝑗 in table 𝑇 , given linked main column L which is a column vector of entities. First, write 1 for the indicator function that maps true to 1 and false to 0. Define score 𝑖 𝑗 (𝑝) = 1(conv (𝑝 (L 𝑖 ) = 𝑡 𝑖,𝑗 )).</p><p>We say that a cell value (𝑡 𝑖 𝑗 ) is consistent with the property value of the linked entity in the same row (L 𝑖 ) if their values are equal within unit conversion (conv). Define score * 𝑖 𝑗 (𝑝) = 1(∃𝜏. conv (𝑡 𝑖,𝑗 ) ∈ C 𝑝;𝜏 ∧ type (L 𝑖 ) = 𝜏). We say that a cell value (𝑡 𝑖 𝑗 ) is approximately consistent with the property value of the linked entity in the same row (L 𝑖 ) if their values are within the characteristic range, modulo unit conversion (conv).</p><p>String Properties. Wikidata has significant property sparseness since users are not obliged to include all properties when adding entities. This makes assigning properties to columns more challenging as direct or fuzzy string-matching can be insufficient. For example, if a column is about the eye colour of athletes we are likely to struggle to identify the property as a significant amount of athlete entities do not have eye colour as a property.</p><p>We want to address the case where we find that at least one value in the column matches to a property value, but other entities do not have that property and thus we cannot confidently assign the column. Our method estimates how likely it is that the property is missing (but should be present) for the other entities by checking if similar entities have it. In our previous example if most athletes in our table do not have the property eye colour, but similar athletes to them do, we can increase our confidence that eye colour is the correct match for our column.</p><p>We define a property scoring function for a string cell value 𝑡 𝑖,𝑗 in table 𝑇 , given linked main column L. Define score 𝑖 𝑗 (𝑝) = 1(𝑝(L 𝑖 ) ≈ 𝑡 𝑖,𝑗 ). We say that a cell value (𝑡 𝑖 𝑗 ) is consistent with the property value of the linked entity in the same row (L 𝑖 ) if their values are equal within fuzzy matching, written ≈ (similarly to <ref type="bibr" target="#b39">[40]</ref>). Define score * 𝑖 𝑗 (𝑝) = arg max 𝑝 ∈𝑝𝑟𝑒𝑑 max 𝑒 ∈ E 1𝑖 score(𝑝, 𝑒). We estimate how likely it is that the property is missing. We do this by looking at the properties of the 𝑛 nearest neighbors in PBG that share the type of 𝑒.</p><p>Similar to Word2Vec, PBG generates multi-relation embeddings by maximizing the (transformed) similarity score for existing RDF triples while minimizing it for non-existent ones. The similarity is measured by cosine distance (TransE) or dot product distance (RESCAL, DistMult, ComplEx) over transformed vectors for the source and object. The transformations considered are linear transformations (RESCAL), translations (TransE) and complex multiplication (DistMult, ComplEx).</p><p>Thus, for TransE embeddings we compute a score to estimate what is the likelihood that entity e is missing property p as score(𝑝, 𝑒) = 𝑛 𝑠𝑖𝑚(𝑒 𝑖 , 𝑒) (1(𝑝 (𝑒 𝑖 ) ≠ ⊥) − 1(𝑝(𝑒 𝑖 ) = ⊥)), where 𝑠𝑖𝑚(𝑒, 𝑒 𝑖 ) = 1 − 𝐿 2 (𝑒,𝑒 𝑖 ) max( {𝐿 2 (𝑒,𝑒 𝑗 ) | 𝑗 &lt;𝑛) }) and where the operator 𝑓 acting on function 𝑓 is defined as 𝑓 (𝑥) = min(max(0, 𝑓 (𝑥)), 1).</p><p>Entity-Property linking results. In our work we extend a previous system LinkingPark that was recently externally evaluated in the SemTab Competition. The system ranked 2nd overall performing particularly well for the main entity type annotation task (CTA) 10 . By enhancing the prior pipeline with the new property linking module we improve performance slightly over the SemTab dataset (unfortunately for this task simple methods like direct linking achieve around 95% precision). For Rounds 1-3 we have an up to 1% improvement over the base model and for Round 4 a 1.2% improvement. The main performance difference can be seen for the WikiTables dataset. By including the new module we improve coverage from 38% to 44%. This dataset does not have ground truth available for KB linking but we can infer from the gap filling performance via RDFs that precision is 98.7%.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Row Completion in a Nutshell</figDesc><graphic coords="1,347.99,313.36,180.19,51.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Row completion pipeline. In Step 1 we link the table to Wikidata, find the in-table properties (Step 1c), and the possible types (Step 1a) and corresponding Q-numbers for the subject entities (Step 1b). To retrieve other subject entities (Kendrick Lamar) we rank candidates generated via PBG' (Step 2a) and GPT-3 (Step 2b). To fill in the remaining relevant information we either suggest GPT-3 verified candidates (Step 3a) or we retrieve directly from Wikidata (Step 3b).</figDesc><graphic coords="4,53.80,83.69,504.40,272.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>1,1 , ..., 𝑡 𝑚,𝑛 }, where 𝑡 ranges over text values. A table is a matrix of text cells of 𝑚 rows and 𝑛 columns. Write 𝑇 [𝑖, * ] for row 𝑖 in table 𝑇 ; write 𝑇 [ * ,𝑗 ] for column 𝑗 in table 𝑇 . We do not assume availability of metadata beyond the table contents, such as column headers or types.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>1 , the same notation applies to other knowledge bases like DBpedia and Freebase, etc. Definition 1. Given table 𝑇 and entity set E, table entity linking aims to link entity mention 𝑚 𝑘 in a specific cell 𝑡 𝑖,𝑗 of table 𝑇 to its referent entity in E, or predict there is no corresponding entity in the KB, denoted ⊥. In Figure 2, 1b displays linked entities. Definition 2. Given table 𝑇 and property set P, property linking associates a pair of columns, indexed by 𝑠 and 𝑜, with a property 𝑝 ∈ P such that property 𝑝 relates 𝑇 [ * ,𝑠 ] and 𝑇 [ * ,𝑜 ] component-wise: 𝑝 (𝑡 𝑖,𝑠 ) = 𝑡 𝑖,𝑜 for all 𝑖. In Figure 2, 1c displays linked properties.</figDesc><table /><note>Definition 3. Let 𝐸 = (𝑒 1,1 , ..., 𝑒 𝑛,1</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Algorithm 2 Ranked Gap Filling for cell (𝑖, 𝑗) in linked table L. rankValues(𝑠, 𝑗, L, 𝑝?) = context ← contextOfSeeds({bing(L [𝑖,1] , 𝑝, L [𝑖,𝑗 ] ) | 𝑖 ≤ rows(L)}) scoredValues ← ∅ for i in sample o ← GPT3(toPrompt(L [ * ,1] • L [ * ,𝑗 ] )) snippets ← bing(𝑠, 𝑝, 𝑜) best ← argmax 𝑥 ∈snippets score(𝑥, context) if best score &gt; threshold then scoredValues ← scoredValues ∪ {(𝑜, best text )} return scoredValues gapFill(𝑖, 𝑗, L) = s ← L [𝑖,1] , p ← propertyLinks(L, 𝑗) if ⟨𝑠, 𝑝, 𝑜⟩ ∈ KB then return {(𝑜, ⟨𝑠, 𝑝, 𝑜⟩)} 3b return rankValues(𝑠, 𝑗, L, 𝑝) 3a</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Candidate generation for subject suggestion. Average recall for generations from top 3 seeds. For 1000 generations we observe a significant gain over prior art. The difference between PBG versions is not significant.</figDesc><table><row><cell cols="4">Average Recall per nr candidates generated</cell></row><row><cell>Method</cell><cell>Anchor</cell><cell cols="2"># Candidates</cell></row><row><cell></cell><cell></cell><cell>1000</cell><cell>10000</cell></row><row><cell>EntiTables KB [36]</cell><cell>DBpedia</cell><cell>64.1</cell><cell>78.8</cell></row><row><cell>Entitables [36]</cell><cell>+ tables</cell><cell>78.4</cell><cell>94.0</cell></row><row><cell cols="2">PBG TransE/ComplexE Wikidata</cell><cell cols="2">72.2/72.4 88.1/88.2</cell></row><row><cell cols="4">+ GPT-3 (Our method) + free text 87.4/87.5 94.5/94.7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Gap Filling. We extend prior methods by including candidates that are verified in news or Wikipedia articles and improvements in both recall and precision are significant (around 15%). The test set includes all cells, except the subject column, for non-seed rows in the 1000 WikiTables dataset.</figDesc><table><row><cell>8</cell><cell>37.2</cell><cell>97.8</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://www.wikidata.org/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">https://github.com/facebookresearch/PyTorch-BigGraph</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">https://fasttext.cc/docs/en/english-vectors.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">https://huggingface.co/sentence-transformers/bert-base-nli-mean-tokens</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">https://beta.openai.com/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5">https://www.microsoft.com/en-us/bing/apis/bing-web-search-api</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6">https://huggingface.co/gpt2</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7">https://openai.com/blog/openai-codex/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8">using the implementation found at https://github.com/SFIG611/tabbie</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean average precision for subject suggestion Method</head><p>Our candidates EntiTables 3 4 3 4 Table2Vec <ref type="bibr" target="#b34">[35]</ref> 55.8 56.7 64.0 65.2 EntiTables <ref type="bibr" target="#b35">[36]</ref> + TABBIE <ref type="bibr" target="#b11">[12]</ref> 63.2 63.7 66.0 66.2 XGBOD (Our method) 72.4 72.6 59.9 60.2 XGBOD + TABBIE <ref type="bibr" target="#b11">[12]</ref> 72.8 72.9 64.9 64.9</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">DBpedia: A nucleus for a web of open data</title>
		<author>
			<persName><forename type="first">Sören</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgi</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Ives</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The semantic web</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="722" to="735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">TabEL: Entity Linking in Web Tables</title>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Sekhar Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thanapon</forename><surname>Noraset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web -ISWC</title>
				<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<publisher>Transactions of the Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tom B Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><surname>Askell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14165</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiming</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henrique</forename><surname>Ponde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harrison</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yura</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raul</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heidy</forename><surname>Khlaaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brooke</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alethea</forename><surname>Power ; Lukasz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felipe</forename><forename type="middle">Petroski</forename><surname>Tillet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">W</forename><surname>Such</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Cummings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fotios</forename><surname>Plappert</surname></persName>
		</author>
		<author>
			<persName><surname>Chantzis</surname></persName>
		</author>
		<idno>ArXiv abs/2107.03374</idno>
		<ptr target="https://www.cs.ox.ac.uk/isg/challenges/sem-tab/2020/results.html" />
		<editor>Nichol, Igor Babuschkin, S. Arun Balaji, Shantanu Jain, Andrew Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew M. Knight</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>Sam McCandlish, Ilya Sutskever</publisher>
			<biblScope unit="volume">10</biblScope>
			<pubPlace>Elizabeth Barnes, Ariel Herbert-Voss, William H. Guss, Alex; Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei</pubPlace>
		</imprint>
	</monogr>
	<note>and Wojciech Zaremba. 2021. Evaluating Large Language Models Trained on Code</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alyssa</forename><surname>Lees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">You</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cong</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.14806</idno>
		<title level="m">TURL: Table Understanding through Representation Learning</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Julian</forename><surname>Eberius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maik</forename><surname>Thiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katrin</forename><surname>Braunschweig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Lehner</surname></persName>
		</author>
		<title level="m">Top-k Entity Augmentation Using Consistent Set Covering</title>
				<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bayesian sets</title>
		<author>
			<persName><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><forename type="middle">A</forename><surname>Heller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Answering table augmentation queries from unstructured lists on the web</title>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
				<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Seisa: set expansion by iterative similarity aggregation</title>
		<author>
			<persName><forename type="first">Yeye</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Xin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on World wide web</title>
				<meeting>the 20th international conference on World wide web</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Language Models as Knowledge Bases: On Entity Representations, Storage Capacity, and Paraphrased Queries</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Heinzerling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">TABBIE: Pretrained Representations of Tabular Data</title>
		<author>
			<persName><forename type="first">Hiroshi</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dung</forename><surname>Thai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varun</forename><surname>Manjunatha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter</title>
				<meeting>the 2021 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Auto-Encoding Variational Bayes. CoRR abs/1312</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page">6114</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Ontological modelling in Wikidata. Talk at Workshop on Ontology Design and Patterns</title>
		<author>
			<persName><forename type="first">Markus</forename><surname>Krötzsch</surname></persName>
		</author>
		<ptr target="https://iccl.inf.tu-dresden.de/w/images/e/ed/Ontology_modelling_Wikidata_Markus_Kroetzsch_WOP2018.pdf" />
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note>held at ISWC 2018. Available at</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Guy</forename><surname>Kushilevitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaul</forename><surname>Markovitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.01063</idno>
		<title level="m">A Two-Stage Masked LM Method for Term Set Expansion</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Language Models as Fact Checkers?</title>
		<author>
			<persName><forename type="first">Nayeon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Belinda</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sinong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><surname>Tau Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madian</forename><surname>Khabsa</surname></persName>
		</author>
		<idno>ArXiv abs/2006.04102</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">PyTorch-BigGraph: A Large-scale Graph Embedding System</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Ledell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothée</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wehrstedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><surname>Peysakhovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Isolation-Based Anomaly Detection</title>
		<author>
			<persName><forename type="first">Tony</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><forename type="middle">Ming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi-Hua</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhe</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinlan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroaki</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing</title>
				<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Generative Adversarial Active Learning for Unsupervised Outlier Detection</title>
		<author>
			<persName><forename type="first">Yezheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanchun</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianshan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Building Top-k Consistent Results for Web Table Augmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 14th Web Information Systems and Applications Conference (WISA)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Choosing Better Seeds for Entity Set Expansion by Leveraging Wikipedia Semantic Knowledge</title>
		<author>
			<persName><forename type="first">Zhenyu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition -Chinese Conference, CCPR 2012</title>
				<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-09-24">2012. September 24-26, 2012</date>
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Matching HTML Tables to DBpedia</title>
		<author>
			<persName><forename type="first">Dominique</forename><surname>Ritze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Lehmberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WIMS &apos;15</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Egoset: Exploiting word ego-networks and user-generated ontology for multifaceted set expansion</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eytan</forename><surname>Adar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth ACM international conference on Web search and data mining</title>
				<meeting>the Ninth ACM international conference on Web search and data mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">More like these&quot; growing entity classes from seeds</title>
		<author>
			<persName><forename type="first">Luis</forename><surname>Sarmento</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentin</forename><surname>Jijkuon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eugenio</forename><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixteenth ACM conference on Conference on information and knowledge management</title>
				<meeting>the sixteenth ACM conference on Conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Setexpan: Corpus-based set expansion via context feature selection and rank ensemble</title>
		<author>
			<persName><forename type="first">Jiaming</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeqiu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongming</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingbo</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">General Table Completion using a Bayesian Nonparametric Model</title>
		<author>
			<persName><forename type="first">Isabel</forename><surname>Valera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems</title>
				<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-12-08">2014. 2014. December 8-13 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Wikidata: a free collaborative knowledgebase</title>
		<author>
			<persName><forename type="first">Denny</forename><surname>Vrandečić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Krötzsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="78" to="85" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Concept expansion using web tables</title>
		<author>
			<persName><forename type="first">Chi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaushik</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeye</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kris</forename><surname>Ganjam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhimin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">A</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web</title>
				<meeting>the 24th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">PatternRank+NN: A Ranking Framework Bringing User Behaviors into Entity Set Expansion from Web Search Queries</title>
		<author>
			<persName><forename type="first">Zhijun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cuiping</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Web</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">End-to-End Bootstrapping Neural Network for Entity Set Expansion</title>
		<author>
			<persName><forename type="first">Lingyong</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning to Bootstrap for Entity Set Expansion</title>
		<author>
			<persName><forename type="first">Lingyong</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP-IJCNLP</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data</title>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Corpus-based Set Expansion with Lexical Features and Distributed Representations</title>
		<author>
			<persName><forename type="first">Puxuan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiqi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Razieh</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
				<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Table2Vec: Neural Word and Entity Embeddings for Table Population and Retrieval</title>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
				<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Entitables: Smart assistance for entityfocused tables</title>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
				<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Auto-Completion for Data Cells in Relational Tables</title>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Web Table Extraction, Retrieval, and Augmentation: A Survey</title>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Intell. Syst. Technol</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Generating Categories for Sets of Entities</title>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Novel Entity Discovery Web Tables</title>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edgar</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ridho</forename><surname>Reinanda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference</title>
				<meeting>The Web Conference</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Entity Set Expansion via Knowledge Graphs</title>
		<author>
			<persName><forename type="first">Xiangling</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yueguo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyong</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
				<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Shinjuku, Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-08-07">2017. August 7-11, 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Empower Entity Set Expansion via Language Model Probing</title>
		<author>
			<persName><forename type="first">Yunyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaming</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingbo</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020</title>
				<meeting>the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-07-05">2020. July 5-10, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A Joint Model for Entity Set Expansion and Attribute Extraction from Web Search Queries</title>
		<author>
			<persName><forename type="first">Zhenzhong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence</title>
				<meeting>the Thirtieth AAAI Conference on Artificial Intelligence<address><addrLine>Phoenix, Arizona, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-02-12">2016. February 12-17, 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">XGBOD: Improving Supervised Outlier Detection with Unsupervised Representation Learning</title>
		<author>
			<persName><forename type="first">Yue</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Hryniewicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Neural Networks (IJCNN)</title>
				<imprint>
			<date type="published" when="2018">2018. 2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">LSCP: Locally Selective Combination in Parallel Outlier Ensembles</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Yue Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zain</forename><surname>Hryniewicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Nasrullah</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">PyOD: A Python Toolbox for Scalable Outlier Detection</title>
		<author>
			<persName><forename type="first">Yue</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zain</forename><surname>Nasrullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Entity Set Expansion with Meta Path in Knowledge Graph</title>
		<author>
			<persName><forename type="first">Yuyan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoli</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Knowledge Discovery and Data Mining -21st Pacific-Asia Conference</title>
				<meeting><address><addrLine>Jeju, South Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-05-23">2017. 2017. May 23-26, 2017</date>
		</imprint>
	</monogr>
	<note>Proceedings, Part I</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Factual Probing Is [MASK]: Learning vs. Learning to Recall</title>
		<author>
			<persName><forename type="first">Zexuan</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter</title>
				<meeting>the 2021 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
