<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Contents lists available at ScienceDirect</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-10-13">13 October 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Neural</forename><surname>Networks</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Istituto Dalle Molle di Studi sull&apos;Intelligenza Artificiale</orgName>
								<orgName type="institution" key="instit1">The Swiss AI Lab IDSIA</orgName>
								<orgName type="institution" key="instit2">University of Lugano &amp; SUPSI</orgName>
								<address>
									<addrLine>Galleria 2</addrLine>
									<postCode>6928</postCode>
									<settlement>Manno-Lugano</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Istituto Dalle Molle di Studi sull&apos;Intelligenza Artificiale</orgName>
								<orgName type="institution" key="instit1">The Swiss AI Lab IDSIA</orgName>
								<orgName type="institution" key="instit2">University of Lugano &amp; SUPSI</orgName>
								<address>
									<addrLine>Galleria 2</addrLine>
									<postCode>6928</postCode>
									<settlement>Manno-Lugano</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Contents lists available at ScienceDirect</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-10-13">13 October 2014</date>
						</imprint>
					</monogr>
					<idno type="MD5">96FB29A184C9C9EC3B4B2931068FFFCD</idno>
					<idno type="DOI">10.1016/j.neunet.2014.09.003</idno>
					<note type="submission">Received 2 May 2014 Received in revised form 12 September 2014 Accepted 14 September 2014</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2024-05-06T00:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Deep learning Supervised learning Unsupervised learning Reinforcement learning Evolutionary computation</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning &amp; evolutionary computation, and indirect search for short programs encoding deep and large networks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preface</head><p>This is the preprint of an invited Deep Learning (DL) overview. One of its goals is to assign credit to those who contributed to the present state of the art. I acknowledge the limitations of attempting to achieve this goal. The DL research community itself may be viewed as a continually evolving, deep network of scientists who have influenced each other in complex ways. Starting from recent DL results, I tried to trace back the origins of relevant ideas through the past half century and beyond, sometimes using ''local search'' to follow citations of citations backwards in time. Since not all DL publications properly acknowledge earlier relevant work, additional global search strategies were employed, aided by consulting numerous neural network experts. As a result, the present preprint mostly consists of references. Nevertheless, through an expert selection bias I may have missed important work. A related bias was surely introduced by my special familiarity with the work of my own DL research group in the past quarter-century. For these reasons, this work should be viewed as merely a snapshot of an ongoing credit assignment process. To help improve it, please do not hesitate to send corrections and suggestions to juergen@idsia.ch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction to Deep Learning (DL) in Neural Networks (NNs)</head><p>Which modifiable components of a learning system are responsible for its success or failure? What changes to them improve performance? This has been called the fundamental credit assignment problem <ref type="bibr" target="#b492">(Minsky, 1963)</ref>. There are general credit assignment methods for universal problem solvers that are time-optimal in various theoretical senses <ref type="bibr">(Section 6.8</ref>). The present survey, however, will focus on the narrower, but now commercially important, subfield of Deep <ref type="bibr">Learning (DL)</ref> in Artificial Neural Networks <ref type="bibr">(NNs)</ref>.</p><p>A standard neural network (NN) consists of many simple, connected processors called neurons, each producing a sequence of real-valued activations. Input neurons get activated through sensors perceiving the environment, other neurons get activated through weighted connections from previously active neurons (details in Section 2). Some neurons may influence the environment by triggering actions. Learning or credit assignment is about finding weights that make the NN exhibit desired behavior, such as driving a car. Depending on the problem and how the neurons are connected, such behavior may require long causal chains of computational stages (Section 3), where each stage transforms (often in a non-linear way) the aggregate activation of the network. Deep Learning is about accurately assigning credit across many such stages.</p><p>Shallow NN-like models with few such stages have been around for many decades if not centuries (Section 5.1). Models with several successive nonlinear layers of neurons date back at least to the 1960s (Section 5.3) and 1970s <ref type="bibr">(Section 5.5</ref>). An efficient gradient descent method for teacher-based Supervised <ref type="bibr">Learning (SL)</ref> in discrete, differentiable networks of arbitrary depth called backpropagation (BP) was developed in the 1960s and 1970s, and applied to NNs in 1981 (Section 5.5). BP-based training of deep NNs with many layers, however, had been found to be difficult in practice by the late 1980s (Section 5.6), and had become an explicit research subject by the early 1990s (Section 5.9). DL became practically feasible to some extent through the help of Unsupervised Learning (UL), e.g., <ref type="bibr">Section 5.10 (1991)</ref>, <ref type="bibr">Section 5.15 (2006)</ref>. The 1990s and 2000s also saw many improvements of purely supervised DL (Section 5). In the new millennium, deep NNs have finally attracted wide-spread attention, mainly by outperforming alternative machine learning methods such as kernel machines <ref type="bibr" target="#b672">(Schölkopf, Burges, &amp; Smola, 1998;</ref><ref type="bibr" target="#b758">Vapnik, 1995)</ref> in numerous important applications. In fact, since 2009, supervised deep NNs have won many official international pattern recognition competitions (e.g., <ref type="bibr">Sections 5.17,</ref><ref type="bibr">5.19,</ref><ref type="bibr">5.21 and 5.22)</ref>, achieving the first superhuman visual pattern recognition results in limited domains <ref type="bibr">(Section 5.19, 2011)</ref>. Deep NNs also have become relevant for the more general field of Reinforcement <ref type="bibr">Learning (RL)</ref> where there is no supervising teacher (Section 6).</p><p>Both feedforward (acyclic) NNs (FNNs) and recurrent (cyclic) NNs (RNNs) have won contests <ref type="bibr">(Sections 5.12,</ref><ref type="bibr">5.14,</ref><ref type="bibr">5.17,</ref><ref type="bibr">5.19,</ref><ref type="bibr">5.21,</ref><ref type="bibr">5.22)</ref>. In a sense, RNNs are the deepest of all NNs (Section 3)they are general computers more powerful than FNNs, and can in principle create and process memories of arbitrary sequences of input patterns (e.g., <ref type="bibr" target="#b644">Schmidhuber, 1990a;</ref><ref type="bibr" target="#b693">Siegelmann &amp; Sontag, 1991)</ref>. Unlike traditional methods for automatic sequential program synthesis (e.g., <ref type="bibr" target="#b66">Balzer, 1985;</ref><ref type="bibr" target="#b164">Deville &amp; Lau, 1994</ref> Winner-Take-All 1986; <ref type="bibr" target="#b766">Waldinger &amp; Lee, 1969)</ref>, RNNs can learn programs that mix sequential and parallel information processing in a natural and efficient way, exploiting the massive parallelism viewed as crucial for sustaining the rapid decline of computation cost observed over the past 75 years. The rest of this paper is structured as follows. Section 2 introduces a compact, event-oriented notation that is simple yet general enough to accommodate both FNNs and RNNs. Section 3 introduces the concept of Credit Assignment Paths (CAPs) to measure whether learning in a given NN application is of the deep or shallow type. Section 4 lists recurring themes of DL in SL, UL, and RL. Section 5 focuses on SL and UL, and on how UL can facilitate SL, although pure SL has become dominant in recent competitions ). Section 5 is arranged in a historical timeline format with subsections on important inspirations and technical contributions. Section 6 on deep RL discusses traditional Dynamic Programming (DP)-based RL combined with gradient-based search techniques for SL or UL in deep NNs, as well as general methods for direct and indirect search in the weight space of deep FNNs and RNNs, including successful policy gradient and evolutionary methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Event-oriented notation for activation spreading in NNs</head><p>Throughout this paper, let i, j, k, t, p, q, r denote positive integer variables assuming ranges implicit in the given contexts. Let n, m, T denote positive integer constants.</p><p>An NN's topology may change over time (e.g., <ref type="bibr">Sections 5.3,</ref><ref type="bibr">5.6.3)</ref>. At any given moment, it can be described as a finite subset of units (or nodes or neurons) N = {u 1 , u 2 , . . . , } and a finite set H ⊆ N × N of directed edges or connections between nodes. FNNs are acyclic graphs, RNNs cyclic. The first (input) layer is the set of input units, a subset of N. In FNNs, the kth layer (k &gt; 1) is the set of all nodes u ∈ N such that there is an edge path of length k − 1 (but no longer path) between some input unit and u. There may be shortcut connections between distant layers. In sequenceprocessing, fully connected RNNs, all units have connections to all non-input units.</p><p>The NN's behavior or program is determined by a set of realvalued, possibly modifiable, parameters or weights w i (i = 1, . . . , n). We now focus on a single finite episode or epoch of information processing and activation spreading, without learning through weight changes. The following slightly unconventional notation is designed to compactly describe what is happening during the runtime of the system.</p><p>During an episode, there is a partially causal sequence x t (t = 1, . . . , T ) of real values that I call events. Each x t is either an input set by the environment, or the activation of a unit that may directly depend on other x k (k &lt; t) through a current NN topologydependent set in t of indices k representing incoming causal connections or links. Let the function v encode topology information and map such event index pairs (k, t) to weight indices. For example, in the non-input case we may have x t = f t (net t ) with real-valued net t =  k∈in t x k w v(k,t) (additive case) or net t =  k∈in t x k w v(k,t) (multiplicative case), where f t is a typically nonlinear real-valued activation function such as tanh. In many recent competition-winning NNs <ref type="bibr">(Sections 5.19,</ref><ref type="bibr">5.21,</ref><ref type="bibr">5.22)</ref> there also are events of the type x t = max k∈in t (x k ); some network types may also use complex polynomial activation functions (Section 5.3). x t may directly affect certain x k (k &gt; t) through outgoing connections or links represented through a current set out t of indices k with t ∈ in k . Some of the non-input events are called output events.</p><p>Note that many of the x t may refer to different, time-varying activations of the same unit in sequence-processing RNNs (e.g., <ref type="bibr">Williams, 1989 ''unfolding in time'')</ref>, or also in FNNs sequentially exposed to time-varying input patterns of a large training set encoded as input events. During an episode, the same weight may get reused over and over again in topology-dependent ways, e.g., in RNNs, or in convolutional NNs <ref type="bibr">(Sections 5.4 and 5.8)</ref>. I call this weight sharing across space and/or time. Weight sharing may greatly reduce the NN's descriptive complexity, which is the number of bits of information required to describe the NN (Section 4.4).</p><p>In Supervised Learning (SL), certain NN output events x t may be associated with teacher-given, real-valued labels or targets d t yielding errors e t , e.g., e t = 1/2(x t − d t ) 2 . A typical goal of supervised NN training is to find weights that yield episodes with small total error E, the sum of all such e t . The hope is that the NN will generalize well in later episodes, causing only small errors on previously unseen sequences of input events. Many alternative error functions for SL and UL are possible.</p><p>SL assumes that input events are independent of earlier output events (which may affect the environment through actions causing subsequent perceptions). This assumption does not hold in the broader fields of Sequential Decision Making and Reinforcement Learning (RL) <ref type="bibr" target="#b323">(Hutter, 2005;</ref><ref type="bibr" target="#b360">Kaelbling, Littman, &amp; Moore, 1996;</ref><ref type="bibr" target="#b729">Sutton &amp; Barto, 1998;</ref><ref type="bibr" target="#b801">Wiering &amp; van Otterlo, 2012</ref>) (Section 6). In RL, some of the input events may encode real-valued reward signals given by the environment, and a typical goal is to find weights that yield episodes with a high sum of reward signals, through sequences of appropriate output actions.</p><p>Section 5.5 will use the notation above to compactly describe a central algorithm of DL, namely, backpropagation (BP) for supervised weight-sharing FNNs and RNNs. (FNNs may be viewed as RNNs with certain fixed zero weights.) Section 6 will address the more general RL case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Depth of Credit Assignment Paths (CAPs) and of problems</head><p>To measure whether credit assignment in a given NN application is of the deep or shallow type, I introduce the concept of Credit Assignment Paths or CAPs, which are chains of possibly causal links between the events of Section 2, e.g., from input through hidden to output layers in FNNs, or through transformations over time in RNNs.</p><p>Let us first focus on SL. Consider two events x p and x q (1 ≤ p &lt; q ≤ T ). Depending on the application, they may have a Potential Direct Causal Connection (PDCC) expressed by the Boolean predicate pdcc(p, q), which is true if and only if p ∈ in q . Then the 2element list (p, q) is defined to be a CAP (a minimal one) from p to q. A learning algorithm may be allowed to change w v(p,q) to improve performance in future episodes.</p><p>More general, possibly indirect, Potential Causal Connections (PCC) are expressed by the recursively defined Boolean predicate pcc(p, q), which in the SL case is true only if pdcc(p, q), or if pcc(p, k) for some k and pdcc(k, q). In the latter case, appending q to any CAP from p to k yields a CAP from p to q (this is a recursive definition, too). The set of such CAPs may be large but is finite. Note that the same weight may affect many different PDCCs between successive events listed by a given CAP, e.g., in the case of RNNs, or weight-sharing FNNs.</p><p>Suppose a CAP has the form <ref type="bibr">(. . . , k, t, . . . , q)</ref>, where k and t (possibly t = q) are the first successive elements with modifiable w v(k,t) . Then the length of the suffix list (t, . . . , q) is called the CAP's depth (which is 0 if there are no modifiable links at all). This depth limits how far backwards credit assignment can move down the causal chain to find a modifiable weight. 1   Suppose an episode and its event sequence x 1 , . . . , x T satisfy a computable criterion used to decide whether a given problem has been solved (e.g., total error E below some threshold). Then the set 1 An alternative would be to count only modifiable links when measuring depth.</p><p>In many typical NN applications this would not make a difference, but in some it would, e.g., Section 6.1. of used weights is called a solution to the problem, and the depth of the deepest CAP within the sequence is called the solution depth. There may be other solutions (yielding different event sequences) with different depths. Given some fixed NN topology, the smallest depth of any solution is called the problem depth.</p><p>Sometimes we also speak of the depth of an architecture: SL FNNs with fixed topology imply a problem-independent maximal problem depth bounded by the number of non-input layers. Certain SL RNNs with fixed weights for all connections except those to output units <ref type="bibr" target="#b342">(Jaeger, 2001</ref><ref type="bibr" target="#b343">(Jaeger, , 2004;;</ref><ref type="bibr" target="#b457">Maass, Natschläger, &amp; Markram, 2002;</ref><ref type="bibr" target="#b676">Schrauwen, Verstraeten, &amp; Van Campenhout, 2007)</ref> have a maximal problem depth of 1, because only the final links in the corresponding CAPs are modifiable. In general, however, RNNs may learn to solve problems of potentially unlimited depth.</p><p>Note that the definitions above are solely based on the depths of causal chains, and agnostic to the temporal distance between events. For example, shallow FNNs perceiving large ''time windows'' of input events may correctly classify long input sequences through appropriate output events, and thus solve shallow problems involving long time lags between relevant events.</p><p>At which problem depth does Shallow Learning end, and Deep Learning begin? Discussions with DL experts have not yet yielded a conclusive response to this question. Instead of committing myself to a precise answer, let me just define for the purposes of this overview: problems of depth &gt;10 require Very Deep Learning.</p><p>The difficulty of a problem may have little to do with its depth. Some NNs can quickly learn to solve certain deep problems, e.g., through random weight guessing (Section 5.9) or other types of direct search (Section 6.6) or indirect search (Section 6.7) in weight space, or through training an NN first on shallow problems whose solutions may then generalize to deep problems, or through collapsing sequences of (non)linear operations into a single (non)linear operation (but see an analysis of non-trivial aspects of deep linear networks, <ref type="bibr">Baldi &amp; Hornik, 1995, Section B)</ref>. In general, however, finding an NN that precisely models a given training set is an NP-complete problem <ref type="bibr">(Blum &amp; Rivest, 1992;</ref><ref type="bibr" target="#b357">Judd, 1990)</ref>, also in the case of deep NNs <ref type="bibr" target="#b162">(de Souto, Souto, &amp; Oliveira, 1999;</ref><ref type="bibr" target="#b695">Síma, 1994;</ref><ref type="bibr" target="#b814">Windisch, 2005)</ref>; compare a survey of negative results <ref type="bibr">(Síma, 2002, Section 1)</ref>.</p><p>Above we have focused on SL. In the more general case of RL in unknown environments, pcc(p, q) is also true if x p is an output event and x q any later input event-any action may affect the environment and thus any later perception. (In the real world, the environment may even influence non-input events computed on a physical hardware entangled with the entire universe, but this is ignored here.) It is possible to model and replace such unmodifiable environmental PCCs through a part of the NN that has already learned to predict (through some of its units) input events (including reward signals) from former input events and actions (Section 6.1). Its weights are frozen, but can help to assign credit to other, still modifiable weights used to compute actions (Section 6.1). This approach may lead to very deep CAPs though. Some DL research is about automatically rephrasing problems such that their depth is reduced (Section 4). In particular, sometimes UL is used to make SL problems less deep, e.g., Section 5.10. Often Dynamic Programming (Section 4.1) is used to facilitate certain traditional RL problems, e.g., Section 6.2. Section 5 focuses on CAPs for SL, Section 6 on the more complex case of RL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Recurring themes of Deep Learning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Dynamic programming for Supervised/Reinforcement Learning (SL/RL)</head><p>One recurring theme of DL is Dynamic Programming (DP) <ref type="bibr" target="#b92">(Bellman, 1957)</ref>, which can help to facilitate credit assignment under certain assumptions. For example, in SL NNs, backpropagation itself can be viewed as a DP-derived method (Section 5.5). In traditional RL based on strong Markovian assumptions, DP-derived methods can help to greatly reduce problem depth (Section 6.2). DP algorithms are also essential for systems that combine concepts of NNs and graphical models, such as Hidden Markov Models (HMMs) <ref type="bibr" target="#b76">(Baum &amp; Petrie, 1966;</ref><ref type="bibr" target="#b722">Stratonovich, 1960)</ref> and Expectation Maximization (EM) <ref type="bibr" target="#b161">(Dempster, Laird, &amp; Rubin, 1977;</ref><ref type="bibr" target="#b212">Friedman, Hastie, &amp; Tibshirani, 2001)</ref>, e.g., <ref type="bibr" target="#b59">Baldi and Chauvin (1996)</ref>, <ref type="bibr" target="#b93">Bengio (1991)</ref>, <ref type="bibr" target="#b102">Bishop (2006)</ref>, <ref type="bibr" target="#b112">Bottou (1991)</ref>, <ref type="bibr" target="#b113">Bourlard and Morgan (1994)</ref>, <ref type="bibr" target="#b149">Dahl, Yu, Deng, and Acero (2012)</ref>, <ref type="bibr" target="#b284">Hastie, Tibshirani, and Friedman (2009)</ref>, <ref type="bibr" target="#b298">Hinton, Deng, et al. (2012)</ref>, <ref type="bibr" target="#b354">Jordan and Sejnowski (2001)</ref>, <ref type="bibr" target="#b577">Poon and Domingos (2011)</ref> and <ref type="bibr" target="#b822">Wu and Shao (2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Unsupervised Learning (UL) facilitating SL and RL</head><p>Another recurring theme is how UL can facilitate both SL (Section 5) and RL (Section 6). UL (Section 5.6.4) is normally used to encode raw incoming data such as video or speech streams in a form that is more convenient for subsequent goal-directed learning. In particular, codes that describe the original data in a less redundant or more compact way can be fed into SL <ref type="bibr">(Sections 5.10,</ref><ref type="bibr">5.15)</ref> or RL machines (Section 6.4), whose search spaces may thus become smaller (and whose CAPs shallower) than those necessary for dealing with the raw data. UL is closely connected to the topics of regularization and compression <ref type="bibr">(Sections 4.4,</ref><ref type="bibr">5.6.3)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Learning hierarchical representations through deep SL, UL, RL</head><p>Many methods of Good Old-Fashioned Artificial Intelligence (GO-FAI) <ref type="bibr" target="#b531">(Nilsson, 1980)</ref> as well as more recent approaches to AI (Russell, Norvig, Canny, <ref type="bibr" target="#b622">Malik, &amp; Edwards, 1995)</ref> and Machine Learning <ref type="bibr" target="#b495">(Mitchell, 1997)</ref> learn hierarchies of more and more abstract data representations. For example, certain methods of syntactic pattern recognition <ref type="bibr" target="#b215">(Fu, 1977)</ref> such as grammar induction discover hierarchies of formal rules to model observations. The partially (un)supervised Automated Mathematician/EURISKO <ref type="bibr" target="#b426">(Lenat, 1983;</ref><ref type="bibr">Lenat &amp; Brown, 1984)</ref> continually learns concepts by combining previously learnt concepts. Such hierarchical representation learning <ref type="bibr" target="#b95">(Bengio, Courville, &amp; Vincent, 2013;</ref><ref type="bibr" target="#b161">Deng &amp; Yu, 2014;</ref><ref type="bibr" target="#b604">Ring, 1994)</ref> is also a recurring theme of DL NNs for SL (Section 5), UL-aided SL <ref type="bibr">(Sections 5.7,</ref><ref type="bibr">5.10,</ref><ref type="bibr">5.15)</ref>, and hierarchical RL (Section 6.5). Often, abstract hierarchical representations are natural by-products of data compression (Section 4.4), e.g., Section 5.10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Occam's razor: compression and Minimum Description Length (MDL)</head><p>Occam's razor favors simple solutions over complex ones. Given some programming language, the principle of Minimum Description Length (MDL) can be used to measure the complexity of a solution candidate by the length of the shortest program that computes it (e.g., <ref type="bibr" target="#b106">Blumer, Ehrenfeucht, Haussler, &amp; Warmuth, 1987;</ref><ref type="bibr" target="#b134">Chaitin, 1966;</ref><ref type="bibr" target="#b270">Grünwald, Myung, &amp; Pitt, 2005;</ref><ref type="bibr" target="#b385">Kolmogorov, 1965b;</ref><ref type="bibr" target="#b429">Levin, 1973a;</ref><ref type="bibr" target="#b435">Li &amp; Vitányi, 1997;</ref><ref type="bibr" target="#b607">Rissanen, 1986;</ref><ref type="bibr" target="#b706">Solomonoff, 1964</ref><ref type="bibr" target="#b707">Solomonoff, , 1978;;</ref><ref type="bibr" target="#b767">Wallace &amp; Boulton, 1968)</ref>. Some methods explicitly take into account program runtime <ref type="bibr" target="#b30">(Allender, 1992;</ref><ref type="bibr" target="#b654">Schmidhuber, 1997</ref><ref type="bibr" target="#b655">Schmidhuber, , 2002;;</ref><ref type="bibr" target="#b773">Watanabe, 1992)</ref>; many consider only programs with constant runtime, written in non-universal programming languages (e.g., <ref type="bibr" target="#b304">Hinton &amp; van Camp, 1993;</ref><ref type="bibr" target="#b607">Rissanen, 1986)</ref>. In the NN case, the MDL principle suggests that low NN weight complexity corresponds to high NN probability in the Bayesian view (e.g., <ref type="bibr" target="#b127">Buntine &amp; Weigend, 1991;</ref><ref type="bibr" target="#b158">De Freitas, 2003;</ref><ref type="bibr" target="#b458">MacKay, 1992;</ref><ref type="bibr">Neal, 1995)</ref>, and to high generalization performance (e.g., <ref type="bibr" target="#b75">Baum &amp; Haussler, 1989)</ref>, without overfitting the training data. Many methods have been proposed for regularizing NNs, that is, searching for solutioncomputing but simple, low-complexity SL NNs (Section 5.6.3) and RL NNs (Section 6.7). This is closely related to certain UL methods (Sections 4.2, 5.6.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Fast Graphics Processing Units (GPUs) for DL in NNs</head><p>While the previous millennium saw several attempts at creating fast NN-specific hardware (e.g., <ref type="bibr" target="#b188">Faggin, 1992;</ref><ref type="bibr" target="#b288">Heemskerk, 1995;</ref><ref type="bibr" target="#b339">Jackel et al., 1990;</ref><ref type="bibr" target="#b390">Korkin, de Garis, Gers, &amp; Hemmi, 1997;</ref><ref type="bibr" target="#b588">Ramacher et al., 1993;</ref><ref type="bibr" target="#b752">Urlbe, 1999;</ref><ref type="bibr" target="#b796">Widrow, Rumelhart, &amp; Lehr, 1994)</ref>, and at exploiting standard hardware (e.g., <ref type="bibr" target="#b43">Anguita &amp; Gomes, 1996;</ref><ref type="bibr" target="#b44">Anguita, Parodi, &amp; Zunino, 1994;</ref><ref type="bibr" target="#b515">Muller, Gunzinger, &amp; Guggenbühl, 1995)</ref>, the new millennium brought a DL breakthrough in form of cheap, multi-processor graphics cards or GPUs. GPUs are widely used for video games, a huge and competitive market that has driven down hardware prices. GPUs excel at the fast matrix and vector multiplications required not only for convincing virtual realities but also for NN training, where they can speed up learning by a factor of 50 and more. Some of the GPUbased FNN implementations ) have greatly contributed to recent successes in contests for pattern recognition , image segmentation (Section 5.21), and object detection (Sections 5.21-5.22).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Supervised NNs, some helped by unsupervised NNs</head><p>The main focus of current practical applications is on Supervised Learning (SL), which has dominated recent pattern recognition contests (Sections 5.17-5.23). Several methods, however, use additional Unsupervised Learning (UL) to facilitate SL <ref type="bibr">(Sections 5.7,</ref><ref type="bibr">5.10,</ref><ref type="bibr">5.15)</ref>. It does make sense to treat SL and UL in the same section: often gradient-based methods, such as BP (Section 5.5.1), are used to optimize objective functions of both UL and SL, and the boundary between SL and UL may blur, for example, when it comes to time series prediction and sequence classification, e.g., Sections 5.10, 5.12.</p><p>A historical timeline format will help to arrange subsections on important inspirations and technical contributions (although such a subsection may span a time interval of many years). Section 5.1 briefly mentions early, shallow NN models since the 1940s (and 1800s), Section 5.2 additional early neurobiological inspiration relevant for modern Deep Learning (DL). <ref type="bibr">Section 5.3 is about GMDH networks (since 1965)</ref>, to my knowledge the first (feedforward) DL systems. Section 5.4 is about the relatively deep Neocognitron <ref type="bibr">NN (1979)</ref> which is very similar to certain modern deep FNN architectures, as it combines convolutional NNs (CNNs), weight pattern replication, and subsampling mechanisms. Section 5.5 uses the notation of Section 2 to compactly describe a central algorithm of DL, namely, backpropagation (BP) for supervised weight-sharing FNNs and RNNs. It also summarizes the history of BP 1960-1981 and beyond. Section 5.6 describes problems encountered in the late 1980s with BP for deep NNs, and mentions several ideas from the previous millennium to overcome them. Section 5.7 discusses a first hierarchical stack (1987) of coupled UL-based Autoencoders (AEs)-this concept resurfaced in the new millennium (Section 5.15). Section 5.8 is about applying BP to CNNs (1989), which is important for today's DL applications. Section 5.9 explains BP's Fundamental DL Problem (of vanishing/exploding gradients) discovered in 1991. Section 5.10 explains how a deep RNN stack of 1991 (the History Compressor) pre-trained by UL helped to solve previously unlearnable DL benchmarks requiring Credit Assignment Paths (CAPs, Section 3) of depth 1000 and more. Section 5.11 discusses a particular winner-take-all (WTA) method called Max-Pooling <ref type="bibr">(MP, 1992)</ref> widely used in today's deep FNNs. Section 5.12 mentions a first important contest won by SL NNs in 1994. Section 5.13 describes a purely supervised DL RNN <ref type="bibr">(Long Short-Term Memory, LSTM, 1995)</ref> for problems of depth 1000 and more. Section 5.14 mentions an early contest of 2003 won by an ensemble of shallow FNNs, as well as good pattern recognition results with CNNs and deep FNNs and LSTM RNNs <ref type="bibr">(2003)</ref>. Section 5.15 is mostly about Deep Belief Networks <ref type="bibr">(DBNs, 2006)</ref> and related stacks of Autoencoders (AEs, Section 5.7), both pre-trained by UL to facilitate subsequent BP-based SL (compare Sections 5.6.1, 5.10). Section 5.16 mentions the first SL-based <ref type="bibr">GPU-CNNs (2006)</ref>, <ref type="bibr">BP-trained MPCNNs (2007), and</ref><ref type="bibr">LSTM stacks (2007)</ref>. Sections 5.17-5.22 focus on official competitions with secret test sets won by (mostly purely supervised) deep NNs since 2009, in sequence recognition, image classification, image segmentation, and object detection. Many RNN results depended on LSTM (Section 5.13); many FNN results depended on GPU-based FNN code developed since 2004 , in particular, GPU-MPCNNs (Section 5.19). Section 5.24 mentions recent tricks for improving DL in NNs, many of them closely related to earlier tricks from the previous millennium (e.g., <ref type="bibr">Sections 5.6.2,</ref><ref type="bibr">5.6.3)</ref>. Section 5.25 discusses how artificial NNs can help to understand biological NNs; Section 5.26 addresses the possibility of DL in NNs with spiking neurons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Early NNs since the 1940s (and the 1800s)</head><p>Early NN architectures <ref type="bibr">(McCulloch &amp; Pitts, 1943)</ref> did not learn. The first ideas about UL were published a few years later <ref type="bibr">(Hebb, 1949)</ref>. The following decades brought simple NNs trained by SL (e.g., <ref type="bibr" target="#b522">Narendra &amp; Thathatchar, 1974;</ref><ref type="bibr" target="#b614">Rosenblatt, 1958</ref><ref type="bibr" target="#b615">Rosenblatt, , 1962;;</ref><ref type="bibr" target="#b796">Widrow &amp; Hoff, 1962)</ref> and UL (e.g., <ref type="bibr" target="#b266">Grossberg, 1969;</ref><ref type="bibr" target="#b380">Kohonen, 1972;</ref><ref type="bibr">von der Malsburg, 1973;</ref><ref type="bibr" target="#b813">Willshaw &amp; von der Malsburg, 1976)</ref>, as well as closely related associative memories (e.g., <ref type="bibr" target="#b316">Hopfield, 1982;</ref><ref type="bibr" target="#b552">Palm, 1980)</ref>.</p><p>In a sense NNs have been around even longer, since early supervised NNs were essentially variants of linear regression methods going back at least to the early 1800s (e.g., <ref type="bibr" target="#b224">Gauss, 1809</ref><ref type="bibr">Gauss, , 1821;;</ref><ref type="bibr" target="#b422">Legendre, 1805)</ref>; Gauss also refers to his work of 1795. Early NNs had a maximal CAP depth of 1 (Section 3). <ref type="bibr">(Sections 5.4,</ref><ref type="bibr">5.11)</ref> Simple cells and complex cells were found in the cat's visual cortex (e.g., <ref type="bibr" target="#b318">Hubel &amp; Wiesel, 1962;</ref><ref type="bibr" target="#b803">Wiesel &amp; Hubel, 1959)</ref>. These cells fire in response to certain properties of visual sensory inputs, such as the orientation of edges. Complex cells exhibit more spatial invariance than simple cells. This inspired later deep NN architectures <ref type="bibr">(Sections 5.4,</ref><ref type="bibr">5.11)</ref> used in certain modern awardwinning Deep Learners .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Around 1960: visual cortex provides inspiration for DL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">1965: deep networks based on the Group Method of Data Handling</head><p>Networks trained by the Group Method of Data Handling (GMDH) <ref type="bibr" target="#b332">(Ivakhnenko, 1968</ref><ref type="bibr" target="#b333">(Ivakhnenko, , 1971;;</ref><ref type="bibr" target="#b335">Ivakhnenko &amp; Lapa, 1965;</ref><ref type="bibr" target="#b336">Ivakhnenko, Lapa, &amp; McDonough, 1967)</ref> were perhaps the first DL systems of the Feedforward Multilayer Perceptron type, although there was earlier work on NNs with a single hidden layer (e.g., <ref type="bibr" target="#b355">Joseph, 1961;</ref><ref type="bibr" target="#b762">Viglione, 1970)</ref>. The units of GMDH nets may have polynomial activation functions implementing Kolmogorov-Gabor polynomials (more general than other widely used NN activation functions, Section 2). Given a training set, layers are incrementally grown and trained by regression analysis (e.g., <ref type="bibr" target="#b224">Gauss, 1809</ref><ref type="bibr">Gauss, , 1821;;</ref><ref type="bibr" target="#b422">Legendre, 1805</ref>) (Section 5.1), then pruned with the help of a separate validation set (using today's terminology), where Decision Regularization is used to weed out superfluous units (compare <ref type="bibr">Section 5.6.3)</ref>. The numbers of layers and units per layer can be learned in problem-dependent fashion. To my knowledge, this was the first example of open-ended, hierarchical representation learning in NNs (Section 4.3). A paper of 1971 already described a deep GMDH network with 8 layers <ref type="bibr" target="#b333">(Ivakhnenko, 1971)</ref>.</p><p>There have been numerous applications of GMDH-style nets, e.g. <ref type="bibr" target="#b194">Farlow (1984)</ref>, <ref type="bibr" target="#b328">Ikeda, Ochiai, and Sawaragi (1976)</ref>, <ref type="bibr" target="#b334">Ivakhnenko (1995)</ref>, <ref type="bibr" target="#b387">Kondo (1998)</ref>, <ref type="bibr" target="#b388">Kondo and Ueno (2008)</ref>, <ref type="bibr" target="#b389">Kordík, Náplava, Snorek, and Genyk-Berezovskyj (2003)</ref>, <ref type="bibr" target="#b462">Madala and Ivakhnenko (1994)</ref> and <ref type="bibr" target="#b816">Witczak, Korbicz, Mrugalski, and</ref><ref type="bibr">Patton (2006). 5.4. 1979: convolution</ref> </p><formula xml:id="formula_0">+ weight replication + subsampling (Neocog- nitron)</formula><p>Apart from deep GMDH networks (Section 5.3), the Neocognitron <ref type="bibr" target="#b217">(Fukushima, 1979</ref><ref type="bibr" target="#b218">(Fukushima, , 1980</ref><ref type="bibr" target="#b220">(Fukushima, , 2013a) )</ref> was perhaps the first artificial NN that deserved the attribute deep, and the first to incorporate the neurophysiological insights of Section 5.2. It introduced convolutional NNs (today often called CNNs or convnets), where the (typically rectangular) receptive field of a convolutional unit with given weight vector (a filter) is shifted step by step across a 2dimensional array of input values, such as the pixels of an image (usually there are several such filters). The resulting 2D array of subsequent activation events of this unit can then provide inputs to higher-level units, and so on. Due to massive weight replication (Section 2), relatively few parameters (Section 4.4) may be necessary to describe the behavior of such a convolutional layer.</p><p>Subsampling or downsampling layers consist of units whose fixed-weight connections originate from physical neighbors in the convolutional layers below. Subsampling units become active if at least one of their inputs is active; their responses are insensitive to certain small image shifts (compare Section 5.2).</p><p>The Neocognitron is very similar to the architecture of modern, contest-winning, purely supervised, feedforward, gradient-based Deep Learners with alternating convolutional and downsampling layers (e.g., ). Fukushima, however, did not set the weights by supervised backpropagation (Sections 5.5, 5.8), but by local, WTA-based unsupervised learning rules (e.g., <ref type="bibr" target="#b221">Fukushima, 2013b)</ref>, or by pre-wiring. In that sense he did not care for the DL problem (Section 5.9), although his architecture was comparatively deep indeed. For downsampling purposes he used Spatial Averaging <ref type="bibr" target="#b218">(Fukushima, 1980</ref><ref type="bibr" target="#b219">(Fukushima, , 2011) )</ref> instead of Max-Pooling (MP, Section 5.11), currently a particularly convenient and popular WTA mechanism. Today's DL combinations of CNNs and MP and BP also profit a lot from later work (e.g., <ref type="bibr">Sections 5.8, 5.16, 5.19). 5.5. 1960-1981 and</ref><ref type="bibr">beyond: development</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>of backpropagation (BP) for NNs</head><p>The minimization of errors through gradient descent <ref type="bibr" target="#b274">(Hadamard, 1908)</ref> in the parameter space of complex, nonlinear, differentiable <ref type="bibr" target="#b425">(Leibniz, 1684)</ref>, multi-stage, NN-related systems has been discussed at least since the early 1960s (e.g., <ref type="bibr" target="#b35">Amari, 1967;</ref><ref type="bibr" target="#b124">Bryson, 1961;</ref><ref type="bibr" target="#b124">Bryson &amp; Denham, 1961;</ref><ref type="bibr" target="#b125">Bryson &amp; Ho, 1969;</ref><ref type="bibr" target="#b172">Director &amp; Rohrer, 1969;</ref><ref type="bibr" target="#b176">Dreyfus, 1962;</ref><ref type="bibr" target="#b367">Kelley, 1960;</ref><ref type="bibr" target="#b576">Pontryagin, Boltyanskii, Gamrelidze, &amp; Mishchenko, 1961;</ref><ref type="bibr">Wilkinson, 1965)</ref>, initially within the framework of Euler-Lagrange equations in the Calculus of <ref type="bibr">Variations (e.g., Euler, 1744)</ref>.</p><p>Steepest descent in the weight space of such systems can be performed <ref type="bibr" target="#b124">(Bryson, 1961;</ref><ref type="bibr" target="#b125">Bryson &amp; Ho, 1969;</ref><ref type="bibr" target="#b367">Kelley, 1960)</ref> by iterating the chain rule <ref type="bibr" target="#b424">(Leibniz, 1676;</ref><ref type="bibr" target="#b434">L'Hôpital, 1696)</ref> à la Dynamic Programming (DP) <ref type="bibr" target="#b92">(Bellman, 1957)</ref>. A simplified derivation of this backpropagation method uses the chain rule only <ref type="bibr" target="#b176">(Dreyfus, 1962)</ref>.</p><p>The systems of the 1960s were already efficient in the DP sense. However, they backpropagated derivative information through standard Jacobian matrix calculations from one ''layer'' to the previous one, without explicitly addressing either direct links across several layers or potential additional efficiency gains due to network sparsity (but perhaps such enhancements seemed obvious to the authors). Given all the prior work on learning in multilayer NN-like systems (see also Section 5.3 on deep nonlinear nets since 1965), it seems surprising in hindsight that a book <ref type="bibr" target="#b493">(Minsky &amp; Papert, 1969)</ref> on the limitations of simple linear perceptrons with a single layer (Section 5.1) discouraged some researchers from further studying NNs.</p><p>Explicit, efficient error backpropagation (BP) in arbitrary, discrete, possibly sparsely connected, NN-like networks apparently was first described in a 1970 master's thesis <ref type="bibr" target="#b441">(Linnainmaa, 1970</ref><ref type="bibr" target="#b441">(Linnainmaa, , 1976))</ref>, albeit without reference to NNs. BP is also known as the reverse mode of automatic differentiation <ref type="bibr" target="#b264">(Griewank, 2012)</ref>, where the costs of forward activation spreading essentially equal the costs of backward derivative calculation. See early FORTRAN code <ref type="bibr" target="#b441">(Linnainmaa, 1970)</ref> and closely related work <ref type="bibr" target="#b546">(Ostrovskii, Volin, &amp; Borisov, 1971)</ref>.</p><p>Efficient BP was soon explicitly used to minimize cost functions by adapting control parameters (weights) <ref type="bibr" target="#b177">(Dreyfus, 1973)</ref>. Compare some preliminary, NN-specific discussion <ref type="bibr">(Werbos, 1974, Section 5.5</ref>.1), a method for multilayer threshold NNs <ref type="bibr" target="#b107">(Bobrowski, 1978)</ref>, and a computer program for automatically deriving and implementing BP for given differentiable systems <ref type="bibr" target="#b710">(Speelpenning, 1980)</ref>.</p><p>To my knowledge, the first NN-specific application of efficient BP as above was described in 1981 <ref type="bibr" target="#b782">(Werbos, 1981</ref><ref type="bibr" target="#b789">(Werbos, , 2006))</ref>. Related work was published several years later <ref type="bibr">(LeCun, 1985</ref><ref type="bibr" target="#b409">(LeCun, , 1988;;</ref><ref type="bibr" target="#b555">Parker, 1985)</ref>. A paper of 1986 significantly contributed to the popularization of BP for NNs <ref type="bibr" target="#b619">(Rumelhart, Hinton, &amp; Williams, 1986)</ref>, experimentally demonstrating the emergence of useful internal representations in hidden layers. See generalizations for sequenceprocessing recurrent NNs (e.g., <ref type="bibr" target="#b48">Atiya &amp; Parlos, 2000;</ref><ref type="bibr" target="#b55">Baldi, 1995;</ref><ref type="bibr" target="#b234">Gherrity, 1989;</ref><ref type="bibr" target="#b396">Kremer &amp; Kolen, 2001;</ref><ref type="bibr" target="#b559">Pearlmutter, 1989</ref><ref type="bibr" target="#b561">Pearlmutter, , 1995;;</ref><ref type="bibr" target="#b609">Robinson &amp; Fallside, 1987;</ref><ref type="bibr" target="#b613">Rohwer, 1989;</ref><ref type="bibr" target="#b650">Schmidhuber, 1992a;</ref><ref type="bibr" target="#b784">Werbos, 1988;</ref><ref type="bibr" target="#b807">Williams, 1989;</ref><ref type="bibr" target="#b810">Williams &amp; Peng, 1990;</ref><ref type="bibr" target="#b811">Williams &amp; Zipser, 1988</ref><ref type="bibr">, 1989a</ref><ref type="bibr">, 1989b)</ref>, also for equilibrium RNNs <ref type="bibr" target="#b32">(Almeida, 1987;</ref><ref type="bibr" target="#b571">Pineda, 1987)</ref> with stationary inputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.1.">BP for weight-sharing feedforward NNs (FNNs) and recurrent NNs (RNNs)</head><p>Using the notation of Section 2 for weight-sharing FNNs or RNNs, after an episode of activation spreading through differentiable f t , a single iteration of gradient descent through BP computes changes of all w i in proportion to</p><formula xml:id="formula_1">∂E ∂w i =  t ∂E ∂net t ∂net t ∂w i</formula><p>as in Algorithm 5.5.1 (for the additive case), where each weight w i is associated with a real-valued variable ∆ i initialized by 0.  The computational costs of the backward (BP) pass are essentially those of the forward pass (Section 2). Forward and backward passes are re-iterated until sufficient performance is reached.</p><p>As of 2014, this simple BP method is still the central learning algorithm for FNNs and RNNs. Notably, most contest-winning NNs up to 2014 <ref type="bibr">(Sections 5.12,</ref><ref type="bibr">5.14,</ref><ref type="bibr">5.17,</ref><ref type="bibr">5.19,</ref><ref type="bibr">5.21,</ref><ref type="bibr">5.22)</ref> did not augment supervised BP by some sort of unsupervised learning as discussed in <ref type="bibr">Sections 5.7, 5.10, 5.15. 5.6. Late 1980s-2000 and</ref><ref type="bibr">beyond: numerous</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>improvements of NNs</head><p>By the late 1980s it seemed clear that BP by itself (Section 5.5) was no panacea. Most FNN applications focused on FNNs with few hidden layers. Additional hidden layers often did not seem to offer empirical benefits. Many practitioners found solace in a theorem <ref type="bibr" target="#b287">(Hecht-Nielsen, 1989;</ref><ref type="bibr" target="#b317">Hornik, Stinchcombe, &amp; White, 1989;</ref><ref type="bibr" target="#b384">Kolmogorov, 1965a)</ref> stating that an NN with a single layer of enough hidden units can approximate any multivariate continuous function with arbitrary accuracy.</p><p>Likewise, most RNN applications did not require backpropagating errors far. Many researchers helped their RNNs by first training them on shallow problems (Section 3) whose solutions then generalized to deeper problems. In fact, some popular RNN algorithms restricted credit assignment to a single step backwards <ref type="bibr" target="#b183">(Elman, 1990;</ref><ref type="bibr" target="#b350">Jordan, 1986</ref><ref type="bibr" target="#b352">Jordan, , 1997))</ref>, also in more recent studies <ref type="bibr" target="#b342">(Jaeger, 2001</ref><ref type="bibr" target="#b343">(Jaeger, , 2004;;</ref><ref type="bibr" target="#b457">Maass et al., 2002)</ref>.</p><p>Generally speaking, although BP allows for deep problems in principle, it seemed to work only for shallow problems. The late 1980s and early 1990s saw a few ideas with a potential to overcome this problem, which was fully understood only in 1991 (Section 5.9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.1.">Ideas for dealing with long time lags and deep CAPs</head><p>To deal with long time lags between relevant events, several sequence processing methods were proposed, including Focused BP based on decay factors for activations of units in RNNs <ref type="bibr" target="#b511">(Mozer, 1989</ref><ref type="bibr" target="#b513">(Mozer, , 1992))</ref>, Time-Delay Neural Networks (TDNNs) <ref type="bibr" target="#b403">(Lang, Waibel, &amp; Hinton, 1990)</ref> and their adaptive extension <ref type="bibr" target="#b109">(Bodenhausen &amp; Waibel, 1991)</ref>, Nonlinear AutoRegressive with eXogenous inputs (NARX) RNNs <ref type="bibr" target="#b438">(Lin, Horne, Tino, &amp; Giles, 1996)</ref>, certain hierarchical RNNs <ref type="bibr" target="#b294">(Hihi &amp; Bengio, 1996</ref><ref type="bibr">) (compare Section 5.10, 1991)</ref>, RL economies in RNNs with WTA units and local learning rules <ref type="bibr" target="#b643">(Schmidhuber, 1989b)</ref>, and other methods (e.g., <ref type="bibr" target="#b97">Bengio, Simard, &amp; Frasconi, 1994;</ref><ref type="bibr" target="#b165">de Vries &amp; Principe, 1991;</ref><ref type="bibr" target="#b572">Plate, 1993;</ref><ref type="bibr" target="#b603">Ring, 1993</ref><ref type="bibr" target="#b604">Ring, , 1994;;</ref><ref type="bibr">Sun, Chen, &amp; Lee, 1993)</ref>. However, these algorithms either worked for shallow CAPs only, could not generalize to unseen CAP depths, had problems with greatly varying time lags between relevant events, needed external fine tuning of delay constants, or suffered from other problems. In fact, it turned out that certain simple but deep benchmark problems used to evaluate such methods are more quickly solved by randomly guessing RNN weights until a solution is found <ref type="bibr" target="#b306">(Hochreiter &amp; Schmidhuber, 1996)</ref>.</p><p>While the RNN methods above were designed for DL of temporal sequences, the Neural Heat Exchanger <ref type="bibr" target="#b645">(Schmidhuber, 1990c)</ref> consists of two parallel deep FNNs with opposite flow directions. Input patterns enter the first FNN and are propagated ''up''. Desired outputs (targets) enter the ''opposite'' FNN and are propagated ''down''. Using a local learning rule, each layer in each net tries to be similar (in information content) to the preceding layer and to the adjacent layer of the other net. The input entering the first net slowly ''heats up'' to become the target. The target entering the opposite net slowly ''cools down'' to become the input. The Helmholtz Machine <ref type="bibr" target="#b153">(Dayan &amp; Hinton, 1996;</ref><ref type="bibr" target="#b154">Dayan, Hinton, Neal, &amp; Zemel, 1995)</ref> may be viewed as an unsupervised (Section 5.6.4) variant thereof (Peter <ref type="bibr">Dayan, personal communication, 1994)</ref>.</p><p>A hybrid approach <ref type="bibr" target="#b691">(Shavlik &amp; Towell, 1989;</ref><ref type="bibr" target="#b744">Towell &amp; Shavlik, 1994)</ref> initializes a potentially deep FNN through a domain theory in propositional logic, which may be acquired through explanationbased learning <ref type="bibr" target="#b159">(DeJong &amp; Mooney, 1986;</ref><ref type="bibr" target="#b494">Minton et al., 1989;</ref><ref type="bibr" target="#b496">Mitchell, Keller, &amp; Kedar-Cabelli, 1986</ref>). The NN is then fine-tuned through BP (Section 5.5). The NN's depth reflects the longest chain of reasoning in the original set of logical rules. An extension of this approach <ref type="bibr" target="#b460">(Maclin &amp; Shavlik, 1993;</ref><ref type="bibr" target="#b744">Shavlik, 1994)</ref> initializes an RNN by domain knowledge expressed as a Finite State Automaton (FSA). BP-based fine-tuning has become important for later DL systems pre-trained by UL, e.g., <ref type="bibr">Sections 5.10,</ref><ref type="bibr">5.15. 5.6.2. Better BP through advanced gradient descent (compare Section 5.24)</ref> Numerous improvements of steepest descent through BP (Section 5.5) have been proposed. Least-squares methods <ref type="bibr">(Gauss-Newton, Levenberg-Marquardt)</ref>  <ref type="bibr" target="#b224">(Gauss, 1809;</ref><ref type="bibr" target="#b428">Levenberg, 1944;</ref><ref type="bibr" target="#b472">Marquardt, 1963;</ref><ref type="bibr" target="#b530">Newton, 1687;</ref><ref type="bibr" target="#b635">Schaback &amp; Werner, 1992)</ref> and quasi-Newton methods (Broyden-Fletcher-Goldfarb-Shanno, BFGS) <ref type="bibr" target="#b121">(Broyden et al., 1965;</ref><ref type="bibr" target="#b206">Fletcher &amp; Powell, 1963;</ref><ref type="bibr" target="#b243">Goldfarb, 1970;</ref><ref type="bibr" target="#b688">Shanno, 1970)</ref> are computationally too expensive for large NNs. Partial BFGS <ref type="bibr" target="#b74">(Battiti, 1992;</ref><ref type="bibr" target="#b623">Saito &amp; Nakano, 1997)</ref> and conjugate gradient <ref type="bibr" target="#b293">(Hestenes &amp; Stiefel, 1952;</ref><ref type="bibr" target="#b500">Møller, 1993)</ref> as well as other methods <ref type="bibr" target="#b133">(Cauwenberghs, 1993;</ref><ref type="bibr" target="#b642">Schmidhuber, 1989a;</ref><ref type="bibr" target="#b705">Solla, 1988)</ref> provide sometimes useful fast alternatives. BP can be treated as a linear least-squares problem <ref type="bibr" target="#b100">(Biegler-König &amp; Bärmann, 1993)</ref>, where second-order gradient information is passed back to preceding layers.</p><p>To speed up BP, momentum was introduced <ref type="bibr">(Rumelhart et al., 1986)</ref>, ad-hoc constants were added to the slope of the linearized activation function <ref type="bibr" target="#b189">(Fahlman, 1988)</ref>, or the nonlinearity of the slope was exaggerated <ref type="bibr" target="#b790">(West &amp; Saad, 1995)</ref>.</p><p>Only the signs of the error derivatives are taken into account by the successful and widely used BP variant R-prop <ref type="bibr" target="#b598">(Riedmiller &amp; Braun, 1993)</ref> and the robust variation iRprop+ <ref type="bibr" target="#b327">(Igel &amp; Hüsken, 2003)</ref>, which was also successfully applied to RNNs.</p><p>The local gradient can be normalized based on the NN architecture <ref type="bibr" target="#b675">(Schraudolph &amp; Sejnowski, 1996)</ref>, through a diagonalized Hessian approach <ref type="bibr" target="#b83">(Becker &amp; Le Cun, 1989)</ref>, or related efficient methods <ref type="bibr" target="#b673">(Schraudolph, 2002)</ref>.</p><p>Some algorithms for controlling BP step size adapt a global learning rate <ref type="bibr" target="#b73">(Battiti, 1989;</ref><ref type="bibr" target="#b405">Lapedes &amp; Farber, 1986;</ref><ref type="bibr" target="#b415">LeCun, Simard, &amp; Pearlmutter, 1993;</ref><ref type="bibr" target="#b765">Vogl, Mangis, Rigler, Zink, &amp; Alkon, 1988;</ref><ref type="bibr" target="#b832">Yu, Chen, &amp; Cheng, 1995)</ref>, while others compute individual learning rates for each weight <ref type="bibr" target="#b341">(Jacobs, 1988;</ref><ref type="bibr" target="#b694">Silva &amp; Almeida, 1990)</ref>. In online learning, where BP is applied after each pattern presentation, the vario-η algorithm <ref type="bibr" target="#b529">(Neuneier &amp; Zimmermann, 1996)</ref> sets each weight's learning rate inversely proportional to the empirical standard deviation of its local gradient, thus normalizing the stochastic weight fluctuations. Compare a local online step size adaptation method for nonlinear NNs <ref type="bibr" target="#b33">(Almeida, Almeida, Langlois, Amaral, &amp; Redol, 1997)</ref>.</p><p>Many additional tricks for improving NNs have been described (e.g., <ref type="bibr" target="#b502">Montavon, Orr, &amp; Müller, 2012;</ref><ref type="bibr" target="#b545">Orr &amp; Müller, 1998)</ref>. Compare Section 5.6.3 and recent developments mentioned in <ref type="bibr">Section 5.24. 5.6.3. Searching for simple,</ref> Many researchers used BP-like methods to search for ''simple'', low-complexity NNs (Section 4.4) with high generalization capability. Most approaches address the bias/variance dilemma <ref type="bibr" target="#b227">(Geman, Bienenstock, &amp; Doursat, 1992)</ref> through strong prior assumptions. For example, weight decay <ref type="bibr" target="#b279">(Hanson &amp; Pratt, 1989;</ref><ref type="bibr" target="#b398">Krogh &amp; Hertz, 1992;</ref><ref type="bibr" target="#b778">Weigend, Rumelhart, &amp; Huberman, 1991)</ref> encourages nearzero weights, by penalizing large weights. In a Bayesian framework <ref type="bibr" target="#b81">(Bayes, 1763)</ref>, weight decay can be derived <ref type="bibr" target="#b304">(Hinton &amp; van Camp, 1993)</ref> from Gaussian or Laplacian weight priors <ref type="bibr" target="#b224">(Gauss, 1809;</ref><ref type="bibr" target="#b406">Laplace, 1774)</ref>; see also <ref type="bibr" target="#b517">Murray and Edwards (1993)</ref>. An extension of this approach postulates that a distribution of networks with many similar weights generated by Gaussian mixtures is ''better'' a priori <ref type="bibr" target="#b534">(Nowlan &amp; Hinton, 1992)</ref>.</p><p>Often weight priors are implicit in additional penalty terms <ref type="bibr" target="#b458">(MacKay, 1992)</ref> or in methods based on validation sets <ref type="bibr" target="#b146">(Craven &amp; Wahba, 1979;</ref><ref type="bibr" target="#b186">Eubank, 1988;</ref><ref type="bibr" target="#b244">Golub, Heath, &amp; Wahba, 1979;</ref><ref type="bibr" target="#b283">Hastie &amp; Tibshirani, 1990;</ref><ref type="bibr" target="#b510">Mosteller &amp; Tukey, 1968;</ref><ref type="bibr" target="#b720">Stone, 1974</ref>), Akaike's information criterion and final prediction error <ref type="bibr" target="#b27">(Akaike, 1970</ref><ref type="bibr" target="#b28">(Akaike, , 1973</ref><ref type="bibr" target="#b29">(Akaike, , 1974))</ref>, or generalized prediction error <ref type="bibr" target="#b504">(Moody, 1992;</ref><ref type="bibr" target="#b505">Moody &amp; Utans, 1994)</ref>. See also <ref type="bibr" target="#b38">Amari and Murata (1993)</ref>, <ref type="bibr" target="#b273">Guyon, Vapnik, Boser, Bottou, and Solla (1992)</ref>, <ref type="bibr" target="#b312">Holden (1994)</ref>, <ref type="bibr" target="#b757">Vapnik (1992)</ref>, <ref type="bibr" target="#b771">Wang, Venkatesh, and Judd (1994)</ref> and <ref type="bibr" target="#b820">Wolpert (1994)</ref>. Similar priors (or biases towards simplicity) are implicit in constructive and pruning algorithms, e.g., layer-by-layer sequential network construction (e.g., <ref type="bibr" target="#b46">Ash, 1989;</ref><ref type="bibr" target="#b128">Burgess, 1994;</ref><ref type="bibr" target="#b190">Fahlman, 1991;</ref><ref type="bibr" target="#b214">Fritzke, 1994;</ref><ref type="bibr" target="#b223">Gallant, 1988;</ref><ref type="bibr" target="#b314">Honavar &amp; Uhr, 1988</ref><ref type="bibr">, 1993;</ref><ref type="bibr" target="#b332">Ivakhnenko, 1968</ref><ref type="bibr" target="#b333">Ivakhnenko, , 1971;;</ref><ref type="bibr" target="#b503">Moody, 1989;</ref><ref type="bibr" target="#b554">Parekh, Yang, &amp; Honavar, 2000;</ref><ref type="bibr" target="#b602">Ring, 1991;</ref><ref type="bibr" target="#b753">Utgoff &amp; Stracuzzi, 2002;</ref><ref type="bibr">Weng, Ahuja, &amp; Huang, 1992</ref>) (see also <ref type="bibr">Sections 5.3,</ref><ref type="bibr">5.11)</ref>, input pruning <ref type="bibr" target="#b504">(Moody, 1992;</ref><ref type="bibr" target="#b595">Refenes, Zapranis, &amp; Francis, 1994)</ref>, unit pruning (e.g., <ref type="bibr" target="#b332">Ivakhnenko, 1968</ref><ref type="bibr" target="#b333">Ivakhnenko, , 1971;;</ref><ref type="bibr" target="#b431">Levin, Leen, &amp; Moody, 1994;</ref><ref type="bibr" target="#b514">Mozer &amp; Smolensky, 1989;</ref><ref type="bibr" target="#b791">White, 1989)</ref>, weight pruning, e.g., optimal brain damage (LeCun, Denker, &amp; <ref type="bibr" target="#b413">Solla, 1990)</ref>, and optimal brain surgeon <ref type="bibr" target="#b281">(Hassibi &amp; Stork, 1993)</ref>.</p><p>A very general but not always practical approach for discovering low-complexity SL NNs or RL NNs searches among weight matrix-computing programs written in a universal programming language, with a bias towards fast and short programs (Schmidhuber, 1997) (Section 6.7).</p><p>Flat Minimum Search (FMS) <ref type="bibr" target="#b306">(Hochreiter &amp; Schmidhuber, 1997a</ref><ref type="bibr">, 1999)</ref> searches for a ''flat'' minimum of the error function: a large connected region in weight space where error is low and remains approximately constant, that is, few bits of information are required to describe low-precision weights with high variance. Compare perturbation tolerance conditions <ref type="bibr" target="#b101">(Bishop, 1993;</ref><ref type="bibr" target="#b130">Carter, Rudolph, &amp; Nucci, 1990;</ref><ref type="bibr" target="#b278">Hanson, 1990;</ref><ref type="bibr" target="#b369">Kerlirzin &amp; Vallet, 1993;</ref><ref type="bibr" target="#b477">Matsuoka, 1992;</ref><ref type="bibr">Minai &amp; Williams, 1994;</ref><ref type="bibr" target="#b517">Murray &amp; Edwards, 1993;</ref><ref type="bibr" target="#b528">Neti, Schneider, &amp; Young, 1992</ref>). An MDL-based, Bayesian argument suggests that flat minima correspond to ''simple'' NNs and low expected overfitting. Compare Section 5.6.4 and more recent developments mentioned in Section 5.24. <ref type="bibr">Sections 5.7,</ref><ref type="bibr">5.10,</ref><ref type="bibr">5.15)</ref> The notation of Section 2 introduced teacher-given labels d t . Many papers of the previous millennium, however, were about unsupervised learning (UL) without a teacher (e.g., <ref type="bibr" target="#b47">Atick, Li, &amp; Redlich, 1992;</ref><ref type="bibr" target="#b60">Baldi &amp; Hornik, 1989;</ref><ref type="bibr" target="#b68">Barlow, Kaushal, &amp; Mitchison, 1989;</ref><ref type="bibr" target="#b69">Barrow, 1987;</ref><ref type="bibr" target="#b156">Deco &amp; Parra, 1997;</ref><ref type="bibr" target="#b200">Field, 1987;</ref><ref type="bibr" target="#b210">Földiák, 1990;</ref><ref type="bibr" target="#b211">Földiák &amp; Young, 1995;</ref><ref type="bibr" target="#b267">Grossberg, 1976a</ref><ref type="bibr" target="#b268">Grossberg, , 1976b;;</ref><ref type="bibr">Hebb, 1949;</ref><ref type="bibr" target="#b380">Kohonen, 1972</ref><ref type="bibr" target="#b381">Kohonen, , 1982</ref><ref type="bibr" target="#b382">Kohonen, , 1988;;</ref><ref type="bibr" target="#b391">Kosko, 1990;</ref><ref type="bibr" target="#b475">Martinetz, Ritter, &amp; Schulten, 1990;</ref><ref type="bibr" target="#b487">Miller, 1994;</ref><ref type="bibr" target="#b512">Mozer, 1991;</ref><ref type="bibr" target="#b537">Oja, 1989;</ref><ref type="bibr" target="#b552">Palm, 1992;</ref><ref type="bibr" target="#b562">Pearlmutter &amp; Hinton, 1986;</ref><ref type="bibr" target="#b608">Ritter &amp; Kohonen, 1989;</ref><ref type="bibr" target="#b617">Rubner &amp; Schulten, 1990;</ref><ref type="bibr" target="#b631">Sanger, 1989;</ref><ref type="bibr" target="#b634">Saund, 1994;</ref><ref type="bibr">von der Malsburg, 1973;</ref><ref type="bibr" target="#b772">Watanabe, 1985;</ref><ref type="bibr" target="#b813">Willshaw &amp; von der Malsburg, 1976)</ref>; see also <ref type="bibr">post-2000</ref><ref type="bibr">work (e.g., Carreira-Perpinan, 2001;</ref><ref type="bibr" target="#b212">Franzius, Sprekeler, &amp; Wiskott, 2007;</ref><ref type="bibr" target="#b776">Waydo &amp; Koch, 2008;</ref><ref type="bibr" target="#b815">Wiskott &amp; Sejnowski, 2002)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.4.">Potential benefits of UL for SL (compare</head><p>Many UL methods are designed to maximize entropy-related, information-theoretic <ref type="bibr" target="#b111">(Boltzmann, 1909;</ref><ref type="bibr" target="#b400">Kullback &amp; Leibler, 1951;</ref><ref type="bibr" target="#b689">Shannon, 1948)</ref> objectives (e.g., <ref type="bibr" target="#b37">Amari, Cichocki, &amp; Yang, 1996;</ref><ref type="bibr" target="#b68">Barlow et al., 1989;</ref><ref type="bibr">Dayan &amp; Zemel, 1995;</ref><ref type="bibr" target="#b156">Deco &amp; Parra, 1997;</ref><ref type="bibr" target="#b201">Field, 1994;</ref><ref type="bibr" target="#b297">Hinton, Dayan, Frey, &amp; Neal, 1995;</ref><ref type="bibr" target="#b442">Linsker, 1988;</ref><ref type="bibr" target="#b459">MacKay &amp; Miller, 1990;</ref><ref type="bibr" target="#b573">Plumbley, 1991;</ref><ref type="bibr" target="#b594">Redlich, 1993;</ref><ref type="bibr" target="#b651">Schmidhuber, 1992b</ref><ref type="bibr" target="#b651">Schmidhuber, , 1992c;;</ref><ref type="bibr" target="#b674">Schraudolph &amp; Sejnowski, 1993;</ref><ref type="bibr" target="#b835">Zemel, 1993;</ref><ref type="bibr" target="#b836">Zemel &amp; Hinton, 1994)</ref>.</p><p>Many do this to uncover and disentangle hidden underlying sources of signals (e.g., <ref type="bibr" target="#b41">Andrade, Chacon, Merelo, &amp; Moran, 1993;</ref><ref type="bibr" target="#b91">Bell &amp; Sejnowski, 1995</ref>; Belouchrani, Abed-Meraim, Cardoso, &amp; Moulines, 1997; <ref type="bibr" target="#b129">Cardoso, 1994;</ref><ref type="bibr">Comon, 1994;</ref><ref type="bibr" target="#b325">Hyvärinen, Karhunen, &amp; Oja, 2001;</ref><ref type="bibr" target="#b358">Jutten &amp; Herault, 1991;</ref><ref type="bibr" target="#b364">Karhunen &amp; Joutsensalo, 1995;</ref><ref type="bibr" target="#b499">Molgedey &amp; Schuster, 1994;</ref><ref type="bibr" target="#b677">Schuster, 1992;</ref><ref type="bibr" target="#b687">Shan &amp; Cottrell, 2014;</ref><ref type="bibr" target="#b687">Shan, Zhang, &amp; Cottrell, 2007;</ref><ref type="bibr" target="#b732">Szabó, Póczos, &amp; Lőrincz, 2006)</ref>.</p><p>Many UL methods automatically and robustly generate distributed, sparse representations of input patterns <ref type="bibr" target="#b191">(Falconbridge, Stamps, &amp; Badcock, 2006;</ref><ref type="bibr" target="#b210">Földiák, 1990;</ref><ref type="bibr" target="#b299">Hinton &amp; Ghahramani, 1997;</ref><ref type="bibr" target="#b308">Hochreiter &amp; Schmidhuber, 1999;</ref><ref type="bibr" target="#b324">Hyvärinen, Hoyer, &amp; Oja, 1999;</ref><ref type="bibr" target="#b433">Lewicki &amp; Olshausen, 1998)</ref> through well-known feature detectors (e.g., <ref type="bibr" target="#b539">Olshausen &amp; Field, 1996;</ref><ref type="bibr" target="#b664">Schmidhuber, Eldracher, &amp; Foltin, 1996)</ref>, such as off-center-on-surround-like structures, as well as orientation sensitive edge detectors and Gabor filters <ref type="bibr" target="#b222">(Gabor, 1946)</ref>. They extract simple features related to those observed in early visual pre-processing stages of biological systems (e.g., <ref type="bibr" target="#b163">De Valois, Albrecht, &amp; Thorell, 1982;</ref><ref type="bibr" target="#b349">Jones &amp; Palmer, 1987)</ref>.</p><p>UL can also serve to extract invariant features from different data items (e.g., <ref type="bibr" target="#b82">Becker, 1991)</ref> through coupled NNs observing two different inputs <ref type="bibr" target="#b667">(Schmidhuber &amp; Prelinger, 1992)</ref>, also called Siamese NNs (e.g., <ref type="bibr" target="#b120">Bromley et al., 1993;</ref><ref type="bibr" target="#b137">Chen &amp; Salman, 2011;</ref><ref type="bibr" target="#b275">Hadsell, Chopra, &amp; LeCun, 2006;</ref><ref type="bibr" target="#b735">Taylor, Spiro, Bregler, &amp; Fergus, 2011)</ref>.</p><p>UL can help to encode input data in a form advantageous for further processing. In the context of DL, one important goal of UL is redundancy reduction. Ideally, given an ensemble of input patterns, redundancy reduction through a deep NN will create a factorial code (a code with statistically independent components) of the ensemble <ref type="bibr" target="#b67">(Barlow, 1989;</ref><ref type="bibr" target="#b68">Barlow et al., 1989)</ref>, to disentangle the unknown factors of variation (compare <ref type="bibr" target="#b95">Bengio et al., 2013)</ref>. Such codes may be sparse and can be advantageous for (1) data compression, (2) speeding up subsequent BP <ref type="bibr" target="#b82">(Becker, 1991)</ref>, <ref type="bibr" target="#b5">(3)</ref> trivializing the task of subsequent naive yet optimal Bayes classifiers <ref type="bibr" target="#b664">(Schmidhuber et al., 1996)</ref>.</p><p>Most early UL FNNs had a single layer. Methods for deeper UL FNNs include hierarchical (Section 4.3) self-organizing Kohonen maps (e.g., <ref type="bibr" target="#b173">Dittenbach, Merkl, &amp; Rauber, 2000;</ref><ref type="bibr" target="#b383">Koikkalainen &amp; Oja, 1990;</ref><ref type="bibr" target="#b402">Lampinen &amp; Oja, 1992;</ref><ref type="bibr" target="#b591">Rauber, Merkl, &amp; Dittenbach, 2002;</ref><ref type="bibr" target="#b759">Versino &amp; Gambardella, 1996)</ref>, hierarchical Gaussian potential function networks <ref type="bibr" target="#b420">(Lee &amp; Kil, 1991)</ref>, layer-wise UL of feature hierarchies fed into SL classifiers <ref type="bibr" target="#b84">(Behnke, 1999</ref><ref type="bibr" target="#b87">(Behnke, , 2003a))</ref>, the Self-Organizing Tree Algorithm (SOTA) <ref type="bibr" target="#b291">(Herrero, Valencia, &amp; Dopazo, 2001)</ref>, and nonlinear Autoencoders (AEs) with more than 3 (e.g., 5) layers <ref type="bibr" target="#b160">(DeMers &amp; Cottrell, 1993;</ref><ref type="bibr" target="#b395">Kramer, 1991;</ref><ref type="bibr" target="#b538">Oja, 1991)</ref>. Such AE NNs <ref type="bibr">(Rumelhart et al., 1986</ref>) can be trained to map input patterns to themselves, for example, by compactly encoding them through activations of units of a narrow bottleneck hidden layer. Certain nonlinear AEs suffer from certain limitations <ref type="bibr" target="#b56">(Baldi, 2012)</ref>.</p><p>Lococode <ref type="bibr" target="#b308">(Hochreiter &amp; Schmidhuber, 1999)</ref> uses FMS (Section 5.6.3) to find low-complexity AEs with low-precision weights describable by few bits of information, often producing sparse or factorial codes. Predictability Minimization (PM) <ref type="bibr" target="#b651">(Schmidhuber, 1992c)</ref> searches for factorial codes through nonlinear feature detectors that fight nonlinear predictors, trying to become both as informative and as unpredictable as possible. PM-based UL was applied not only to FNNs but also to RNNs (e.g., <ref type="bibr" target="#b440">Lindstädt, 1993;</ref><ref type="bibr" target="#b653">Schmidhuber, 1993b)</ref>. Compare Section 5.10 on UL-based RNN stacks (1991), as well as later UL RNNs (e.g., Klapper-Rybicka, <ref type="bibr" target="#b377">Schraudolph, &amp; Schmidhuber, 2001;</ref><ref type="bibr" target="#b717">Steil, 2007)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7.">1987: UL through Autoencoder (AE) hierarchies (compare Section 5.15)</head><p>Perhaps the first work to study potential benefits of UL-based pre-training was published in 1987. It proposed unsupervised AE hierarchies <ref type="bibr" target="#b64">(Ballard, 1987)</ref>, closely related to certain post-2000 feedforward Deep Learners based on UL (Section 5.15). The lowestlevel AE NN with a single hidden layer is trained to map input patterns to themselves. Its hidden layer codes are then fed into a higher-level AE of the same type, and so on. The hope is that the codes in the hidden AE layers have properties that facilitate subsequent learning. In one experiment, a particular AE-specific learning algorithm (different from traditional BP of Section 5.5.1) was used to learn a mapping in an AE stack pre-trained by this type of UL <ref type="bibr" target="#b64">(Ballard, 1987)</ref>. This was faster than learning an equivalent mapping by BP through a single deeper AE without pre-training. On the other hand, the task did not really require a deep AE, that is, the benefits of UL were not that obvious from this experiment. Compare an early survey <ref type="bibr" target="#b295">(Hinton, 1989)</ref> and the somewhat related Recursive Auto-Associative Memory (RAAM) <ref type="bibr" target="#b480">(Melnik, Levy, &amp; Pollack, 2000;</ref><ref type="bibr" target="#b574">Pollack, 1988</ref><ref type="bibr" target="#b575">Pollack, , 1990))</ref>, originally used to encode sequential linguistic structures of arbitrary size through a fixed number of hidden units. More recently, RAAMs were also used as unsupervised pre-processors to facilitate deep credit assignment for RL <ref type="bibr" target="#b236">(Gisslen, Luciw, Graziano, &amp; Schmidhuber, 2011</ref>) (Section 6.4).</p><p>In principle, many UL methods (Section 5.6.4) could be stacked like the AEs above, the history-compressing RNNs of Section 5.10, the Restricted Boltzmann Machines (RBMs) of Section 5.15, or hierarchical Kohonen nets (Section 5.6.4), to facilitate subsequent SL. Compare Stacked Generalization <ref type="bibr">(Ting &amp; Witten, 1997;</ref><ref type="bibr" target="#b819">Wolpert, 1992)</ref>, and FNNs that profit from pre-training by competitive UL (e.g., <ref type="bibr" target="#b620">Rumelhart &amp; Zipser, 1986)</ref> prior to BP-based fine-tuning <ref type="bibr" target="#b461">(Maclin &amp; Shavlik, 1995)</ref>. See also more recent methods using UL to improve subsequent SL (e.g., <ref type="bibr" target="#b84">Behnke, 1999</ref><ref type="bibr" target="#b87">Behnke, , 2003a;;</ref><ref type="bibr" target="#b185">Escalante-B &amp; Wiskott, 2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.8.">1989: BP for convolutional NNs (CNNs, Section 5.4)</head><p>In 1989, backpropagation (Section 5.5) was applied <ref type="bibr" target="#b410">(LeCun et al., 1989;</ref><ref type="bibr" target="#b411">LeCun, Boser, et al., 1990;</ref><ref type="bibr" target="#b412">LeCun, Bottou, Bengio, &amp; Haffner, 1998)</ref> to Neocognitron-like, weight-sharing, convolutional neural layers (Section 5.4) with adaptive connections. This combination, augmented by Max-Pooling (MP, <ref type="bibr">Sections 5.11,</ref><ref type="bibr">5.16</ref>), and sped up on graphics cards (Section 5.19), has become an essential ingredient of many modern, competition-winning, feedforward, visual Deep Learners . This work also introduced the MNIST data set of handwritten digits <ref type="bibr" target="#b410">(LeCun et al., 1989)</ref>, which over time has become perhaps the most famous benchmark of Machine Learning. CNNs helped to achieve good performance on <ref type="bibr">MNIST (LeCun, Boser, et al., 1990</ref>) (CAP depth 5) and on fingerprint recognition <ref type="bibr" target="#b58">(Baldi &amp; Chauvin, 1993)</ref>; similar CNNs were used commercially in the 1990s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.9.">1991: Fundamental Deep Learning Problem of gradient descent</head><p>A diploma thesis <ref type="bibr" target="#b305">(Hochreiter, 1991)</ref> represented a milestone of explicit DL research. As mentioned in Section 5.6, by the late 1980s, experiments had indicated that traditional deep feedforward or recurrent networks are hard to train by backpropagation (BP) (Section 5.5). Hochreiter's work formally identified a major reason: Typical deep NNs suffer from the now famous problem of vanishing or exploding gradients. With standard activation functions (Section 1), cumulative backpropagated error signals (Section 5.5.1) either shrink rapidly, or grow out of bounds. In fact, they decay exponentially in the number of layers or CAP depth (Section 3), or they explode. This is also known as the long time lag problem. Much subsequent DL research of the 1990s and 2000s was motivated by this insight. Later work <ref type="bibr" target="#b97">(Bengio et al., 1994)</ref> also studied basins of attraction and their stability under noise from a dynamical systems point of view: either the dynamics are not robust to noise, or the gradients vanish. See also <ref type="bibr" target="#b306">Hochreiter, Bengio, Frasconi, and Schmidhuber (2001)</ref> and <ref type="bibr" target="#b742">Tiňo and Hammer (2004)</ref>. Over the years, several ways of partially overcoming the Fundamental Deep Learning Problem were explored: I. A Very Deep Learner of 1991 (the History Compressor, Section 5.10) alleviates the problem through unsupervised pre-training for a hierarchy of RNNs. This greatly facilitates subsequent supervised credit assignment through BP (Section 5.5).</p><p>In the FNN case, similar effects can be achieved through conceptually related AE stacks (Sections 5.7, 5.15) and Deep Belief Networks (DBNs, Section 5.15). II. LSTM-like networks <ref type="bibr">(Sections 5.13,</ref><ref type="bibr">5.16,</ref><ref type="bibr">5.17,</ref>) alleviate the problem through a special architecture unaffected by it. III. Today's GPU-based computers have a million times the computational power of desktop machines of the early 1990s. This allows for propagating errors a few layers further down within reasonable time, even in traditional NNs (Section 5.18). That is basically what is winning many of the image recognition competitions now <ref type="bibr">(Sections 5.19,</ref><ref type="bibr">5.21,</ref><ref type="bibr">5.22)</ref>. (Although this does not really overcome the problem in a fundamental way.) IV. Hessian-free optimization (Section 5.6.2) can alleviate the problem for FNNs <ref type="bibr" target="#b473">(Martens, 2010;</ref><ref type="bibr" target="#b500">Møller, 1993;</ref><ref type="bibr" target="#b560">Pearlmutter, 1994;</ref><ref type="bibr" target="#b673">Schraudolph, 2002)</ref> (Section 5.6.2) and RNNs <ref type="bibr" target="#b474">(Martens &amp; Sutskever, 2011</ref>) (Section 5.20). V. The space of NN weight matrices can also be searched without relying on error gradients, thus avoiding the Fundamental Deep Learning Problem altogether. Random weight guessing sometimes works better than more sophisticated methods <ref type="bibr" target="#b306">(Hochreiter &amp; Schmidhuber, 1996)</ref>. Certain more complex problems are better solved by using Universal Search <ref type="bibr" target="#b430">(Levin, 1973b)</ref> for weight matrix-computing programs written in a universal programming language <ref type="bibr" target="#b654">(Schmidhuber, 1997)</ref>. Some are better solved by using linear methods to obtain optimal weights for connections to output events (Section 2), and evolving weights of connections to other events-this is called Evolino (Schmidhuber, <ref type="bibr" target="#b669">Wierstra, Gagliolo, &amp; Gomez, 2007)</ref>. Compare also related RNNs pre-trained by certain UL rules <ref type="bibr" target="#b717">(Steil, 2007)</ref>, also in the case of spiking neurons <ref type="bibr" target="#b376">(Klampfl &amp; Maass, 2013;</ref><ref type="bibr" target="#b829">Yin, Meng, &amp; Jin, 2012</ref>) (Section 5.26). Direct search methods are relevant not only for SL but also for more general RL, and are discussed in more detail in Section 6.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.10.">1991: UL-based history compression through a deep stack of RNNs</head><p>A working Very Deep Learner (Section 3) of 1991 <ref type="bibr" target="#b651">(Schmidhuber, 1992b</ref><ref type="bibr" target="#b661">(Schmidhuber, , 2013a) )</ref> could perform credit assignment across hundreds of nonlinear operators or neural layers, by using unsupervised pretraining for a hierarchy of RNNs.</p><p>The basic idea is still relevant today. Each RNN is trained for a while in unsupervised fashion to predict its next input (e.g., <ref type="bibr" target="#b143">Connor, Martin, &amp; Atlas, 1994;</ref><ref type="bibr" target="#b175">Dorffner, 1996)</ref>. From then on, only unexpected inputs (errors) convey new information and get fed to the next higher RNN which thus ticks on a slower, self-organizing time scale. It can easily be shown that no information gets lost. It just gets compressed (much of machine learning is essentially about compression, e.g., <ref type="bibr">Sections 4.4,</ref><ref type="bibr">5.6.3,</ref><ref type="bibr">6.7)</ref>. For each individual input sequence, we get a series of less and less redundant encodings in deeper and deeper levels of this History Compressor or Neural Sequence Chunker, which can compress data in both space (like feedforward NNs) and time. This is another good example of hierarchical representation learning (Section 4.3). There also is a continuous variant of the history compressor <ref type="bibr" target="#b666">(Schmidhuber, Mozer, &amp; Prelinger, 1993)</ref>.</p><p>The RNN stack is essentially a deep generative model of the data, which can be reconstructed from its compressed form. Adding another RNN to the stack improves a bound on the data's description length -equivalent to the negative logarithm of its probability <ref type="bibr" target="#b320">(Huffman, 1952;</ref><ref type="bibr" target="#b689">Shannon, 1948</ref>) -as long as there is remaining local learnable predictability in the data representation on the corresponding level of the hierarchy. Compare a similar observation for feedforward Deep Belief Networks <ref type="bibr">(DBNs, 2006, Section 5.15)</ref>.</p><p>The system was able to learn many previously unlearnable DL tasks. One ancient illustrative DL experiment <ref type="bibr" target="#b653">(Schmidhuber, 1993b)</ref> required CAPs (Section 3) of depth 1200. The top level code of the initially unsupervised RNN stack, however, got so compact that (previously infeasible) sequence classification through additional BP-based SL became possible. Essentially the system used UL to greatly reduce problem depth. Compare earlier BP-based finetuning of NNs initialized by rules of propositional logic <ref type="bibr" target="#b691">(Shavlik &amp; Towell, 1989</ref>) (Section 5.6.1).</p><p>There is a way of compressing higher levels down into lower levels, thus fully or partially collapsing the RNN stack. The trick is to retrain a lower-level RNN to continually imitate (predict) the hidden units of an already trained, slower, higher-level RNN (the ''conscious'' chunker), through additional predictive output neurons <ref type="bibr" target="#b651">(Schmidhuber, 1992b)</ref>. This helps the lower RNN (the automatizer) to develop appropriate, rarely changing memories that may bridge very long time lags. Again, this procedure can greatly reduce the required depth of the BP process.</p><p>The 1991 system was a working Deep Learner in the modern post-2000 sense, and also a first Neural Hierarchical Temporal Memory (HTM). It is conceptually similar to earlier AE hierarchies (1987, Section 5.7) and later Deep Belief Networks (2006, Section 5.15), but more general in the sense that it uses sequence-processing RNNs instead of FNNs with unchanging inputs. More recently, wellknown entrepreneurs <ref type="bibr" target="#b285">(Hawkins &amp; George, 2006;</ref><ref type="bibr" target="#b401">Kurzweil, 2012)</ref> also got interested in HTMs; compare also hierarchical HMMs (e.g., <ref type="bibr" target="#b203">Fine, Singer, &amp; Tishby, 1998)</ref>, as well as later UL-based recurrent systems <ref type="bibr" target="#b376">(Klampfl &amp; Maass, 2013;</ref><ref type="bibr" target="#b377">Klapper-Rybicka et al., 2001;</ref><ref type="bibr" target="#b717">Steil, 2007;</ref><ref type="bibr" target="#b831">Young, Davis, Mishtal, &amp; Arel, 2014)</ref>. Clockwork RNNs <ref type="bibr" target="#b393">(Koutník, Greff, Gomez, &amp; Schmidhuber, 2014</ref>) also consist of interacting RNN modules with different clock rates, but do not use UL to set those rates. Stacks of RNNs were used in later work on SL with great success, e.g., <ref type="bibr">Sections 5.13, 5.16, 5.17, 5.22. 5.11. 1992: Max-Pooling (MP)</ref>: towards MPCNNs (compare <ref type="bibr">Sections 5.16,</ref><ref type="bibr">5.19)</ref> The Neocognitron (Section 5.4) inspired the Cresceptron <ref type="bibr">(Weng et al., 1992)</ref>, which adapts its topology during training (Section 5.6.3); compare the incrementally growing and shrinking GMDH networks <ref type="bibr">(1965, Section 5.3)</ref>.</p><p>Instead of using alternative local subsampling or WTA methods (e.g., <ref type="bibr" target="#b218">Fukushima, 1980</ref><ref type="bibr" target="#b220">Fukushima, , 2013a;;</ref><ref type="bibr" target="#b456">Maass, 2000;</ref><ref type="bibr" target="#b643">Schmidhuber, 1989b)</ref>, the Cresceptron uses Max-Pooling (MP) layers. Here a 2dimensional layer or array of unit activations is partitioned into smaller rectangular arrays. Each is replaced in a downsampling layer by the activation of its maximally active unit. A later, more complex version of the Cresceptron <ref type="bibr" target="#b780">(Weng, Ahuja, &amp; Huang, 1997</ref>) also included ''blurring'' layers to improve object location tolerance.</p><p>The neurophysiologically plausible topology of the feedforward HMAX model <ref type="bibr" target="#b600">(Riesenhuber &amp; Poggio, 1999)</ref> is very similar to the one of the 1992 Cresceptron (and thus to the 1979 Neocognitron). HMAX does not learn though. Its units have hand-crafted weights; biologically plausible learning rules were later proposed for similar models (e.g., <ref type="bibr" target="#b685">Serre, Riesenhuber, Louie, &amp; Poggio, 2002;</ref><ref type="bibr" target="#b737">Teichmann, Wiltschut, &amp; Hamker, 2012)</ref>.</p><p>When CNNs or convnets (Sections 5.4, 5.8) are combined with MP, they become Cresceptron-like or HMAX-like MPCNNs with alternating convolutional and max-pooling layers. Unlike Cresceptron and HMAX, however, MPCNNs are trained by BP (Sections 5.5, 5.16) <ref type="bibr" target="#b589">(Ranzato, Huang, Boureau, &amp; LeCun, 2007)</ref>. Advantages of doing this were pointed out subsequently <ref type="bibr" target="#b640">(Scherer, Müller, &amp; Behnke, 2010)</ref>. BP-trained MPCNNs have become central to many modern, competition-winning, feedforward, visual Deep Learners (Sections 5.17, 5.19-5.23).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.12.">1994: early contest-winning NNs</head><p>Back in the 1990s, certain NNs already won certain controlled pattern recognition contests with secret test sets. Notably, an NN with internal delay lines won the Santa Fe time-series competition on chaotic intensity pulsations of an NH3 laser <ref type="bibr" target="#b768">(Wan, 1994;</ref><ref type="bibr" target="#b777">Weigend &amp; Gershenfeld, 1993)</ref>. No very deep CAPs (Section 3) were needed though.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.13.">1995: supervised recurrent very Deep Learner (LSTM RNN)</head><p>Supervised Long Short-Term Memory (LSTM) RNNs <ref type="bibr" target="#b230">(Gers, Schmidhuber, &amp; Cummins, 2000;</ref><ref type="bibr" target="#b307">Hochreiter &amp; Schmidhuber, 1997b;</ref><ref type="bibr" target="#b564">Pérez-Ortiz, Gers, Eck, &amp; Schmidhuber, 2003)</ref> could eventually perform similar feats as the deep RNN hierarchy of 1991 (Section 5.10), overcoming the Fundamental Deep Learning Problem (Section 5.9) without any unsupervised pre-training. LSTM could also learn DL tasks without local sequence predictability (and thus unlearnable by the partially unsupervised 1991 History Compressor, Section 5.10), dealing with very deep problems (Section 3) (e.g., <ref type="bibr" target="#b231">Gers, Schraudolph, &amp; Schmidhuber, 2002)</ref>.</p><p>The basic LSTM idea is very simple. Some of the units are called Constant Error Carousels (CECs). Each CEC uses as an activation function f , the identity function, and has a connection to itself with fixed weight of 1.0. Due to f 's constant derivative of 1.0, errors backpropagated through a CEC cannot vanish or explode (Section 5.9) but stay as they are (unless they ''flow out'' of the CEC to other, typically adaptive parts of the NN). CECs are connected to several nonlinear adaptive units (some with multiplicative activation functions) needed for learning nonlinear behavior. Weight changes of these units often profit from error signals propagated far back in time through CECs. CECs are the main reason why LSTM nets can learn to discover the importance of (and memorize) events that happened thousands of discrete time steps ago, while previous RNNs already failed in case of minimal time lags of 10 steps.</p><p>Many different LSTM variants and topologies are allowed. It is possible to evolve good problem-specific topologies <ref type="bibr" target="#b80">(Bayer, Wierstra, Togelius, &amp; Schmidhuber, 2009)</ref>. Some LSTM variants also use modifiable self-connections of CECs <ref type="bibr" target="#b229">(Gers &amp; Schmidhuber, 2001)</ref>.</p><p>To a certain extent, LSTM is biologically plausible <ref type="bibr" target="#b543">(O'Reilly, 2003)</ref>. LSTM learned to solve many previously unlearnable DL tasks involving: Recognition of the temporal order of widely separated events in noisy input streams; Robust storage of highprecision real numbers across extended time intervals; Arithmetic operations on continuous input streams; Extraction of information conveyed by the temporal distance between events; Recognition of temporally extended patterns in noisy input sequences <ref type="bibr">(Gers et al., 2000;</ref><ref type="bibr" target="#b307">Hochreiter &amp; Schmidhuber, 1997b)</ref>; Stable generation of precisely timed rhythms, as well as smooth and non-smooth periodic trajectories <ref type="bibr">(Gers &amp; Schmidhuber, 2000)</ref>. LSTM clearly outperformed previous RNNs on tasks that require learning the rules of regular languages describable by deterministic Finite State Automata (FSAs) <ref type="bibr" target="#b103">(Blair &amp; Pollack, 1997;</ref><ref type="bibr" target="#b132">Casey, 1996;</ref><ref type="bibr" target="#b362">Kalinke &amp; Lehmann, 1998;</ref><ref type="bibr" target="#b469">Manolios &amp; Fanelli, 1994;</ref><ref type="bibr" target="#b540">Omlin &amp; Giles, 1996;</ref><ref type="bibr" target="#b692">Siegelmann, 1992;</ref><ref type="bibr" target="#b754">Vahed &amp; Omlin, 2004;</ref><ref type="bibr" target="#b775">Watrous &amp; Kuhn, 1992;</ref><ref type="bibr" target="#b837">Zeng, Goodman, &amp; Smyth, 1994)</ref>, both in terms of reliability and speed.</p><p>LSTM also worked on tasks involving context free languages (CFLs) that cannot be represented by HMMs or similar FSAs discussed in the RNN literature <ref type="bibr" target="#b42">(Andrews, Diederich, &amp; Tickle, 1995;</ref><ref type="bibr" target="#b610">Rodriguez &amp; Wiles, 1998;</ref><ref type="bibr" target="#b611">Rodriguez, Wiles, &amp; Elman, 1999;</ref><ref type="bibr" target="#b716">Steijvers &amp; Grunwald, 1996;</ref><ref type="bibr" target="#b724">Sun, Giles, Chen, &amp; Lee, 1993;</ref><ref type="bibr" target="#b743">Tonkes &amp; Wiles, 1997;</ref><ref type="bibr" target="#b804">Wiles &amp; Elman, 1995)</ref>. CFL recognition <ref type="bibr" target="#b416">(Lee, 1996)</ref> requires the functional equivalent of a runtime stack. Some previous RNNs failed to learn small CFL training sets <ref type="bibr" target="#b610">(Rodriguez &amp; Wiles, 1998)</ref>. Those that did not <ref type="bibr" target="#b108">(Bodén &amp; Wiles, 2000;</ref><ref type="bibr" target="#b611">Rodriguez et al., 1999)</ref> failed to extract the general rules, and did not generalize well on substantially larger test sets. Similar for context-sensitive languages (CSLs) (e.g., <ref type="bibr" target="#b135">Chalup &amp; Blair, 2003)</ref>. LSTM generalized well though, requiring only the 30 shortest exemplars (n ≤ 10) of the CSL a n b n c n to correctly predict the possible continuations of sequence prefixes for n up to 1000 and more. A combination of a decoupled extended Kalman filter <ref type="bibr" target="#b194">(Feldkamp, Prokhorov, Eagen, &amp; Yuan, 1998;</ref><ref type="bibr" target="#b194">Feldkamp, Prokhorov, &amp; Feldkamp, 2003;</ref><ref type="bibr" target="#b286">Haykin, 2001;</ref><ref type="bibr" target="#b363">Kalman, 1960;</ref><ref type="bibr" target="#b585">Puskorius &amp; Feldkamp, 1994;</ref><ref type="bibr" target="#b809">Williams, 1992b)</ref> and an LSTM RNN <ref type="bibr" target="#b564">(Pérez-Ortiz et al., 2003)</ref> learned to deal correctly with values of n up to 10 million and more. That is, after training the network was able to read sequences of 30,000,000 symbols and more, one symbol at a time, and finally detect the subtle differences between legal strings such as a 10,000,000 b 10,000,000 c 10,000,000 and very similar but illegal strings such as a 10,000,000 b 9,999,999 c 10,000,000 . Compare also more recent RNN algorithms able to deal with long time lags <ref type="bibr" target="#b393">(Koutník et al., 2014;</ref><ref type="bibr" target="#b474">Martens &amp; Sutskever, 2011;</ref><ref type="bibr" target="#b635">Schäfer, Udluft, &amp; Zimmermann, 2006;</ref><ref type="bibr" target="#b838">Zimmermann, Tietz, &amp; Grothmann, 2012)</ref>.</p><p>Bi-directional RNNs (BRNNs) <ref type="bibr" target="#b678">(Schuster, 1999;</ref><ref type="bibr">Schuster &amp; Paliwal, 1997)</ref> are designed for input sequences whose starts and ends are known in advance, such as spoken sentences to be labeled by their phonemes; compare <ref type="bibr" target="#b216">Fukada, Schuster, and Sagisaka (1999)</ref>. To take both past and future context of each sequence element into account, one RNN processes the sequence from start to end, the other backwards from end to start. At each time step their combined outputs predict the corresponding label (if there is any). BRNNs were successfully applied to secondary protein structure prediction <ref type="bibr" target="#b57">(Baldi, Brunak, Frasconi, Pollastri, &amp; Soda, 1999)</ref>. DAG-RNNs <ref type="bibr" target="#b62">(Baldi &amp; Pollastri, 2003;</ref><ref type="bibr" target="#b821">Wu &amp; Baldi, 2008)</ref> generalize BRNNs to multiple dimensions. They learned to predict properties of small organic molecules <ref type="bibr" target="#b452">(Lusci, Pollastri, &amp; Baldi, 2013)</ref> as well as protein contact maps <ref type="bibr" target="#b736">(Tegge, Wang, Eickholt, &amp; Cheng, 2009)</ref>, also in conjunction with a growing deep FNN (Di Lena, Nagata, &amp; Baldi, 2012) (Section 5.21). BRNNs and DAG-RNNs unfold their full potential when combined with the LSTM concept <ref type="bibr">(Graves et al., 2009;</ref><ref type="bibr">Graves &amp; Schmidhuber, 2005</ref><ref type="bibr">, 2009)</ref>.</p><p>Particularly successful in recent competitions are stacks (Section 5.10) of LSTM RNNs <ref type="bibr" target="#b198">(Fernandez, Graves, &amp; Schmidhuber, 2007b;</ref><ref type="bibr">Graves &amp; Schmidhuber, 2009)</ref> trained by Connectionist Temporal Classification (CTC) <ref type="bibr" target="#b256">(Graves, Fernandez, Gomez, &amp; Schmidhuber, 2006)</ref>, a gradient-based method for finding RNN weights that maximize the probability of teacher-given label sequences, given (typically much longer and more high-dimensional) streams of real-valued input vectors. CTC-LSTM performs simultaneous segmentation (alignment) and recognition (Section 5.22).</p><p>In the early 2000s, speech recognition was dominated by HMMs combined with FNNs (e.g., <ref type="bibr" target="#b113">Bourlard &amp; Morgan, 1994)</ref>. Nevertheless, when trained from scratch on utterances from the TIDIGITS speech database, in 2003 LSTM already obtained results comparable to those of HMM-based systems <ref type="bibr" target="#b98">(Beringer, Graves, Schiel, &amp; Schmidhuber, 2005;</ref><ref type="bibr" target="#b255">Graves, Eck, Beringer, &amp; Schmidhuber, 2003;</ref><ref type="bibr" target="#b256">Graves et al., 2006)</ref>. In 2007, LSTM outperformed HMMs in keyword spotting tasks <ref type="bibr" target="#b197">(Fernández, Graves, &amp; Schmidhuber, 2007a)</ref>; compare recent improvements <ref type="bibr" target="#b330">(Indermuhle, Frinken, Fischer, &amp; Bunke, 2011;</ref><ref type="bibr" target="#b818">Wöllmer, Schuller, &amp; Rigoll, 2013)</ref>. By 2013, LSTM also achieved best known results on the famous TIMIT phoneme recognition benchmark <ref type="bibr" target="#b260">(Graves, Mohamed, &amp; Hinton, 2013)</ref>  <ref type="bibr">(Section 5.22)</ref>. Recently, LSTM RNN/HMM hybrids obtained best known performance on medium-vocabulary <ref type="bibr" target="#b226">(Geiger, Zhang, Weninger, Schuller, &amp; Rigoll, 2014)</ref> and large-vocabulary speech recognition <ref type="bibr" target="#b624">(Sak, Senior, &amp; Beaufays, 2014)</ref>.</p><p>LSTM is also applicable to robot localization (Förster, Graves, &amp; Schmidhuber, 2007), robot control <ref type="bibr" target="#b478">(Mayer et al., 2008)</ref>, online driver distraction detection <ref type="bibr" target="#b817">(Wöllmer et al., 2011)</ref>, and many other tasks. For example, it helped to improve the state of the art in diverse applications such as protein analysis <ref type="bibr" target="#b306">(Hochreiter &amp; Obermayer, 2005)</ref>, handwriting recognition <ref type="bibr" target="#b105">(Bluche et al., 2014;</ref><ref type="bibr" target="#b257">Graves, Fernandez, Liwicki, Bunke, &amp; Schmidhuber, 2008;</ref><ref type="bibr">Graves et al., 2009;</ref><ref type="bibr">Graves &amp; Schmidhuber, 2009)</ref>, voice activity detection (Eyben, Weninger, Squartini, &amp; Schuller, 2013), optical character recognition <ref type="bibr" target="#b119">(Breuel, Ul-Hasan, Al-Azawi, &amp; Shafait, 2013)</ref>, language identification (Gonzalez-Dominguez, Lopez-Moreno, Sak, Gonzalez-Rodriguez, &amp; Moreno, 2014), prosody contour prediction <ref type="bibr" target="#b199">(Fernandez, Rendel, Ramabhadran, &amp; Hoory, 2014)</ref>, audio onset detection <ref type="bibr" target="#b470">(Marchi et al., 2014</ref>), text-to-speech synthesis <ref type="bibr" target="#b192">(Fan, Qian, Xie, &amp; Soong, 2014)</ref>, social signal classification <ref type="bibr" target="#b122">(Brueckner &amp; Schulter, 2014)</ref>, machine translation <ref type="bibr" target="#b728">(Sutskever, Vinyals, &amp; Le, 2014)</ref>, and others.</p><p>RNNs can also be used for metalearning <ref type="bibr" target="#b582">(Prokhorov, Feldkamp, &amp; Tyukin, 2002;</ref><ref type="bibr">Schaul &amp; Schmidhuber, 2010;</ref><ref type="bibr" target="#b641">Schmidhuber, 1987)</ref>, because they can in principle learn to run their own weight change algorithm <ref type="bibr" target="#b652">(Schmidhuber, 1993a)</ref>. A successful metalearner <ref type="bibr" target="#b309">(Hochreiter, Younger, &amp; Conwell, 2001</ref>) used an LSTM RNN to quickly learn a learning algorithm for quadratic functions (compare Section 6.8).</p><p>Recently, LSTM RNNs won several international pattern recognition competitions and set numerous benchmark records on large and complex data sets, e.g., Sections 5.17, 5.21, 5.22. Gradientbased LSTM is no panacea though-other methods sometimes outperformed it at least on certain tasks <ref type="bibr" target="#b343">(Jaeger, 2004;</ref><ref type="bibr" target="#b393">Koutník et al., 2014;</ref><ref type="bibr" target="#b474">Martens &amp; Sutskever, 2011;</ref><ref type="bibr" target="#b557">Pascanu, Mikolov, &amp; Bengio, 2013;</ref><ref type="bibr" target="#b669">Schmidhuber et al., 2007)</ref>; compare Section 5.20.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.14.">2003: more contest-winning/record-setting NNs; successful deep NNs</head><p>In the decade around 2000, many practical and commercial pattern recognition applications were dominated by non-neural machine learning methods such as Support Vector Machines (SVMs) <ref type="bibr" target="#b672">(Schölkopf et al., 1998;</ref><ref type="bibr" target="#b758">Vapnik, 1995)</ref>. Nevertheless, at least in certain domains, NNs outperformed other techniques.</p><p>A Bayes NN <ref type="bibr">(Neal, 2006)</ref> based on an ensemble <ref type="bibr" target="#b117">(Breiman, 1996;</ref><ref type="bibr" target="#b169">Dietterich, 2000a;</ref><ref type="bibr" target="#b280">Hashem &amp; Schmeiser, 1992;</ref><ref type="bibr" target="#b636">Schapire, 1990;</ref><ref type="bibr" target="#b751">Ueda, 2000;</ref><ref type="bibr" target="#b819">Wolpert, 1992)</ref> of NNs won the NIPS 2003 Feature Selection Challenge with secret test set <ref type="bibr" target="#b524">(Neal &amp; Zhang, 2006)</ref>. The NN was not very deep though-it had two hidden layers and thus rather shallow CAPs (Section 3) of depth 3.</p><p>Important for many present competition-winning pattern recognizers <ref type="bibr">(Sections 5.19,</ref><ref type="bibr">5.21,</ref><ref type="bibr">5.22)</ref> were developments in the CNN department. A BP-trained <ref type="bibr" target="#b410">(LeCun et al., 1989</ref>) CNN (Sections 5.4, 5.8) set a new MNIST record of 0.4% <ref type="bibr" target="#b697">(Simard, Steinkraus, &amp; Platt, 2003)</ref>, using training pattern deformations <ref type="bibr" target="#b50">(Baird, 1990)</ref> but no unsupervised pre-training (Sections 5.7, 5.10, 5.15). A standard BP net achieved 0.7% <ref type="bibr" target="#b697">(Simard et al., 2003)</ref>. Again, the corresponding CAP depth was low. Compare further improvements in <ref type="bibr">Sections 5.16,</ref><ref type="bibr">5.18,</ref><ref type="bibr">5.19</ref>.</p><p>Good image interpretation results <ref type="bibr" target="#b88">(Behnke, 2003b)</ref> were achieved with rather deep NNs trained by the BP variant R-prop <ref type="bibr" target="#b598">(Riedmiller &amp; Braun, 1993</ref>) (Section 5.6.2); here feedback through recurrent connections helped to improve image interpretation. FNNs with CAP depth up to 6 were used to successfully classify high-dimensional data <ref type="bibr" target="#b761">(Vieira &amp; Barradas, 2003)</ref>.</p><p>Deep LSTM RNNs started to obtain certain first speech recognition results comparable to those of HMM-based systems <ref type="bibr" target="#b255">(Graves et al., 2003)</ref>; compare <ref type="bibr">Sections 5.13,</ref><ref type="bibr">5.16,</ref><ref type="bibr">5.21,</ref><ref type="bibr">5.22</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.15.">2006/7: UL for deep belief networks/AE stacks fine-tuned by BP</head><p>While learning networks with numerous non-linear layers date back at least to 1965 (Section 5.3), and explicit DL research results have been published at least since 1991 (Sections 5.9, 5.10), the expression Deep Learning was actually coined around 2006, when unsupervised pre-training of deep FNNs helped to accelerate subsequent SL through BP <ref type="bibr" target="#b300">(Hinton, Osindero, &amp; Teh, 2006;</ref><ref type="bibr" target="#b301">Hinton &amp; Salakhutdinov, 2006)</ref>. Compare earlier terminology on loading deep networks <ref type="bibr" target="#b695">(Síma, 1994;</ref><ref type="bibr" target="#b814">Windisch, 2005)</ref> and learning deep memories <ref type="bibr" target="#b247">(Gomez &amp; Schmidhuber, 2005)</ref>. Compare also BP-based (Section 5.5) fine-tuning (Section 5.6.1) of (not so deep) FNNs pretrained by competitive UL <ref type="bibr" target="#b461">(Maclin &amp; Shavlik, 1995)</ref>.</p><p>The Deep Belief Network (DBN) is a stack of Restricted Boltzmann Machines (RBMs) <ref type="bibr" target="#b704">(Smolensky, 1986)</ref>, which in turn are Boltzmann Machines (BMs) <ref type="bibr" target="#b302">(Hinton &amp; Sejnowski, 1986</ref>) with a single layer of feature-detecting units; compare also Higher-Order BMs <ref type="bibr" target="#b481">(Memisevic &amp; Hinton, 2010)</ref>. Each RBM perceives pattern representations from the level below and learns to encode them in unsupervised fashion. At least in theory under certain assumptions, adding more layers improves a bound on the data's negative log probability <ref type="bibr">(Hinton et al., 2006</ref>) (equivalent to the data's description length-compare the corresponding observation for RNN stacks, Section 5.10). There are extensions for Temporal RBMs <ref type="bibr" target="#b727">(Sutskever, Hinton, &amp; Taylor, 2008)</ref>.</p><p>Without any training pattern deformations (Section 5.14), a DBN fine-tuned by BP achieved 1.2% error rate <ref type="bibr" target="#b301">(Hinton &amp; Salakhutdinov, 2006)</ref> on the MNIST handwritten digits <ref type="bibr">(Sections 5.8,</ref><ref type="bibr">5.14)</ref>. This result helped to arouse interest in DBNs. DBNs also achieved good results on phoneme recognition, with an error rate of 26.7% on the TIMIT core test set <ref type="bibr" target="#b498">(Mohamed &amp; Hinton, 2010)</ref>; compare further improvements through FNNs <ref type="bibr" target="#b161">(Deng &amp; Yu, 2014;</ref><ref type="bibr" target="#b298">Hinton, Deng, et al., 2012)</ref> and LSTM RNNs (Section 5.22).</p><p>A DBN-based technique called Semantic Hashing <ref type="bibr" target="#b626">(Salakhutdinov &amp; Hinton, 2009)</ref> maps semantically similar documents (of variable size) to nearby addresses in a space of document representations. It outperformed previous searchers for similar documents, such as Locality Sensitive Hashing <ref type="bibr" target="#b126">(Buhler, 2001;</ref><ref type="bibr" target="#b151">Datar, Immorlica, Indyk, &amp; Mirrokni, 2004)</ref>. See the RBM/DBN tutorial <ref type="bibr" target="#b204">(Fischer &amp; Igel, 2014)</ref>.</p><p>Autoencoder (AE) stacks <ref type="bibr" target="#b64">(Ballard, 1987</ref>) (Section 5.7) became a popular alternative way of pre-training deep FNNs in unsupervised fashion, before fine-tuning (Section 5.6.1) them through BP (Section 5.5) <ref type="bibr" target="#b96">(Bengio, Lamblin, Popovici, &amp; Larochelle, 2007;</ref><ref type="bibr" target="#b184">Erhan et al., 2010;</ref><ref type="bibr" target="#b763">Vincent, Hugo, Bengio, &amp; Manzagol, 2008)</ref>. Sparse coding (Section 5.6.4) was formulated as a combination of convex optimization problems <ref type="bibr" target="#b417">(Lee, Battle, Raina, &amp; Ng, 2007)</ref>. Recent surveys of stacked RBM and AE methods focus on post-2006 developments <ref type="bibr" target="#b45">(Arel, Rose, &amp; Karnowski, 2010;</ref><ref type="bibr" target="#b94">Bengio, 2009)</ref>. Unsupervised DBNs and AE stacks are conceptually similar to, but in a certain sense less general than, the unsupervised RNN stack-based History Compressor of 1991 (Section 5.10), which can process and re-encode not only stationary input patterns, but entire pattern sequences. <ref type="bibr">in 2006</ref><ref type="bibr">, a BP-trained (LeCun et al., 1989) CNN (Sections 5.4, 5.8)</ref> set a new MNIST record of 0.39% <ref type="bibr" target="#b590">(Ranzato, Poultney, Chopra, &amp; LeCun, 2006)</ref>, using training pattern deformations (Section 5.14) but no unsupervised pre-training. Compare further improvements in <ref type="bibr">Sections 5.18,</ref><ref type="bibr">5.19</ref>. Similar CNNs were used for off-road obstacle avoidance <ref type="bibr" target="#b414">(LeCun, Muller, Cosatto, &amp; Flepp, 2006)</ref>. A combination of CNNs and TDNNs later learned to map fixed-size representations of variable-size sentences to features relevant for language processing, using a combination of SL and UL <ref type="bibr">(Collobert &amp; Weston, 2008)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.16.">2006/7: improved CNNs/GPU-CNNs/BP for MPCNNs/LSTM stacks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Also</head><p>2006 also saw an early GPU-based CNN implementation <ref type="bibr" target="#b136">(Chellapilla, Puri, &amp; Simard, 2006)</ref> up to 4 times faster than CPU-CNNs; compare also earlier GPU implementations of standard FNNs with a reported speed-up factor of 20 <ref type="bibr" target="#b536">(Oh &amp; Jung, 2004)</ref>. GPUs or graphics cards have become more and more important for DL in subsequent years .</p><p>In 2007, BP (Section 5.5) was applied for the first time <ref type="bibr" target="#b589">(Ranzato et al., 2007)</ref> to Neocognitron-inspired (Section 5.4), Cresceptronlike (or HMAX-like) MPCNNs (Section 5.11) with alternating convolutional and max-pooling layers. BP-trained MPCNNs have become an essential ingredient of many modern, competitionwinning, feedforward, visual Deep Learners <ref type="bibr">(Sections 5.17,</ref>.</p><p>Also in 2007, hierarchical stacks of LSTM RNNs were introduced <ref type="bibr" target="#b198">(Fernandez et al., 2007b)</ref>. They can be trained by hierarchical Connectionist Temporal Classification (CTC) <ref type="bibr" target="#b256">(Graves et al., 2006)</ref>. For tasks of sequence labeling, every LSTM RNN level (Section 5.13) predicts a sequence of labels fed to the next level. Error signals at every level are back-propagated through all the lower levels. On spoken digit recognition, LSTM stacks outperformed HMMs, despite making fewer assumptions about the domain. LSTM stacks do not necessarily require unsupervised pre-training like the earlier UL-based RNN stacks <ref type="bibr" target="#b651">(Schmidhuber, 1992b)</ref> of Section 5.10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.17.">2009: first official competitions won by RNNs, and with MPCNNs</head><p>Stacks of LSTM RNNs trained by CTC <ref type="bibr">(Sections 5.13,</ref><ref type="bibr">5.16</ref>) became the first RNNs to win official international pattern recognition contests (with secret test sets known only to the organizers). More precisely, three connected handwriting competitions at IC-DAR 2009 in three different languages (French, Arab, Farsi) were won by deep LSTM RNNs without any a priori linguistic knowledge, performing simultaneous segmentation and recognition. Compare <ref type="bibr" target="#b258">Graves and Jaitly (2014)</ref>, <ref type="bibr" target="#b261">Graves and Schmidhuber (2005)</ref>, <ref type="bibr">Graves et al. (2009)</ref>, <ref type="bibr" target="#b260">Graves et al. (2013)</ref> and <ref type="bibr">Schmidhuber, Ciresan, Meier, Masci, and Graves (2011) (Section 5.22)</ref>.</p><p>To detect human actions in surveillance videos, a 3-dimensional CNN (e.g., <ref type="bibr" target="#b344">Jain &amp; Seung, 2009;</ref><ref type="bibr" target="#b581">Prokhorov, 2010)</ref>, combined with SVMs, was part of a larger system <ref type="bibr" target="#b827">(Yang et al., 2009)</ref> using a bag of features approach <ref type="bibr" target="#b533">(Nowak, Jurie, &amp; Triggs, 2006)</ref> to extract regions of interest. The system won three 2009 TRECVID competitions. These were possibly the first official international contests won with the help of (MP)CNNs <ref type="bibr">(Section 5.16</ref>). An improved version of the method was published later <ref type="bibr" target="#b345">(Ji, Xu, Yang, &amp; Yu, 2013)</ref>.</p><p>2009 also saw a GPU-DBN implementation <ref type="bibr" target="#b587">(Raina, Madhavan, &amp; Ng, 2009)</ref> orders of magnitudes faster than previous CPU-DBNs (see Section 5.15); see also <ref type="bibr">Coates et al. (2013)</ref>. The Convolutional DBN <ref type="bibr" target="#b419">(Lee, Grosse, Ranganath, &amp; Ng, 2009)</ref> (with a probabilistic variant of MP, Section 5.11) combines ideas from CNNs and DBNs, and was successfully applied to audio classification <ref type="bibr" target="#b421">(Lee, Pham, Largman, &amp; Ng, 2009)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.18.">2010: plain backprop (+ distortions) on GPU breaks MNIST record</head><p>In 2010, a new MNIST (Section 5.8) record of 0.35% error rate was set by good old BP (Section 5.5) in deep but otherwise standard NNs (Ciresan, Meier, Gambardella, &amp; Schmidhuber, 2010), using neither unsupervised pre-training (e.g., <ref type="bibr">Sections 5.7,</ref><ref type="bibr">5.10,</ref><ref type="bibr">5.15)</ref> nor convolution (e.g., <ref type="bibr">Sections 5.4,</ref><ref type="bibr">5.8,</ref><ref type="bibr">5.14,</ref><ref type="bibr">5.16</ref>). However, training pattern deformations (e.g., Section 5.14) were important to generate a big training set and avoid overfitting. This success was made possible mainly through a GPU implementation of BP that was up to 50 times faster than standard CPU versions. A good value of 0.95% was obtained without distortions except for small saccadic eye movement-like translations-compare Section 5.15.</p><p>Since BP was 3-5 decades old by then (Section 5.5), and pattern deformations 2 decades <ref type="bibr" target="#b50">(Baird, 1990</ref>) (Section 5.14), these results seemed to suggest that advances in exploiting modern computing hardware were more important than advances in algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.19.">2011: MPCNNs on GPU achieve superhuman vision performance</head><p>In 2011, a flexible GPU-implementation (Ciresan, Meier, <ref type="bibr">Masci, Gambardella, &amp; Schmidhuber, 2011)</ref> of Max-Pooling (MP) CNNs or Convnets was described (a GPU-MPCNN), building on earlier MP work <ref type="bibr">(Weng et al., 1992</ref>) (Section 5.11) CNNs <ref type="bibr" target="#b217">(Fukushima, 1979;</ref><ref type="bibr">LeCun et al., 1989) (Sections 5.4, 5.8, 5.16)</ref>, and on early GPUbased CNNs without MP <ref type="bibr">(Chellapilla et al., 2006) (Section 5.16</ref>); compare early GPU-NNs <ref type="bibr" target="#b536">(Oh &amp; Jung, 2004)</ref> and GPU-DBNs <ref type="bibr" target="#b587">(Raina et al., 2009</ref>) (Section 5.17). MPCNNs have alternating convolutional layers (Section 5.4) and max-pooling layers (MP, Section 5.11) topped by standard fully connected layers. All weights are trained by BP <ref type="bibr">(Sections 5.5,</ref><ref type="bibr">5.8,</ref><ref type="bibr">5.16</ref>) <ref type="bibr" target="#b589">(Ranzato et al., 2007;</ref><ref type="bibr" target="#b640">Scherer et al., 2010)</ref>. GPU-MPCNNs have become essential for many contestwinning FNNs <ref type="bibr">(Sections 5.21,</ref><ref type="bibr">5.22)</ref>.</p><p>Multi-Column GPU-MPCNNs (Ciresan, Meier, Masci, &amp; Schmidhuber, 2011) are committees <ref type="bibr" target="#b117">(Breiman, 1996;</ref><ref type="bibr" target="#b169">Dietterich, 2000a;</ref><ref type="bibr" target="#b280">Hashem &amp; Schmeiser, 1992;</ref><ref type="bibr" target="#b636">Schapire, 1990;</ref><ref type="bibr" target="#b751">Ueda, 2000;</ref><ref type="bibr" target="#b819">Wolpert, 1992)</ref> of GPU-MPCNNs with simple democratic output averaging. Several MPCNNs see the same input; their output vectors are used to assign probabilities to the various possible classes. The class with the on average highest probability is chosen as the system's classification of the present input. Compare earlier, more sophisticated ensemble methods <ref type="bibr" target="#b636">(Schapire, 1990)</ref>, the contest-winning ensemble Bayes-NN <ref type="bibr">(Neal, 2006)</ref> of Section 5.14, and recent related work <ref type="bibr" target="#b690">(Shao, Wu, &amp; Li, 2014</ref>).</p><p>An ensemble of GPU-MPCNNs was the first system to achieve superhuman visual pattern recognition (Ciresan, Meier, <ref type="bibr" target="#b663">Masci, Schmidhuber, 2011;</ref><ref type="bibr">Ciresan, Meier, Masci, &amp; Schmidhuber, 2012)</ref> in a controlled competition, namely, the IJCNN 2011 traffic sign recognition contest in San Jose (CA) <ref type="bibr" target="#b712">(Stallkamp, Schlipsing, Salmen, &amp; Igel, 2011</ref><ref type="bibr">, 2012)</ref>. This is of interest for fully autonomous, selfdriving cars in traffic (e.g., <ref type="bibr" target="#b167">Dickmanns et al., 1994)</ref>. The GPU-MPCNN ensemble obtained 0.56% error rate and was twice better than human test subjects, three times better than the closest artificial NN competitor <ref type="bibr" target="#b683">(Sermanet &amp; LeCun, 2011)</ref>, and six times better than the best non-neural method.</p><p>A few months earlier, the qualifying round was won in a 1st stage online competition, albeit by a much smaller margin: 1.02% (Ciresan, Meier, Masci, Schmidhuber, 2011) vs 1.03% for second place <ref type="bibr" target="#b683">(Sermanet &amp; LeCun, 2011)</ref>. After the deadline, the organizers revealed that human performance on the test set was 1.19%. That is, the best methods already seemed human-competitive. However, during the qualifying it was possible to incrementally gain information about the test set by probing it through repeated submissions. This is illustrated by better and better results obtained by various teams over time <ref type="bibr" target="#b713">(Stallkamp et al., 2012)</ref> (the organizers eventually imposed a limit of 10 resubmissions). In the final competition this was not possible.</p><p>This illustrates a general problem with benchmarks whose test sets are public, or at least can be probed to some extent: competing teams tend to overfit on the test set even when it cannot be directly used for training, only for evaluation.</p><p>In 1997 many thought it a big deal that human chess world champion Kasparov was beaten by an IBM computer. But back then computers could not at all compete with little kids in visual pattern recognition, which seems much harder than chess from a computational perspective. Of course, the traffic sign domain is highly restricted, and kids are still much better general pattern recognizers. Nevertheless, by 2011, deep NNs could already learn to rival them in important limited visual domains.</p><p>An ensemble of GPU-MPCNNs was also the first method to achieve human-competitive performance (around 0.2%) on MNIST <ref type="bibr">(Ciresan, Meier, &amp; Schmidhuber, 2012a)</ref>. This represented a dramatic improvement, since by then the MNIST record had hovered around 0.4% for almost a decade <ref type="bibr">(Sections 5.14,</ref><ref type="bibr">5.16,</ref><ref type="bibr">5.18)</ref>.</p><p>Given all the prior work on (MP)CNNs <ref type="bibr">(Sections 5.4,</ref><ref type="bibr">5.8,</ref><ref type="bibr">5.11,</ref><ref type="bibr">5.16</ref>) and GPU-CNNs (Section 5.16), GPU-MPCNNs are not a breakthrough in the scientific sense. But they are a commercially relevant breakthrough in efficient coding that has made a difference in several contests since 2011. Today, most feedforward competition-winning deep NNs are (ensembles of) GPU-MPCNNs (Sections 5.21-5.23).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.20.">2011: Hessian-free optimization for RNNs</head><p>Also in 2011 it was shown <ref type="bibr" target="#b474">(Martens &amp; Sutskever, 2011)</ref> that Hessian-free optimization (e.g., <ref type="bibr" target="#b500">Møller, 1993;</ref><ref type="bibr" target="#b560">Pearlmutter, 1994;</ref><ref type="bibr" target="#b673">Schraudolph, 2002)</ref> (Section 5.6.2) can alleviate the Fundamental Deep Learning Problem (Section 5.9) in RNNs, outperforming standard gradient-based LSTM RNNs (Section 5.13) on several tasks. Compare other RNN algorithms <ref type="bibr" target="#b343">(Jaeger, 2004;</ref><ref type="bibr" target="#b393">Koutník et al., 2014;</ref><ref type="bibr" target="#b557">Pascanu, Mikolov, et al., 2013;</ref><ref type="bibr" target="#b669">Schmidhuber et al., 2007</ref>) that also at least sometimes yield better results than steepest descent for LSTM RNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.21.">2012: first contests won on ImageNet, object detection, segmentation</head><p>In 2012, an ensemble of GPU-MPCNNs (Section 5.19) achieved best results on the ImageNet classification benchmark <ref type="bibr">(Krizhevsky, Sutskever, &amp; Hinton, 2012)</ref>, which is popular in the computer vision community. Here relatively large image sizes of 256 × 256 pixels were necessary, as opposed to only 48 × 48 pixels for the 2011 traffic sign competition (Section 5.19). See further improvements in Section 5.22.</p><p>Also in 2012, the biggest NN so far (10 9 free parameters) was trained in unsupervised mode <ref type="bibr">(Sections 5.7,</ref><ref type="bibr">5.15</ref>) on unlabeled data <ref type="bibr" target="#b408">(Le et al., 2012)</ref>, then applied to ImageNet. The codes across its top layer were used to train a simple supervised classifier, which achieved best results so far on 20,000 classes. Instead of relying on efficient GPU programming, this was done by brute force on 1000 standard machines with 16,000 cores.</p><p>So by 2011/2012, excellent results had been achieved by Deep Learners in image recognition and classification <ref type="bibr">(Sections 5.19,</ref><ref type="bibr">5.21)</ref>. The computer vision community, however, is especially interested in object detection in large images, for applications such as image-based search engines, or for biomedical diagnosis where the goal may be to automatically detect tumors etc. in images of human tissue. Object detection presents additional challenges. One natural approach is to train a deep NN classifier on patches of big images, then use it as a feature detector to be shifted across unknown visual scenes, using various rotations and zoom factors. Image parts that yield highly active output units are likely to contain objects similar to those the NN was trained on.</p><p>2012 finally saw the first DL system (an ensemble of GPU-MPCNNs, Section 5.19) to win a contest on visual object detection (Ciresan, <ref type="bibr" target="#b237">Giusti, Gambardella, &amp; Schmidhuber, 2013)</ref> in large images of several million pixels <ref type="bibr">(ICPR, 2012;</ref><ref type="bibr" target="#b616">Roux et al., 2013)</ref>. Such biomedical applications may turn out to be among the most important applications of DL. The world spends over 10% of GDP on healthcare (&gt;6 trillion USD per year), much of it on medical diagnosis through expensive experts. Partial automation of this could not only save lots of money, but also make expert diagnostics accessible to many who currently cannot afford it. It is gratifying to observe that today deep NNs may actually help to improve healthcare and perhaps save human lives.</p><p>2012 also saw the first pure image segmentation contest won by DL (Ciresan, Giusti, Gambardella, &amp; Schmidhuber, 2012), again through an GPU-MPCNN ensemble (Segmentation of Neuronal Structures in EM Stacks Challenge, 2012).<ref type="foot" target="#foot_1">2</ref> EM stacks are relevant for the recently approved huge brain projects in Europe and the US (e.g., <ref type="bibr" target="#b471">Markram, 2012)</ref>. Given electron microscopy images of stacks of thin slices of animal brains, the goal is to build a detailed 3D model of the brain's neurons and dendrites. But human experts need many hours and days and weeks to annotate the images: Which parts depict neuronal membranes? Which parts are irrelevant background? This needs to be automated (e.g., <ref type="bibr" target="#b748">Turaga et al., 2010)</ref>. Deep Multi-Column GPU-MPCNNs learned to solve this task through experience with many training images, and won the contest on all three evaluation metrics by a large margin, with superhuman performance in terms of pixel error.</p><p>Both object detection <ref type="bibr">(Ciresan et al., 2013)</ref> and image segmentation (Ciresan, <ref type="bibr">Giusti, et al., 2012)</ref> profit from fast MPCNN-based image scans that avoid redundant computations. Recent MPCNN scanners speed up naive implementations by up to three orders of magnitude <ref type="bibr" target="#b237">(Giusti, Ciresan, Masci, Gambardella, &amp; Schmidhuber, 2013;</ref><ref type="bibr" target="#b476">Masci, Giusti, Ciresan, Fricout, &amp; Schmidhuber, 2013)</ref>; compare earlier efficient methods for CNNs without MP <ref type="bibr" target="#b755">(Vaillant, Monrocq, &amp; LeCun, 1994)</ref>.</p><p>Also in 2012, a system consisting of growing deep FNNs and 2D-BRNNs <ref type="bibr" target="#b171">(Di Lena et al., 2012)</ref> won the CASP 2012 contest on protein contact map prediction. On the IAM-OnDoDB benchmark, LSTM RNNs (Section 5.13) outperformed all other methods (HMMs, SVMs) on online mode detection <ref type="bibr" target="#b329">(Indermuhle, Frinken, &amp; Bunke, 2012;</ref><ref type="bibr" target="#b549">Otte, Krechel, Liwicki, &amp; Dengel, 2012)</ref> and keyword spotting <ref type="bibr" target="#b330">(Indermuhle et al., 2011)</ref>. On the long time lag problem of language modeling, LSTM RNNs outperformed all statistical approaches on the IAM-DB benchmark <ref type="bibr" target="#b213">(Frinken et al., 2012)</ref>; improved results were later obtained through a combination of NNs and HMMs <ref type="bibr" target="#b833">(Zamora-Martínez et al., 2014)</ref>. Compare earlier RNNs for object recognition through iterative image interpretation <ref type="bibr" target="#b86">(Behnke, 2002</ref><ref type="bibr" target="#b88">(Behnke, , 2003b;;</ref><ref type="bibr" target="#b90">Behnke &amp; Rojas, 1998)</ref>; see also more recent publications (O'Reilly, <ref type="bibr" target="#b544">Wyatte, Herd, Mingus, &amp; Jilk, 2013;</ref><ref type="bibr" target="#b823">Wyatte, Curran, &amp; O'Reilly, 2012)</ref> extending work on biologically plausible learning rules for RNNs (O'Reilly, 1996).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.22.">2013-: more contests and benchmark records</head><p>A stack <ref type="bibr" target="#b198">(Fernandez et al., 2007b;</ref><ref type="bibr">Graves &amp; Schmidhuber, 2009</ref>) (Section 5.10) of bi-directional LSTM RNNs <ref type="bibr">(Graves &amp; Schmidhuber, 2005)</ref> trained by CTC (Sections 5.13, 5.17) broke a famous TIMIT speech (phoneme) recognition record, achieving 17.7% test set error rate <ref type="bibr" target="#b260">(Graves et al., 2013)</ref>, despite thousands of man years previously spent on Hidden Markov Model (HMMs)-based speech recognition research. Compare earlier DBN results (Section 5.15).</p><p>CTC-LSTM also helped to score first at NIST's OpenHaRT2013 evaluation <ref type="bibr" target="#b105">(Bluche et al., 2014)</ref>. For optical character recognition (OCR), LSTM RNNs outperformed commercial recognizers of historical data <ref type="bibr" target="#b119">(Breuel et al., 2013)</ref>. LSTM-based systems also set benchmark records in language identification <ref type="bibr" target="#b250">(Gonzalez-Dominguez et al., 2014)</ref>, medium-vocabulary speech recognition <ref type="bibr" target="#b226">(Geiger et al., 2014)</ref>, prosody contour prediction <ref type="bibr" target="#b199">(Fernandez et al., 2014)</ref>, audio onset detection <ref type="bibr" target="#b470">(Marchi et al., 2014)</ref>, text-to-speech synthesis <ref type="bibr" target="#b192">(Fan et al., 2014)</ref>, and social signal classification <ref type="bibr" target="#b122">(Brueckner &amp; Schulter, 2014</ref>).</p><p>An LSTM RNN was used to estimate the state posteriors of an HMM; this system beat the previous state of the art in large vocabulary speech recognition <ref type="bibr">(Sak, Senior, et al., 2014;</ref><ref type="bibr" target="#b625">Sak, Vinyals, et al., 2014)</ref>. Another LSTM RNN with hundreds of millions of connections was used to rerank hypotheses of a statistical machine translation system; this system beat the previous state of the art in English to French translation <ref type="bibr" target="#b728">(Sutskever et al., 2014)</ref>.</p><p>A new record on the ICDAR Chinese handwriting recognition benchmark (over 3700 classes) was set on a desktop machine by an ensemble of GPU-MPCNNs (Section 5.19) with almost human performance <ref type="bibr">(Ciresan &amp; Schmidhuber, 2013)</ref>; compare <ref type="bibr" target="#b830">(Yin, Wang, Zhang, &amp; Liu, 2013)</ref>.</p><p>The MICCAI 2013 Grand Challenge on Mitosis Detection <ref type="bibr" target="#b760">(Veta, Viergever, Pluim, Stathonikos, &amp; van Diest, 2013)</ref> also was won by an object-detecting GPU-MPCNN ensemble <ref type="bibr">(Ciresan et al., 2013)</ref>. Its data set was even larger and more challenging than the one of ICPR 2012 (Section 5.21): a real-world data set including many ambiguous cases and frequently encountered problems such as imperfect slide staining.</p><p>Three 2D-CNNs (with mean-pooling instead of MP, Section 5.11) observing three orthogonal projections of 3D images outperformed traditional full 3D methods on the task of segmenting tibial cartilage in low field knee MRI scans <ref type="bibr" target="#b579">(Prasoon et al., 2013)</ref>.</p><p>Deep GPU-MPCNNs (Section 5.19) also helped to achieve new best results on important benchmarks of the computer vision community: ImageNet classification <ref type="bibr" target="#b733">(Szegedy et al., 2014;</ref><ref type="bibr" target="#b834">Zeiler &amp; Fergus, 2013)</ref> and -in conjunction with traditional approaches -PASCAL object detection <ref type="bibr" target="#b235">(Girshick, Donahue, Darrell, &amp; Malik, 2013)</ref>. They also learned to predict bounding box coordinates of objects in the Imagenet 2013 database, and obtained state-ofthe-art results on tasks of localization and detection <ref type="bibr" target="#b682">(Sermanet et al., 2013)</ref>. GPU-MPCNNs also helped to recognize multi-digit numbers in Google Street View images <ref type="bibr" target="#b251">(Goodfellow, Bulatov, Ibarz, Arnoud, &amp; Shet, 2014)</ref>, where part of the NN was trained to count visible digits; compare earlier work on detecting ''numerosity'' through DBNs <ref type="bibr" target="#b719">(Stoianov &amp; Zorzi, 2012)</ref>. This system also excelled at recognizing distorted synthetic text in reCAPTCHA puzzles. Other successful CNN applications include scene parsing <ref type="bibr" target="#b193">(Farabet, Couprie, Najman, &amp; LeCun, 2013)</ref>, object detection <ref type="bibr" target="#b734">(Szegedy, Toshev, &amp; Erhan, 2013)</ref>, shadow detection <ref type="bibr" target="#b370">(Khan, Bennamoun, Sohel, &amp; Togneri, 2014)</ref>, video classification <ref type="bibr" target="#b365">(Karpathy et al., 2014)</ref>, and Alzheimer's disease neuroimaging <ref type="bibr" target="#b436">(Li et al., 2014)</ref>.</p><p>Additional contests are mentioned in the web pages of the Swiss AI Lab IDSIA, the University of Toronto, NY University, and the University of Montreal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.23.">Currently successful techniques: LSTM RNNs and GPU-MPCNNs</head><p>Most competition-winning or benchmark record-setting Deep Learners actually use one of two supervised techniques: (a) recurrent LSTM (1997) trained by <ref type="bibr">CTC (2006)</ref>  <ref type="bibr">(Sections 5.13,</ref><ref type="bibr">5.17,</ref><ref type="bibr">5.21,</ref><ref type="bibr">5.22)</ref>, or (b) feedforward <ref type="bibr">GPU-MPCNNs (2011, Sections 5.19, 5.21, 5.22)</ref> based on CNNs (1979, Section 5.4) with MP (1992, Section 5.11) trained through <ref type="bibr">BP (1989</ref><ref type="bibr">-2007, Sections 5.8, 5.16)</ref>.</p><p>Exceptions include two 2011 contests <ref type="bibr" target="#b252">(Goodfellow, Courville, &amp; Bengio, 2011</ref><ref type="bibr">, 2012;</ref><ref type="bibr" target="#b484">Mesnil et al., 2011)</ref> specialized on Transfer Learning from one data set to another (e.g., <ref type="bibr" target="#b131">Caruana, 1997;</ref><ref type="bibr" target="#b553">Pan &amp; Yang, 2010;</ref><ref type="bibr" target="#b656">Schmidhuber, 2004)</ref>. However, deep GPU-MPCNNs do allow for pure SL-based transfer <ref type="bibr">(Ciresan, Meier, &amp; Schmidhuber, 2012b)</ref>, where pre-training on one training set greatly improves performance on quite different sets, also in more recent studies <ref type="bibr" target="#b174">(Donahue et al., 2013;</ref><ref type="bibr" target="#b541">Oquab, Bottou, Laptev, &amp; Sivic, 2013)</ref>. In fact, deep MPCNNs pre-trained by SL can extract useful features from quite diverse off-training-set images, yielding better results than traditional, widely used features such as SIFT <ref type="bibr" target="#b449">(Lowe, 1999</ref><ref type="bibr" target="#b450">(Lowe, , 2004</ref>) on many vision tasks <ref type="bibr" target="#b592">(Razavian, Azizpour, Sullivan, &amp; Carlsson, 2014)</ref>. To deal with changing data sets, slowly learning deep NNs were also combined with rapidly adapting ''surface'' NNs <ref type="bibr" target="#b361">(Kak, Chen, &amp; Wang, 2010)</ref>.</p><p>Remarkably, in the 1990s a trend went from partially unsupervised RNN stacks (Section 5.10) to purely supervised LSTM RNNs (Section 5.13), just like in the 2000s a trend went from partially unsupervised FNN stacks (Section 5.15) to purely supervised MPCNNs ). Nevertheless, in many applications it can still be advantageous to combine the best of both worlds-supervised learning and unsupervised pre-training (Sections 5.10, 5.15). <ref type="bibr">NNs (compare Sections 5.6.2,</ref><ref type="bibr">5.6.3)</ref> DBN training (Section 5.15) can be improved through gradient enhancements and automatic learning rate adjustments during stochastic gradient descent <ref type="bibr" target="#b138">(Cho, 2014;</ref><ref type="bibr" target="#b140">Cho, Raiko, &amp; Ilin, 2013)</ref>, and through Tikhonov-type <ref type="bibr" target="#b741">(Tikhonov, Arsenin, &amp; John, 1977)</ref> regularization of RBMs <ref type="bibr" target="#b139">(Cho, Ilin, &amp; Raiko, 2012)</ref>. Contractive AEs (Rifai, <ref type="bibr" target="#b601">Vincent, Muller, Glorot, &amp; Bengio, 2011)</ref> discourage hidden unit perturbations in response to input perturbations, similar to how FMS (Section 5.6.3) for Lococode AEs (Section 5.6.4) discourages output perturbations in response to weight perturbations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.24.">Recent tricks for improving SL deep</head><p>Hierarchical CNNs in a Neural Abstraction Pyramid (e.g., <ref type="bibr" target="#b88">Behnke, 2003b</ref><ref type="bibr" target="#b89">Behnke, , 2005) )</ref> were trained to reconstruct images corrupted by structured noise <ref type="bibr" target="#b85">(Behnke, 2001)</ref>, thus enforcing increasingly abstract image representations in deeper and deeper layers. Denoising AEs later used a similar procedure <ref type="bibr" target="#b763">(Vincent et al., 2008)</ref>.</p><p>Dropout <ref type="bibr" target="#b49">(Ba &amp; Frey, 2013;</ref><ref type="bibr" target="#b303">Hinton, Srivastava, Krizhevsky, Sutskever, &amp; Salakhutdinov, 2012)</ref> removes units from NNs during training to improve generalization. Some view it as an ensemble method that trains multiple data models simultaneously <ref type="bibr" target="#b63">(Baldi &amp; Sadowski, 2014)</ref>. Under certain circumstances, it could also be viewed as a form of training set augmentation: effectively, more and more informative complex features are removed from the training data. Compare dropout for RNNs <ref type="bibr" target="#b551">(Pachitariu &amp; Sahani, 2013;</ref><ref type="bibr" target="#b556">Pascanu, Gulcehre, Cho, &amp; Bengio, 2013;</ref><ref type="bibr" target="#b570">Pham, Kermorvant, &amp; Louradour, 2013)</ref>. A deterministic approximation coined fast dropout <ref type="bibr" target="#b770">(Wang &amp; Manning, 2013)</ref> can lead to faster learning and evaluation and was adapted for RNNs <ref type="bibr" target="#b79">(Bayer, Osendorfer, Chen, Urban, &amp; van der Smagt, 2013)</ref>. Dropout is closely related to older, biologically plausible techniques for adding noise to neurons or synapses during training (e.g., <ref type="bibr">An, 1996;</ref><ref type="bibr" target="#b278">Hanson, 1990;</ref><ref type="bibr" target="#b346">Jim, Giles, &amp; Horne, 1995;</ref><ref type="bibr" target="#b517">Murray &amp; Edwards, 1993;</ref><ref type="bibr" target="#b518">Nadal &amp; Parga, 1994;</ref><ref type="bibr" target="#b677">Schuster, 1992)</ref>, which in turn are closely related to finding perturbation-resistant low-complexity NNs, e.g., through FMS <ref type="bibr">(Section 5.6.3)</ref>. MDL-based stochastic variational methods <ref type="bibr" target="#b254">(Graves, 2011)</ref> are also related to FMS. They are useful for RNNs, where classic regularizers such as weight decay (Section 5.6.3) represent a bias towards limited memory capacity (e.g., <ref type="bibr" target="#b557">Pascanu, Mikolov, et al., 2013)</ref>. Compare recent work on variational recurrent AEs <ref type="bibr" target="#b78">(Bayer &amp; Osendorfer, 2014)</ref>.</p><p>The activation function f of Rectified Linear Units (ReLUs) is f (x) = x for x &gt; 0, f (x) = 0 otherwise-compare the old concept of half-wave rectified units <ref type="bibr" target="#b467">(Malik &amp; Perona, 1990)</ref>. ReLU NNs are useful for RBMs <ref type="bibr" target="#b453">(Maas, Hannun, &amp; Ng, 2013;</ref><ref type="bibr" target="#b520">Nair &amp; Hinton, 2010)</ref>, outperformed sigmoidal activation functions in deep NNs <ref type="bibr" target="#b239">(Glorot, Bordes, &amp; Bengio, 2011)</ref>, and helped to obtain best results on several benchmark problems across multiple domains (e.g., <ref type="bibr" target="#b148">Dahl, Sainath, &amp; Hinton, 2013;</ref><ref type="bibr" target="#b397">Krizhevsky et al., 2012)</ref>. NNs with competing linear units tend to outperform those with non-competing nonlinear units, and avoid catastrophic forgetting through BP when training sets change over time <ref type="bibr" target="#b711">(Srivastava, Masci, Kazerounian, Gomez, &amp; Schmidhuber, 2013)</ref>. In this context, choosing a learning algorithm may be more important than choosing activation functions <ref type="bibr" target="#b253">(Goodfellow, Mirza, Da, Courville, &amp; Bengio, 2014)</ref>. Maxout NNs <ref type="bibr" target="#b253">(Goodfellow, Warde-Farley, Mirza, Courville, &amp; Bengio, 2013)</ref> combine competitive interactions and dropout (see above) to achieve excellent results on certain benchmarks. Compare early RNNs with competing units for SL and RL <ref type="bibr" target="#b643">(Schmidhuber, 1989b)</ref>. To address overfitting, instead of depending on pre-wired regularizers and hyper-parameters <ref type="bibr" target="#b102">(Bishop, 2006;</ref><ref type="bibr" target="#b292">Hertz, Krogh, &amp; Palmer, 1991)</ref>, self-delimiting RNNs (SLIM NNs) with competing units <ref type="bibr" target="#b660">(Schmidhuber, 2012)</ref> can in principle learn to select their own runtime and their own numbers of effective free parameters, thus learning their own computable regularizers <ref type="bibr">(Sections 4.4,</ref><ref type="bibr">5.6.3)</ref>, becoming fast and slim when necessary. One may penalize the task-specific total length of connections (e.g., <ref type="bibr">Clune, Mouret, &amp; Lipson, 2013;</ref><ref type="bibr" target="#b422">Legenstein &amp; Maass, 2002;</ref><ref type="bibr" target="#b660">Schmidhuber, 2012</ref><ref type="bibr" target="#b662">Schmidhuber, , 2013b) )</ref> and communication costs of SLIM NNs implemented on the 3-dimensional brain-like multi-processor hardware to be expected in the future.</p><p>RmsProp <ref type="bibr" target="#b638">(Schaul, Zhang, &amp; LeCun, 2013;</ref><ref type="bibr" target="#b741">Tieleman &amp; Hinton, 2012)</ref> can speed up first order gradient descent methods (Sections 5.5, 5.6.2); compare vario-η <ref type="bibr" target="#b529">(Neuneier &amp; Zimmermann, 1996)</ref>, Adagrad <ref type="bibr" target="#b178">(Duchi, Hazan, &amp; Singer, 2011)</ref> and Adadelta <ref type="bibr" target="#b834">(Zeiler, 2012)</ref>. DL in NNs can also be improved by transforming hidden unit activations such that they have zero output and slope on average <ref type="bibr" target="#b586">(Raiko, Valpola, &amp; LeCun, 2012)</ref>. Many additional, older tricks <ref type="bibr">(Sections 5.6.2,</ref><ref type="bibr">5.6.3)</ref> should also be applicable to today's deep NNs; compare <ref type="bibr" target="#b502">(Montavon et al., 2012;</ref><ref type="bibr" target="#b545">Orr &amp; Müller, 1998)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.25.">Consequences for neuroscience</head><p>It is ironic that artificial NNs (ANNs) can help to better understand biological NNs (BNNs)-see the ISBI 2012 results mentioned in <ref type="bibr">Section 5.21 (Ciresan, Giusti, et al., 2012;</ref><ref type="bibr">Segmentation of Neuronal Structures in EM Stacks Challenge, 2012)</ref>.</p><p>The feature detectors learned by single-layer visual ANNs are similar to those found in early visual processing stages of BNNs (e.g., <ref type="bibr">Section 5.6.4)</ref>. Likewise, the feature detectors learned in deep layers of visual ANNs should be highly predictive of what neuroscientists will find in deep layers of BNNs. While the visual cortex of BNNs may use quite different learning algorithms, its objective function to be minimized may be quite similar to the one of visual ANNs. In fact, results obtained with relatively deep artificial DBNs <ref type="bibr" target="#b418">(Lee, Ekanadham, &amp; Ng, 2007)</ref> and CNNs <ref type="bibr" target="#b826">(Yamins, Hong, Cadieu, &amp; DiCarlo, 2013)</ref> seem compatible with insights about the visual pathway in the primate cerebral cortex, which has been studied for many decades (e.g., <ref type="bibr">Bichot, Rossi, &amp; Desimone, 2005;</ref><ref type="bibr" target="#b142">Connor, Brincat, &amp; Pasupathy, 2007;</ref><ref type="bibr" target="#b161">Desimone, Albright, Gross, &amp; Bruce, 1984;</ref><ref type="bibr" target="#b166">DiCarlo, Zoccolan, &amp; Rust, 2012;</ref><ref type="bibr" target="#b196">Felleman &amp; Van Essen, 1991;</ref><ref type="bibr" target="#b319">Hubel &amp; Wiesel, 1968;</ref><ref type="bibr" target="#b321">Hung, Kreiman, Poggio, &amp; DiCarlo, 2005;</ref><ref type="bibr" target="#b378">Kobatake &amp; Tanaka, 1994;</ref><ref type="bibr" target="#b396">Kriegeskorte et al., 2008;</ref><ref type="bibr" target="#b427">Lennie &amp; Movshon, 2005;</ref><ref type="bibr" target="#b446">Logothetis, Pauls, &amp; Poggio, 1995;</ref><ref type="bibr" target="#b565">Perrett, Hietanen, Oram, Benson, &amp; Rolls, 1992;</ref><ref type="bibr" target="#b566">Perrett, Rolls, &amp; Caan, 1982)</ref>; compare a computer vision-oriented survey <ref type="bibr" target="#b399">(Kruger et al., 2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.26.">DL with spiking neurons?</head><p>Many recent DL results profit from GPU-based traditional deep NNs, e.g., . Current GPUs, however, are little ovens, much hungrier for energy than biological brains, whose neurons efficiently communicate by brief spikes <ref type="bibr" target="#b205">(FitzHugh, 1961;</ref><ref type="bibr" target="#b310">Hodgkin &amp; Huxley, 1952;</ref><ref type="bibr" target="#b519">Nagumo, Arimoto, &amp; Yoshizawa, 1962)</ref>, and often remain quiet. Many computational models of such spiking neurons have been proposed and analyzed (e.g., <ref type="bibr" target="#b39">Amit &amp; Brunel, 1997;</ref><ref type="bibr" target="#b110">Bohte, Kok, &amp; La Poutre, 2002;</ref><ref type="bibr" target="#b116">Brea, Senn, &amp; Pfister, 2013;</ref><ref type="bibr" target="#b118">Brette et al., 2007;</ref><ref type="bibr" target="#b123">Brunel, 2000;</ref><ref type="bibr" target="#b157">Deco &amp; Rolls, 2005;</ref><ref type="bibr" target="#b232">Gerstner &amp; Kistler, 2002;</ref><ref type="bibr" target="#b232">Gerstner &amp; van Hemmen, 1992;</ref><ref type="bibr" target="#b311">Hoerzer, Legenstein, &amp; Maass, 2014;</ref><ref type="bibr" target="#b337">Izhikevich et al., 2003;</ref><ref type="bibr" target="#b366">Kasabov, 2014;</ref><ref type="bibr" target="#b368">Kempter, Gerstner, &amp; Van Hemmen, 1999;</ref><ref type="bibr" target="#b374">Kistler, Gerstner, &amp; van Hemmen, 1997;</ref><ref type="bibr" target="#b454">Maass, 1996</ref><ref type="bibr" target="#b455">Maass, , 1997;;</ref><ref type="bibr" target="#b465">Maex &amp; Orban, 1996;</ref><ref type="bibr" target="#b527">Nessler, Pfeiffer, Buesing, &amp; Maass, 2013;</ref><ref type="bibr" target="#b596">Rezende &amp; Gerstner, 2014;</ref><ref type="bibr" target="#b686">Seung, 2003;</ref><ref type="bibr" target="#b709">Song, Miller, &amp; Abbott, 2000;</ref><ref type="bibr" target="#b718">Stemmler, 1996;</ref><ref type="bibr" target="#b721">Stoop, Schindler, &amp; Bunimovich, 2000;</ref><ref type="bibr" target="#b746">Tsodyks, Pawelzik, &amp; Markram, 1998;</ref><ref type="bibr" target="#b747">Tsodyks, Skaggs, Sejnowski, &amp; McNaughton, 1996;</ref><ref type="bibr" target="#b839">Zipser, Kehoe, Littlewort, &amp; Fuster, 1993)</ref>.</p><p>Future energy-efficient hardware for DL in NNs may implement aspects of such models (e.g., <ref type="bibr" target="#b202">Fieres, Schemmel, &amp; Meier, 2008;</ref><ref type="bibr">Glackin, McGinnity, Maguire, Wu, &amp; Belatreche, 2005;</ref><ref type="bibr" target="#b331">Indiveri et al., 2011;</ref><ref type="bibr" target="#b347">Jin et al., 2010;</ref><ref type="bibr" target="#b372">Khan et al., 2008;</ref><ref type="bibr" target="#b444">Liu et al., 2001;</ref><ref type="bibr" target="#b483">Merolla et al., 2014;</ref><ref type="bibr" target="#b526">Neil &amp; Liu, 2014;</ref><ref type="bibr" target="#b612">Roggen, Hofmann, Thoma, &amp; Floreano, 2003;</ref><ref type="bibr" target="#b639">Schemmel, Grubl, Meier, &amp; Mueller, 2006;</ref><ref type="bibr" target="#b684">Serrano-Gotarredona et al., 2009)</ref>. A simulated, event-driven, spiking variant <ref type="bibr" target="#b525">(Neftci, Das, Pedroni, Kreutz-Delgado, &amp; Cauwenberghs, 2014)</ref> of an RBM (Section 5.15) was trained by a variant of the Contrastive Divergence algorithm <ref type="bibr" target="#b296">(Hinton, 2002)</ref>. Spiking nets were evolved to achieve reasonable performance on small face recognition data sets <ref type="bibr" target="#b824">(Wysoski, Benuskova, &amp; Kasabov, 2010)</ref> and to control simple robots <ref type="bibr" target="#b207">(Floreano &amp; Mattiussi, 2001;</ref><ref type="bibr">Hagras, Pounds-Cornish, Colley, Callaghan, &amp; Clarke, 2004)</ref>. A spiking DBN with about 250,000 neurons (as part of a larger NN; <ref type="bibr" target="#b181">Eliasmith, 2013;</ref><ref type="bibr" target="#b182">Eliasmith et al., 2012)</ref> achieved 6% error rate on MNIST; compare similar results with a spiking DBN variant of depth 3 using a neuromorphic event-based sensor (O <ref type="bibr">'Connor, Neil, Liu, Delbruck, &amp; Pfeiffer, 2013)</ref>. In practical applications, however, current artificial networks of spiking neurons cannot yet compete with the best traditional deep NNs (e.g., compare MNIST results of Section 5.19).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">DL in FNNs and RNNs for Reinforcement Learning (RL)</head><p>So far we have focused on Deep Learning (DL) in supervised or unsupervised NNs. Such NNs learn to perceive/encode/predict/ classify patterns or pattern sequences, but they do not learn to act in the more general sense of Reinforcement Learning (RL) in unknown environments (see surveys, e.g., <ref type="bibr" target="#b360">Kaelbling et al., 1996;</ref><ref type="bibr" target="#b729">Sutton &amp; Barto, 1998;</ref><ref type="bibr" target="#b801">Wiering &amp; van Otterlo, 2012)</ref>. Here we add a discussion of DL FNNs and RNNs for RL. It will be shorter than the discussion of FNNs and RNNs for SL and UL (Section 5), reflecting the current size of the various fields.</p><p>Without a teacher, solely from occasional real-valued pain and pleasure signals, RL agents must discover how to interact with a dynamic, initially unknown environment to maximize their expected cumulative reward signals (Section 2). There may be arbitrary, a priori unknown delays between actions and perceivable consequences. The problem is as hard as any problem of computer science, since any task with a computable description can be formulated in the RL framework (e.g., <ref type="bibr" target="#b323">Hutter, 2005)</ref>. For example, an answer to the famous question of whether P = NP <ref type="bibr" target="#b144">(Cook, 1971;</ref><ref type="bibr" target="#b430">Levin, 1973b)</ref> would also set limits for what is achievable by general RL. Compare more specific limitations, e.g., <ref type="bibr" target="#b104">Blondel and Tsitsiklis (2000)</ref>, <ref type="bibr" target="#b463">Madani, Hanks, and Condon (2003)</ref> and <ref type="bibr" target="#b764">Vlassis, Littman, and Barber (2012)</ref>. The following subsections mostly focus on certain obvious intersections between DL and RL-they cannot serve as a general RL survey.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">RL through NN world models yields RNNs with deep CAPs</head><p>In the special case of an RL FNN controller C interacting with a deterministic, predictable environment, a separate FNN called M can learn to become C 's world model through system identification, predicting C 's inputs from previous actions and inputs <ref type="bibr">(e.g., Cochocki &amp; Unbehauen, 1993;</ref><ref type="bibr" target="#b225">Ge, Hang, Lee, &amp; Zhang, 2010;</ref><ref type="bibr" target="#b249">Gomi &amp; Kawato, 1993;</ref><ref type="bibr" target="#b351">Jordan, 1988;</ref><ref type="bibr" target="#b353">Jordan &amp; Rumelhart, 1990;</ref><ref type="bibr" target="#b432">Levin &amp; Narendra, 1995;</ref><ref type="bibr" target="#b445">Ljung, 1998;</ref><ref type="bibr" target="#b491">Miller, Werbos, &amp; Sutton, 1995;</ref><ref type="bibr" target="#b516">Munro, 1987;</ref><ref type="bibr" target="#b521">Narendra &amp; Parthasarathy, 1990;</ref><ref type="bibr" target="#b583">Prokhorov, Puskorius, &amp; Feldkamp, 2001;</ref><ref type="bibr" target="#b609">Robinson &amp; Fallside, 1989;</ref><ref type="bibr" target="#b646">Schmidhuber, 1990d;</ref><ref type="bibr" target="#b782">Werbos, 1981</ref><ref type="bibr" target="#b783">Werbos, , 1987</ref><ref type="bibr" target="#b785">Werbos, , 1989a</ref><ref type="bibr" target="#b786">Werbos, , 1989b</ref><ref type="bibr" target="#b787">Werbos, , 1992))</ref>. Assume M has learned to produce accurate predictions. We can use M to substitute the environment. Then M and C form an RNN where M's outputs become inputs of C , whose outputs (actions) in turn become inputs of M. Now BP for RNNs (Section 5.5.1) can be used to achieve desired input events such as high real-valued reward signals: While M's weights remain fixed, gradient information for C 's weights is propagated back through M down into C and back through M etc. To a certain extent, the approach is also applicable in probabilistic or uncertain environments, as long as the inner products of M's Cbased gradient estimates and M's ''true'' gradients tend to be positive.</p><p>In general, this approach implies deep CAPs for C , unlike in DP-based traditional RL (Section 6.2). Decades ago, the method was used to learn to back up a model truck <ref type="bibr" target="#b530">(Nguyen &amp; Widrow, 1989</ref>). An RL active vision system used it to learn sequential shifts (saccades) of a fovea, to detect targets in visual scenes <ref type="bibr" target="#b665">(Schmidhuber &amp; Huber, 1991)</ref>, thus learning to control selective attention. Compare RL-based attention learning without NNs <ref type="bibr" target="#b792">(Whitehead, 1992)</ref>.</p><p>To allow for memories of previous events in partially observable worlds (Section 6.3), the most general variant of this technique uses RNNs instead of FNNs to implement both M and C <ref type="bibr" target="#b195">(Feldkamp &amp; Puskorius, 1998;</ref><ref type="bibr" target="#b646">Schmidhuber, 1990d</ref><ref type="bibr" target="#b648">Schmidhuber, , 1991c))</ref>. This may cause deep CAPs not only for C but also for M.</p><p>M can also be used to optimize expected reward by planning future action sequences <ref type="bibr" target="#b646">(Schmidhuber, 1990d)</ref>. In fact, the winners of the 2004 RoboCup World Championship in the fast league <ref type="bibr" target="#b179">(Egorova et al., 2004)</ref> trained NNs to predict the effects of steering signals on fast robots with 4 motors for 4 different wheels. During play, such NN models were used to achieve desirable subgoals, by optimizing action sequences through quickly planning ahead. The approach also was used to create self-healing robots able to compensate for faulty motors whose effects do not longer match the predictions of the NN models <ref type="bibr" target="#b240">(Gloye, Wiesel, Tenchio, &amp; Simon, 2005;</ref><ref type="bibr" target="#b659">Schmidhuber, 2007)</ref>.</p><p>Typically M is not given in advance. Then an essential question is: which experiments should C conduct to quickly improve M? The Formal Theory of Fun and Creativity (e.g., <ref type="bibr" target="#b657">Schmidhuber, 2006a</ref><ref type="bibr" target="#b662">Schmidhuber, , 2013b) )</ref> formalizes driving forces and value functions behind such curious and exploratory behavior: A measure of the learning progress of M becomes the intrinsic reward of C <ref type="bibr" target="#b647">(Schmidhuber, 1991a)</ref>; compare <ref type="bibr" target="#b550">(Oudeyer, Baranes, &amp; Kaplan, 2013;</ref><ref type="bibr" target="#b701">Singh, Barto, &amp; Chentanez, 2005)</ref>. This motivates C to create action sequences (experiments) such that M makes quick progress.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Deep FNNs for traditional RL and Markov Decision Processes (MDPs)</head><p>The classical approach to RL <ref type="bibr" target="#b99">(Bertsekas &amp; Tsitsiklis, 1996;</ref><ref type="bibr" target="#b630">Samuel, 1959)</ref> makes the simplifying assumption of Markov Decision Processes (MDPs): the current input of the RL agent conveys all information necessary to compute an optimal next output event or decision. This allows for greatly reducing CAP depth in RL NNs (Sections 3, 6.1) by using the Dynamic Programming (DP) trick <ref type="bibr" target="#b92">(Bellman, 1957)</ref>. The latter is often explained in a probabilistic framework (e.g., <ref type="bibr" target="#b729">Sutton &amp; Barto, 1998)</ref>, but its basic idea can already be conveyed in a deterministic setting. For simplicity, using the notation of Section 2, let input events x t encode the entire current state of the environment, including a real-valued reward r t (no need to introduce additional vector-valued notation, since real values can encode arbitrary vectors of real values). The original RL goal (find weights that maximize the sum of all rewards of an episode) is replaced by an equivalent set of alternative goals set by a real-valued value function V defined on input events. Consider any two subse-</p><formula xml:id="formula_2">quent input events x t , x k . Recursively define V (x t ) = r t + V (x k ), where V (x k ) = r k if x k</formula><p>is the last input event. Now search for weights that maximize the V of all input events, by causing appropriate output events or actions.</p><p>Due to the Markov assumption, an FNN suffices to implement the policy that maps input to output events. Relevant CAPs are not deeper than this FNN. V itself is often modeled by a separate FNN (also yielding typically short CAPs) learning to approximate V (x t ) only from local information r t , V (x k ).</p><p>Many variants of traditional RL exist (e.g., <ref type="bibr" target="#b26">Abounadi, Bertsekas, &amp; Borkar, 2002;</ref><ref type="bibr" target="#b51">Baird, 1995;</ref><ref type="bibr" target="#b52">Baird &amp; Moore, 1999;</ref><ref type="bibr" target="#b72">Barto, Sutton, &amp; Anderson, 1983;</ref><ref type="bibr" target="#b99">Bertsekas, 2001;</ref><ref type="bibr" target="#b114">Bradtke, Barto, &amp; Kaelbling, 1996;</ref><ref type="bibr" target="#b115">Brafman &amp; Tennenholtz, 2002;</ref><ref type="bibr">Kaelbling, Littman, &amp; Cassandra, 1995;</ref><ref type="bibr" target="#b401">Lagoudakis &amp; Parr, 2003;</ref><ref type="bibr" target="#b464">Maei &amp; Sutton, 2010;</ref><ref type="bibr" target="#b466">Mahadevan, 1996;</ref><ref type="bibr" target="#b485">Meuleau, Peshkin, Kim, &amp; Kaelbling, 1999;</ref><ref type="bibr" target="#b506">Moore &amp; Atkeson, 1993;</ref><ref type="bibr" target="#b509">Morimoto &amp; Doya, 2000;</ref><ref type="bibr" target="#b563">Peng &amp; Williams, 1996;</ref><ref type="bibr" target="#b584">Prokhorov &amp; Wunsch, 1997;</ref><ref type="bibr" target="#b621">Rummery &amp; Niranjan, 1994;</ref><ref type="bibr" target="#b632">Santamaría, Sutton, &amp; Ram, 1997;</ref><ref type="bibr" target="#b679">Schwartz, 1993;</ref><ref type="bibr" target="#b700">Singh, 1994;</ref><ref type="bibr" target="#b729">Sutton &amp; Barto, 1998;</ref><ref type="bibr" target="#b731">Sutton, Szepesvári, &amp; Maei, 2008;</ref><ref type="bibr" target="#b745">Tsitsiklis &amp; van Roy, 1996;</ref><ref type="bibr" target="#b756">van Hasselt, 2012;</ref><ref type="bibr" target="#b774">Watkins, 1989;</ref><ref type="bibr">Watkins &amp; Dayan, 1992;</ref><ref type="bibr" target="#b800">Wiering &amp; Schmidhuber, 1998b)</ref>. Most are formulated in a probabilistic framework, and evaluate pairs of input and output (action) events (instead of input events only). To facilitate certain mathematical derivations, some discount delayed rewards, but such distortions of the original RL problem are problematic.</p><p>Perhaps the most well-known RL NN is the world-class RL backgammon player <ref type="bibr" target="#b740">(Tesauro, 1994)</ref>, which achieved the level of human world champions by playing against itself. Its nonlinear, rather shallow FNN maps a large but finite number of discrete board states to values. More recently, a rather deep GPU-CNN was used in a traditional RL framework to play several Atari 2600 computer games directly from 84 × 84 pixel 60 Hz video input <ref type="bibr" target="#b497">(Mnih et al., 2013)</ref>, using experience replay <ref type="bibr" target="#b437">(Lin, 1993)</ref>, extending previous work on Neural Fitted Q-Learning (NFQ) <ref type="bibr" target="#b597">(Riedmiller, 2005)</ref>. Even better results are achieved by using (slow) Monte Carlo tree planning to train comparatively fast deep NNs <ref type="bibr" target="#b272">(Guo, Singh, Lee, Lewis, &amp; Wang, 2014)</ref>. Compare RBM-based RL <ref type="bibr" target="#b627">(Sallans &amp; Hinton, 2004)</ref> with high-dimensional inputs <ref type="bibr" target="#b180">(Elfwing, Otsuka, Uchibe, &amp; Doya, 2010)</ref>, earlier RL Atari players <ref type="bibr" target="#b271">(Grüttner, Sehnke, Schaul, &amp; Schmidhuber, 2010)</ref>, and an earlier, raw video-based RL NN for computer games <ref type="bibr" target="#b392">(Koutník, Cuccu, Schmidhuber, &amp; Gomez, 2013)</ref> trained by Indirect Policy Search (Section 6.7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Deep RL RNNs for partially observable MDPs (POMDPs)</head><p>The Markov assumption (Section 6.2) is often unrealistic. We cannot directly perceive what is behind our back, let alone the current state of the entire universe. However, memories of previous events can help to deal with partially observable Markov decision problems (POMDPs) (e.g., <ref type="bibr" target="#b114">Boutilier &amp; Poole, 1996;</ref><ref type="bibr" target="#b338">Jaakkola, Singh, &amp; Jordan, 1995;</ref><ref type="bibr" target="#b359">Kaelbling et al., 1995;</ref><ref type="bibr" target="#b373">Kimura, Miyazaki, &amp; Kobayashi, 1997;</ref><ref type="bibr" target="#b437">Lin, 1993;</ref><ref type="bibr">Littman, Cassandra, &amp; Kaelbling, 1995;</ref><ref type="bibr" target="#b479">McCallum, 1996;</ref><ref type="bibr" target="#b548">Otsuka, Yoshimoto, &amp; Doya, 2010;</ref><ref type="bibr" target="#b602">Ring, 1991</ref><ref type="bibr" target="#b603">Ring, , 1993</ref><ref type="bibr" target="#b604">Ring, , 1994;;</ref><ref type="bibr" target="#b646">Schmidhuber, 1990d</ref><ref type="bibr" target="#b648">Schmidhuber, , 1991c;;</ref><ref type="bibr" target="#b738">Teller, 1994;</ref><ref type="bibr" target="#b798">Wiering &amp; Schmidhuber, 1996</ref><ref type="bibr" target="#b799">, 1998a;</ref><ref type="bibr" target="#b808">Williams, 1992a)</ref>. A naive way of implementing memories without leaving the MDP framework (Section 6.2) would be to simply consider a possibly huge state space, namely, the set of all possible observation histories and their prefixes. A more realistic way is to use function approximators such as RNNs that produce compact state features as a function of the entire history seen so far. Generally speaking, POMDP RL often uses DL RNNs to learn which events to memorize and which to ignore. Three basic alternatives are:</p><p>1. Use an RNN as a value function mapping arbitrary event histories to values (e.g., <ref type="bibr" target="#b53">Bakker, 2002;</ref><ref type="bibr" target="#b437">Lin, 1993;</ref><ref type="bibr" target="#b644">Schmidhuber, 1990b</ref><ref type="bibr" target="#b648">Schmidhuber, , 1991c</ref> In general, however, POMDPs may imply greatly increased CAP depth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">RL facilitated by deep UL in FNNs and RNNs</head><p>RL machines may profit from UL for input preprocessing (e.g., <ref type="bibr" target="#b348">Jodogne &amp; Piater, 2007)</ref>. In particular, an UL NN can learn to compactly encode environmental inputs such as images or videos, e.g., <ref type="bibr">Sections 5.7,</ref><ref type="bibr">5.10,</ref><ref type="bibr">5.15</ref>. The compact codes (instead of the high-dimensional raw data) can be fed into an RL machine, whose job thus may become much easier <ref type="bibr" target="#b147">(Cuccu, Luciw, Schmidhuber, &amp; Gomez, 2011;</ref><ref type="bibr" target="#b423">Legenstein, Wilbert, &amp; Wiskott, 2010)</ref>, just like SL may profit from UL, e.g., <ref type="bibr">Sections 5.7,</ref><ref type="bibr">5.10,</ref><ref type="bibr">5.15</ref>. For example, NFQ <ref type="bibr" target="#b597">(Riedmiller, 2005)</ref> was applied to real-world control tasks <ref type="bibr" target="#b404">(Lange &amp; Riedmiller, 2010;</ref><ref type="bibr" target="#b599">Riedmiller, Lange, &amp; Voigtlaender, 2012)</ref> where purely visual inputs were compactly encoded by deep autoencoders (Sections 5.7, 5.15). RL combined with UL based on Slow Feature Analysis <ref type="bibr" target="#b386">(Kompella, Luciw, &amp; Schmidhuber, 2012;</ref><ref type="bibr" target="#b815">Wiskott &amp; Sejnowski, 2002)</ref> enabled a real humanoid robot to learn skills from raw high-dimensional video streams <ref type="bibr" target="#b451">(Luciw, Kompella, Kazerounian, &amp; Schmidhuber, 2013)</ref>. To deal with POMDPs (Section 6.3) involving high-dimensional inputs, RBM-based RL was used (Otsuka, 2010), and a RAAM <ref type="bibr" target="#b574">(Pollack, 1988</ref>) (Section 5.7) was employed as a deep unsupervised sequence encoder for RL <ref type="bibr" target="#b236">(Gisslen et al., 2011)</ref>. Certain types of RL and UL also were combined in biologically plausible RNNs with spiking neurons (Section 5.26) (e.g., <ref type="bibr" target="#b376">Klampfl &amp; Maass, 2013;</ref><ref type="bibr" target="#b596">Rezende &amp; Gerstner, 2014;</ref><ref type="bibr" target="#b829">Yin et al., 2012)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.">Deep hierarchical RL (HRL) and subgoal learning with FNNs and RNNs</head><p>Multiple learnable levels of abstraction <ref type="bibr" target="#b95">(Bengio et al., 2013;</ref><ref type="bibr" target="#b161">Deng &amp; Yu, 2014;</ref><ref type="bibr" target="#b215">Fu, 1977;</ref><ref type="bibr">Lenat &amp; Brown, 1984;</ref><ref type="bibr" target="#b604">Ring, 1994)</ref> seem as important for RL as for SL. Work on NN-based Hierarchical RL (HRL) has been published since the early 1990s. In particular, gradient-based subgoal discovery with FNNs or RNNs decomposes RL tasks into subtasks for RL submodules <ref type="bibr" target="#b647">(Schmidhuber, 1991b;</ref><ref type="bibr" target="#b668">Schmidhuber &amp; Wahnsiedler, 1992)</ref>. Numerous alternative HRL techniques have been proposed (e.g., <ref type="bibr" target="#b54">Bakker &amp; Schmidhuber, 2004;</ref><ref type="bibr" target="#b70">Barto &amp; Mahadevan, 2003;</ref><ref type="bibr" target="#b170">Dietterich, 2000b;</ref><ref type="bibr" target="#b175">Doya, Samejima, Katagiri, &amp; Kawato, 2002;</ref><ref type="bibr" target="#b233">Ghavamzadeh &amp; Mahadevan, 2003;</ref><ref type="bibr">Jameson, 1991;</ref><ref type="bibr" target="#b482">Menache, Mannor, &amp; Shimkin, 2002;</ref><ref type="bibr" target="#b507">Moore &amp; Atkeson, 1995;</ref><ref type="bibr" target="#b580">Precup, Sutton, &amp; Singh, 1998;</ref><ref type="bibr" target="#b602">Ring, 1991</ref><ref type="bibr" target="#b604">Ring, , 1994;;</ref><ref type="bibr" target="#b629">Samejima, Doya, &amp; Kawato, 2003;</ref><ref type="bibr" target="#b699">Simsek &amp; Barto, 2008;</ref><ref type="bibr" target="#b739">Tenenberg, Karlsson, &amp; Whitehead, 1993;</ref><ref type="bibr" target="#b779">Weiss, 1994;</ref><ref type="bibr" target="#b794">Whiteson, Kohl, Miikkulainen, &amp; Stone, 2005)</ref>. While HRL frameworks such as Feudal RL <ref type="bibr" target="#b152">(Dayan &amp; Hinton, 1993)</ref> and options <ref type="bibr" target="#b71">(Barto, Singh, &amp; Chentanez, 2004;</ref><ref type="bibr" target="#b701">Singh et al., 2005;</ref><ref type="bibr" target="#b730">Sutton, Precup, &amp; Singh, 1999)</ref> do not directly address the problem of automatic subgoal discovery, HQ-Learning <ref type="bibr" target="#b799">(Wiering &amp; Schmidhuber, 1998a)</ref> automatically decomposes POMDPs (Section 6.3) into sequences of simpler subtasks that can be solved by memoryless policies learnable by reactive sub-agents. Recent HRL organizes potentially deep NN-based RL sub-modules into self-organizing, 2-dimensional motor control maps <ref type="bibr" target="#b605">(Ring, Schaul, &amp; Schmidhuber, 2011)</ref> inspired by neurophysiological findings <ref type="bibr" target="#b263">(Graziano, 2009)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6.">Deep RL by direct NN search/policy gradients/evolution</head><p>Not quite as universal as the methods of Section 6.8, yet both practical and more general than most traditional RL algorithms (Section 6.2), are methods for Direct Policy Search (DS). Without a need for value functions or Markovian assumptions (Sections 6.2, 6.3), the weights of an FNN or RNN are directly evaluated on the given RL problem. The results of successive trials inform further search for better weights. Unlike with RL supported by BP <ref type="bibr">(Sections 5.5,</ref><ref type="bibr">6.3,</ref><ref type="bibr">6.1)</ref>, CAP depth (Sections 3, 5.9) is not a crucial issue. DS may solve the credit assignment problem without backtracking through deep causal chains of modifiable parameters-it neither cares for their existence, nor tries to exploit them.</p><p>An important class of DS methods for NNs are Policy Gradient methods <ref type="bibr" target="#b25">(Aberdeen, 2003;</ref><ref type="bibr" target="#b77">Baxter &amp; Bartlett, 2001;</ref><ref type="bibr" target="#b233">Ghavamzadeh &amp; Mahadevan, 2003;</ref><ref type="bibr" target="#b265">Grondman, Busoniu, Lopes, &amp; Babuska, 2012;</ref><ref type="bibr" target="#b271">Grüttner et al., 2010;</ref><ref type="bibr" target="#b289">Heess, Silver, &amp; Teh, 2012;</ref><ref type="bibr" target="#b379">Kohl &amp; Stone, 2004;</ref><ref type="bibr" target="#b567">Peters, 2010;</ref><ref type="bibr" target="#b568">Peters &amp; Schaal, 2008a</ref><ref type="bibr" target="#b569">, 2008b;</ref><ref type="bibr" target="#b618">Rückstieß, Felder, &amp; Schmidhuber, 2008;</ref><ref type="bibr" target="#b681">Sehnke et al., 2010;</ref><ref type="bibr" target="#b729">Sutton, McAllester, Singh, &amp; Mansour, 1999;</ref><ref type="bibr" target="#b801">Wierstra, Foerster, Peters, &amp; Schmidhuber, 2010;</ref><ref type="bibr" target="#b802">Wierstra, Schaul, Peters, &amp; Schmidhuber, 2008;</ref><ref type="bibr" target="#b805">Williams, 1986</ref><ref type="bibr" target="#b806">Williams, , 1988</ref><ref type="bibr" target="#b808">Williams, , 1992a))</ref>. Gradients of the total reward with respect to policies (NN weights) are estimated (and then exploited) through repeated NN evaluations.</p><p>RL NNs can also be evolved through Evolutionary Algorithms (EAs) <ref type="bibr" target="#b209">(Fogel, Owens, &amp; Walsh, 1966;</ref><ref type="bibr" target="#b242">Goldberg, 1989;</ref><ref type="bibr" target="#b313">Holland, 1975;</ref><ref type="bibr" target="#b593">Rechenberg, 1971;</ref><ref type="bibr" target="#b680">Schwefel, 1974)</ref> in a series of trials. Here several policies are represented by a population of NNs improved through mutations and/or repeated recombinations of the population's fittest individuals (e.g., <ref type="bibr" target="#b208">Fogel, Fogel, &amp; Porto, 1990;</ref><ref type="bibr">Happel &amp; Murre, 1994;</ref><ref type="bibr" target="#b468">Maniezzo, 1994;</ref><ref type="bibr" target="#b501">Montana &amp; Davis, 1989;</ref><ref type="bibr" target="#b532">Nolfi, Parisi, &amp; Elman, 1994)</ref>. Compare Genetic Programming (GP) <ref type="bibr" target="#b145">(Cramer, 1985)</ref> (see also <ref type="bibr" target="#b703">Smith, 1980)</ref> which can be used to evolve computer programs of variable size <ref type="bibr" target="#b168">(Dickmanns, Schmidhuber, &amp; Winklhofer, 1987;</ref><ref type="bibr" target="#b394">Koza, 1992)</ref>, and Cartesian GP <ref type="bibr" target="#b488">(Miller &amp; Harding, 2009;</ref><ref type="bibr" target="#b489">Miller &amp; Thomson, 2000)</ref> for evolving graph-like programs, including NNs <ref type="bibr" target="#b371">(Khan, Khan, &amp; Miller, 2010)</ref> and their topology <ref type="bibr" target="#b750">(Turner &amp; Miller, 2013)</ref>. Related methods include probability distributionbased EAs <ref type="bibr" target="#b65">(Baluja, 1994;</ref><ref type="bibr" target="#b407">Larraanaga &amp; Lozano, 2001;</ref><ref type="bibr" target="#b628">Sałustowicz &amp; Schmidhuber, 1997;</ref><ref type="bibr" target="#b633">Saravanan &amp; Fogel, 1995)</ref>, Covariance Matrix Estimation Evolution Strategies (CMA-ES) <ref type="bibr" target="#b276">(Hansen, Müller, &amp; Koumoutsakos, 2003;</ref><ref type="bibr" target="#b277">Hansen &amp; Ostermeier, 2001;</ref><ref type="bibr" target="#b290">Heidrich-Meisner &amp; Igel, 2009;</ref><ref type="bibr" target="#b326">Igel, 2003)</ref>, and NeuroEvolution of Augmenting Topologies (NEAT) <ref type="bibr" target="#b715">(Stanley &amp; Miikkulainen, 2002)</ref>. Hybrid methods combine traditional NN-based RL (Section 6.2) and EAs (e.g., <ref type="bibr" target="#b795">Whiteson &amp; Stone, 2006)</ref>.</p><p>Since RNNs are general computers, RNN evolution is like GP in the sense that it can evolve general programs. Unlike sequential programs learned by traditional GP, however, RNNs can mix sequential and parallel information processing in a natural and efficient way, as already mentioned in Section 1. Many RNN evolvers have been proposed (e.g., <ref type="bibr">Cliff, Husbands, &amp; Harvey, 1993;</ref><ref type="bibr" target="#b356">Juang, 2004;</ref><ref type="bibr" target="#b486">Miglino, Lund, &amp; Nolfi, 1995;</ref><ref type="bibr" target="#b490">Miller, Todd, &amp; Hedge, 1989;</ref><ref type="bibr" target="#b508">Moriarty, 1997;</ref><ref type="bibr" target="#b531">Nolfi, Floreano, Miglino, &amp; Mondada, 1994;</ref><ref type="bibr" target="#b558">Pasemann, Steinmetz, &amp; Dieckman, 1999;</ref><ref type="bibr" target="#b698">Sims, 1994;</ref><ref type="bibr" target="#b793">Whiteson, 2012;</ref><ref type="bibr" target="#b797">Wieland, 1991;</ref><ref type="bibr" target="#b825">Yamauchi &amp; Beer, 1994;</ref><ref type="bibr" target="#b828">Yao, 1993)</ref>. One particularly effective family of methods coevolves neurons, combining them into networks, and selecting those neurons for reproduction that participated in the best-performing networks <ref type="bibr" target="#b245">(Gomez, 2003;</ref><ref type="bibr" target="#b246">Gomez &amp; Miikkulainen, 2003;</ref><ref type="bibr" target="#b508">Moriarty &amp; Miikkulainen, 1996)</ref>. This can help to solve deep POMDPs <ref type="bibr" target="#b247">(Gomez &amp; Schmidhuber, 2005)</ref>. Co-Synaptic Neuro-Evolution (CoSyNE) does something similar on the level of synapses or weights <ref type="bibr" target="#b248">(Gomez, Schmidhuber, &amp; Miikkulainen, 2008)</ref>; benefits of this were shown on difficult nonlinear POMDP benchmarks.</p><p>Natural Evolution Strategies (NES) <ref type="bibr" target="#b238">(Glasmachers, Schaul, Sun, Wierstra, &amp; Schmidhuber, 2010;</ref><ref type="bibr" target="#b725">Sun, Gomez, Schaul, &amp; Schmidhuber, 2013;</ref><ref type="bibr" target="#b726">Sun, Wierstra, Schaul, &amp; Schmidhuber, 2009;</ref><ref type="bibr" target="#b802">Wierstra et al., 2008)</ref> link policy gradient methods and evolutionary approaches through the concept of Natural Gradients <ref type="bibr" target="#b36">(Amari, 1998)</ref>. RNN evolution may also help to improve SL for deep RNNs through Evolino <ref type="bibr" target="#b669">(Schmidhuber et al., 2007)</ref> (Section 5.9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7.">Deep RL by indirect policy search/compressed NN search</head><p>Some DS methods (Section 6.6) can evolve NNs with hundreds or thousands of weights, but not millions. How to search for large and deep NNs? Most SL and RL methods mentioned so far somehow search the space of weights w i . Some profit from a reduction of the search space through shared w i that get reused over and over <ref type="bibr">again,</ref><ref type="bibr">e.g.,</ref><ref type="bibr">in CNNs (Sections 5.4,</ref><ref type="bibr">5.8,</ref><ref type="bibr">5.16,</ref><ref type="bibr">5.21)</ref>, or in RNNs for SL <ref type="bibr">(Sections 5.5,</ref><ref type="bibr">5.13,</ref><ref type="bibr">5.17) and RL (Sections 6.1,</ref><ref type="bibr">6.3,</ref><ref type="bibr">6.6)</ref>.</p><p>It may be possible, however, to exploit additional regularities/compressibilities in the space of solutions, through indirect search in weight space. Instead of evolving large NNs directly (Section 6.6), one can sometimes greatly reduce the search space by evolving compact encodings of NNs, e.g., through Lindenmeyer Systems <ref type="bibr" target="#b340">(Jacob, Lindenmayer, &amp; Rozenberg, 1994;</ref><ref type="bibr" target="#b439">Lindenmayer, 1968)</ref>, graph rewriting <ref type="bibr" target="#b375">(Kitano, 1990)</ref>, Cellular Encoding <ref type="bibr" target="#b269">(Gruau, Whitley, &amp; Pyeatt, 1996)</ref>, HyperNEAT (Clune, <ref type="bibr">Stanley, Pennock, &amp; Ofria, 2011;</ref><ref type="bibr" target="#b150">D'Ambrosio &amp; Stanley, 2007;</ref><ref type="bibr" target="#b714">Stanley, D'Ambrosio, &amp; Gauci, 2009;</ref><ref type="bibr">van den Berg &amp; Whiteson, 2013)</ref> (extending NEAT; Section 6.6), and extensions thereof (e.g., <ref type="bibr" target="#b606">Risi &amp; Stanley, 2012)</ref>. This helps to avoid overfitting (compare <ref type="bibr">Sections 5.6.3,</ref><ref type="bibr">5.24)</ref> and is closely related to the topics of regularization and MDL (Section 4.4).</p><p>A general approach <ref type="bibr" target="#b654">(Schmidhuber, 1997)</ref> for both SL and RL seeks to compactly encode weights of large NNs <ref type="bibr" target="#b654">(Schmidhuber, 1997)</ref> through programs written in a universal programming language <ref type="bibr">(Church, 1936;</ref><ref type="bibr" target="#b241">Gödel, 1931;</ref><ref type="bibr" target="#b578">Post, 1936;</ref><ref type="bibr" target="#b749">Turing, 1936)</ref>. Often it is much more efficient to systematically search the space of such programs with a bias towards short and fast programs <ref type="bibr" target="#b430">(Levin, 1973b;</ref><ref type="bibr" target="#b654">Schmidhuber, 1997</ref><ref type="bibr" target="#b656">Schmidhuber, , 2004))</ref>, instead of directly searching the huge space of possible NN weight matrices. A previous universal language for encoding NNs was assembler-like <ref type="bibr" target="#b654">(Schmidhuber, 1997)</ref>. More recent work uses more practical languages based on coefficients of popular transforms <ref type="bibr">(Fourier, wavelet, etc.)</ref>. In particular, RNN weight matrices may be compressed like images, by encoding them through the coefficients of a discrete cosine transform (DCT) <ref type="bibr" target="#b392">(Koutník et al., 2013;</ref><ref type="bibr" target="#b392">Koutník, Gomez, &amp; Schmidhuber, 2010)</ref>. Compact DCT-based descriptions can be evolved through NES or CoSyNE (Section 6.6). An RNN with over a million weights learned (without a teacher) to drive a simulated car in the TORCS driving game <ref type="bibr" target="#b447">(Loiacono, Cardamone, &amp; Lanzi, 2011;</ref><ref type="bibr" target="#b448">Loiacono et al., 2009)</ref>, based on a high-dimensional videolike visual input stream <ref type="bibr" target="#b392">(Koutník et al., 2013)</ref>. The RNN learned both control and visual processing from scratch, without being aided by UL. (Of course, UL might help to generate more compact image codes (Sections 6.4, 4.2) to be fed into a smaller RNN, to reduce the overall computational effort.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.8.">Universal RL</head><p>General purpose learning algorithms may improve themselves in open-ended fashion and environment-specific ways in a lifelong learning context <ref type="bibr" target="#b641">(Schmidhuber, 1987;</ref><ref type="bibr" target="#b670">Schmidhuber, Zhao, &amp; Schraudolph, 1997;</ref><ref type="bibr" target="#b671">Schmidhuber, Zhao, &amp; Wiering, 1997)</ref>. The most general type of RL is constrained only by the fundamental limitations of computability identified by the founders of theoretical computer science <ref type="bibr">(Church, 1936;</ref><ref type="bibr" target="#b241">Gödel, 1931;</ref><ref type="bibr" target="#b578">Post, 1936;</ref><ref type="bibr" target="#b749">Turing, 1936)</ref>. Remarkably, there exist blueprints of universal problem solvers or universal RL machines for unlimited problem depth that are time-optimal in various theoretical senses <ref type="bibr" target="#b322">(Hutter, 2002</ref><ref type="bibr" target="#b323">(Hutter, , 2005;;</ref><ref type="bibr" target="#b655">Schmidhuber, 2002</ref><ref type="bibr" target="#b658">Schmidhuber, , 2006b))</ref>. In particular, the Gödel Machine can be implemented on general computers such as RNNs and may improve any part of its software (including the learning algorithm itself) in a way that is provably time-optimal in a certain sense <ref type="bibr" target="#b658">(Schmidhuber, 2006b)</ref>. It can be initialized by an asymptotically optimal meta-method <ref type="bibr" target="#b322">(Hutter, 2002)</ref> (also applicable to RNNs) which will solve any well-defined problem as quickly as the unknown fastest way of solving it, save for an additive constant overhead that becomes negligible as problem size grows. Note that most problems are large; only few are small. AI and DL researchers are still in business because many are interested in problems so small that it is worth trying to reduce the overhead through less general methods, including heuristics. Here I will not further discuss universal RL methods, which go beyond what is usually called DL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion and outlook</head><p>Deep <ref type="bibr">Learning (DL)</ref> in Neural Networks (NNs) is relevant for Supervised Learning (SL) (Section 5), Unsupervised Learning (UL) (Section 5), and Reinforcement Learning (RL) (Section 6). By alleviating problems with deep Credit Assignment Paths (CAPs, Sections 3, 5.9), UL (Section 5.6.4) cannot only facilitate SL of sequences (Section 5.10) and stationary patterns <ref type="bibr">(Sections 5.7,</ref><ref type="bibr">5.15)</ref>, but also RL (Sections 6.4, 4.2). Dynamic Programming (DP, Section 4.1) is important for both deep SL (Section 5.5) and traditional RL with deep NNs (Section 6.2). A search for solutioncomputing, perturbation-resistant <ref type="bibr">(Sections 5.6.3,</ref><ref type="bibr">5.15,</ref><ref type="bibr">5.24)</ref>, low-complexity NNs describable by few bits of information (Section 4.4) can reduce overfitting and improve deep SL &amp; UL <ref type="bibr">(Sections 5.6.3,</ref><ref type="bibr">5.6.4)</ref> as well as RL (Section 6.7), also in the case of partially observable environments (Section 6.3). Deep SL, UL, RL often create hierarchies of more and more abstract representations of stationary data <ref type="bibr">(Sections 5.3,</ref><ref type="bibr">5.7,</ref><ref type="bibr">5.15)</ref>, sequential data (Section 5.10), or RL policies (Section 6.5). While UL can facilitate SL, pure SL for feedforward NNs (FNNs) <ref type="bibr">(Sections 5.5,</ref><ref type="bibr">5.8,</ref><ref type="bibr">5.16,</ref><ref type="bibr">5.18</ref>) and recurrent NNs (RNNs) (Sections 5.5, 5.13) did not only win early contests (Sections 5.12, 5.14) but also most of the recent ones . Especially DL in FNNs profited from GPU implementations ). In particular, GPUbased (Section 5.19) Max-Pooling (Section 5.11) Convolutional NNs <ref type="bibr">(Sections 5.4,</ref><ref type="bibr">5.8,</ref><ref type="bibr">5.16</ref>) won competitions not only in pattern recognition ) but also image segmentation (Section 5.21) and object detection <ref type="bibr">(Sections 5.21,</ref><ref type="bibr">5.22)</ref>.</p><p>Unlike these systems, humans learn to actively perceive patterns by sequentially directing attention to relevant parts of the available data. Near future deep NNs will do so, too, extending previous work since 1990 on NNs that learn selective attention through RL of (a) motor actions such as saccade control (Section 6.1) and (b) internal actions controlling spotlights of attention within RNNs, thus closing the general sensorimotor loop through both external and internal feedback (e.g., Sections 2, <ref type="bibr">5.21, 6.6, 6.7)</ref>.</p><p>Many future deep NNs will also take into account that it costs energy to activate neurons, and to send signals between them. Brains seem to minimize such computational costs during problem solving in at least two ways: (1) At a given time, only a small fraction of all neurons is active because local competition through winner-take-all mechanisms shuts down many neighboring neurons, and only winners can activate other neurons through outgoing connections (compare SLIM NNs; Section 5.24). (2) Numerous neurons are sparsely connected in a compact 3D volume by many short-range and few long-range connections (much like microchips in traditional supercomputers). Often neighboring neurons are allocated to solve a single task, thus reducing communication costs. Physics seems to dictate that any efficient computational hardware will in the future also have to be brain-like in keeping with these two constraints. The most successful current deep RNNs, however, are not. Unlike certain spiking NNs (Section 5.26), they usually activate all units at least slightly, and tend to be strongly connected, ignoring natural constraints of 3D hardware. It should be possible to improve them by adopting (1) and (2), and by minimizing non-differentiable energy and communication costs through direct search in program (weight) space (e.g., <ref type="bibr">Sections 6.6,</ref><ref type="bibr">6.7</ref>). These more brain-like RNNs will allocate neighboring RNN parts to related behaviors, and distant RNN parts to less related ones, thus self-modularizing in a way more general than that of traditional self-organizing maps in FNNs (Section 5.6.4). They will also implement Occam's razor <ref type="bibr">(Sections 4.4,</ref><ref type="bibr">5.6.3)</ref> as a by-product of energy minimization, by finding simple (highly generalizing) problem solutions that require few active neurons and few, mostly short connections.</p><p>The more distant future may belong to general purpose learning algorithms that improve themselves in provably optimal ways (Section 6.8), but these are not yet practical or commercially relevant.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Algorithm 5 . 5 . 1 :</head><label>551</label><figDesc>One iteration of BP for weight-sharing FNNs or RNNsfor t = T , .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>; Soloway,   </figDesc><table><row><cell cols="2">Abbreviations in alphabetical order</cell></row><row><cell>AE:</cell><cell>Autoencoder</cell></row><row><cell>AI:</cell><cell>Artificial Intelligence</cell></row><row><cell>ANN:</cell><cell>Artificial Neural Network</cell></row><row><cell>BFGS:</cell><cell>Broyden-Fletcher-Goldfarb-Shanno</cell></row><row><cell>BNN:</cell><cell>Biological Neural Network</cell></row><row><cell>BM:</cell><cell>Boltzmann Machine</cell></row><row><cell>BP:</cell><cell>Backpropagation</cell></row><row><cell cols="2">BRNN: Bi-directional Recurrent Neural Network</cell></row><row><cell>CAP:</cell><cell>Credit Assignment Path</cell></row><row><cell>CEC:</cell><cell>Constant Error Carousel</cell></row><row><cell>CFL:</cell><cell>Context Free Language</cell></row><row><cell cols="2">CMA-ES: Covariance Matrix Estimation ES</cell></row><row><cell>CNN:</cell><cell>Convolutional Neural Network</cell></row><row><cell cols="2">CoSyNE: Co-Synaptic Neuro-Evolution</cell></row><row><cell>CSL:</cell><cell>Context Sensitive Language</cell></row><row><cell>CTC:</cell><cell>Connectionist Temporal Classification</cell></row><row><cell>DBN:</cell><cell>Deep Belief Network</cell></row><row><cell>DCT:</cell><cell>Discrete Cosine Transform</cell></row><row><cell>DL:</cell><cell>Deep Learning</cell></row><row><cell>DP:</cell><cell>Dynamic Programming</cell></row><row><cell>DS:</cell><cell>Direct Policy Search</cell></row><row><cell>EA:</cell><cell>Evolutionary Algorithm</cell></row><row><cell>EM:</cell><cell>Expectation Maximization</cell></row><row><cell>ES:</cell><cell>Evolution Strategy</cell></row><row><cell>FMS:</cell><cell>Flat Minimum Search</cell></row><row><cell>FNN:</cell><cell>Feedforward Neural Network</cell></row><row><cell>FSA:</cell><cell>Finite State Automaton</cell></row><row><cell cols="2">GMDH: Group Method of Data Handling</cell></row><row><cell cols="2">GOFAI: Good Old-Fashioned AI</cell></row><row><cell>GP:</cell><cell>Genetic Programming</cell></row><row><cell>GPU:</cell><cell>Graphics Processing Unit</cell></row><row><cell cols="2">GPU-MPCNN: GPU-Based MPCNN</cell></row><row><cell cols="2">HMM: Hidden Markov Model</cell></row><row><cell>HRL:</cell><cell>Hierarchical Reinforcement Learning</cell></row><row><cell>HTM:</cell><cell>Hierarchical Temporal Memory</cell></row><row><cell cols="2">HMAX: Hierarchical Model ''and X''</cell></row><row><cell cols="2">LSTM: Long Short-Term Memory (RNN)</cell></row><row><cell>MDL:</cell><cell>Minimum Description Length</cell></row><row><cell>MDP:</cell><cell>Markov Decision Process</cell></row><row><cell cols="2">MNIST: Mixed National Institute of Standards and Technol-</cell></row><row><cell></cell><cell>ogy Database</cell></row><row><cell>MP:</cell><cell>Max-Pooling</cell></row><row><cell cols="2">MPCNN: Max-Pooling CNN</cell></row><row><cell>NE:</cell><cell>NeuroEvolution</cell></row><row><cell cols="2">NEAT: NE of Augmenting Topologies</cell></row><row><cell>NES:</cell><cell>Natural Evolution Strategies</cell></row><row><cell>NFQ:</cell><cell>Neural Fitted Q-Learning</cell></row><row><cell>NN:</cell><cell>Neural Network</cell></row><row><cell>OCR:</cell><cell>Optical Character Recognition</cell></row><row><cell>PCC:</cell><cell>Potential Causal Connection</cell></row><row><cell cols="2">PDCC: Potential Direct Causal Connection</cell></row><row><cell>PM:</cell><cell>Predictability Minimization</cell></row><row><cell cols="2">POMDP: Partially Observable MDP</cell></row><row><cell cols="2">RAAM: Recursive Auto-Associative Memory</cell></row><row><cell>RBM:</cell><cell>Restricted Boltzmann Machine</cell></row><row><cell>ReLU:</cell><cell>Rectified Linear Unit</cell></row><row><cell>RL:</cell><cell>Reinforcement Learning</cell></row><row><cell>RNN:</cell><cell>Recurrent Neural Network</cell></row><row><cell cols="2">R-prop: Resilient Backpropagation</cell></row><row><cell>SL:</cell><cell>Supervised Learning</cell></row><row><cell cols="2">SLIM NN: Self-Delimiting Neural Network</cell></row><row><cell>SOTA:</cell><cell>Self-Organizing Tree Algorithm</cell></row><row><cell>SVM:</cell><cell>Support Vector Machine</cell></row><row><cell cols="2">TDNN: Time-Delay Neural Network</cell></row><row><cell cols="2">TIMIT: TI/SRI/MIT Acoustic-Phonetic Continuous Speech</cell></row><row><cell></cell><cell>Corpus</cell></row><row><cell>UL:</cell><cell>Unsupervised Learning</cell></row><row><cell>WTA:</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>. . , 1 do is an input event then continue with next iteration; if there is an error e t then δ t := x t − d t ; add to δ t the value  k∈out for all k ∈ in t add to △ w v(k,t) the value x k δ t</figDesc><table><row><cell>to compute ∂E ∂net t by 0;</cell><cell>, initialize real-valued error signal variable δ t</cell></row><row><cell>if x t end for</cell><cell></cell></row><row><cell>change each w</cell><cell></cell></row></table><note>t w v(t,k) δ k ; (this is the elegant and efficient recursive chain rule application collecting impacts of net t on future events) multiply δ t by f ′ t (net t ); i in proportion to △ i and a small real-valued learning rate</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>. Use an RNN controller in conjunction with a second RNN as predictive world model, to obtain a combined RNN with deep CAPs-see Section 6.1. 3. Use an RNN for RL by Direct Search (Section 6.6) or Indirect Search (Section 6.7) in weight space.</figDesc><table /><note>). For example, deep LSTM RNNs were used in this way for RL robots<ref type="bibr" target="#b54">(Bakker, Zhumatiy, Gruener, &amp; Schmidhuber, 2003)</ref>. 2</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">J.Schmidhuber / Neural Networks 61 (2015)   </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">It should be mentioned, however, that LSTM RNNs already performed simultaneous segmentation and recognition when they became the first recurrent Deep Learners to win official international pattern recognition contests-see Section 5.17.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Since 16 April 2014, drafts of this paper have undergone massive open online peer review through public mailing lists including connectionists@cs.cmu.edu, ml-news@googlegroups.com, compneuro@neuroinf.org, genetic_programming@yahoogroups.com, rllist@googlegroups.com, imageworld@diku.dk, Google+ machine learning forum. Thanks to numerous NN/DL experts for valuable comments. Thanks to SNF, DFG, and the European Commission for partially funding my DL research group in the past quarter-century. The contents of this paper may be used for educational and noncommercial purposes, including articles for Wikipedia and similar sites.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m">convolution + weight replication + subsampling</title>
				<imprint>
			<date type="published" when="1979">1979</date>
			<biblScope unit="page">90</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m">1960-1981 and beyond: development of backpropagation</title>
				<imprint>
			<biblScope unit="page">90</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">BP for weight-sharing feedforward NNs (FNNs) and recurrent NNs (RNNs)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m">Late 1980s-2000 and beyond</title>
				<imprint>
			<biblScope unit="page">91</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Better BP through advanced gradient descent (compare Section 5.24)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Searching for simple, low-complexity, problem-solving NNs</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">UL through Autoencoder (AE) hierarchies (compare Section 5.15)</title>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m">BP for convolutional NNs (CNNs, Section 5.4)</title>
				<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page">93</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">UL-based history compression through a deep stack</title>
		<idno>5.10. 1991</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<idno>5.11. 1992</idno>
		<title level="m">Max-Pooling (MP): towards MPCNNs (compare Sections 5</title>
				<imprint>
			<biblScope unit="volume">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">E-Mail</forename><surname>Address</surname></persName>
			<affiliation>
				<orgName type="collaboration">early contest-winning NNs....................................................................................................................................................................</orgName>
			</affiliation>
		</author>
		<idno type="DOI">10.1016/j.neunet.2014.09.003</idno>
		<ptr target="http://dx" />
		<title level="m">juergen@idsia</title>
				<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page">95</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">1995: supervised recurrent very Deep Learner</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">2003: more contest-winning/record-setting NNs</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m">2006/7: UL for deep belief networks/AE stacks fine-tuned by</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m">2009: first official competitions won by RNNs, and</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<idno>5.19. 2011</idno>
		<title level="m">MPCNNs on GPU achieve superhuman</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m">Hessian-free</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page">98</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">2012: first contests won on ImageNet, object detection</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m">Currently successful techniques: LSTM RNNs and</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m">Recent tricks for improving SL deep NNs</title>
				<imprint>
			<date type="published" when="2003-06-05">compare Sections 5.6.2, 5.6.3</date>
			<biblScope unit="page">99</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">100 6.1. RL through NN world models yields RNNs with deep</title>
	</analytic>
	<monogr>
		<title level="m">DL in FNNs and RNNs for Reinforcement Learning</title>
				<imprint>
			<biblScope unit="page">100</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Deep FNNs for traditional RL and Markov Decision Processes (MDPs)</title>
		<imprint>
			<biblScope unit="page">101</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m">Deep RL RNNs for partially observable MDPs</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Deep hierarchical RL (HRL) and subgoal learning with</title>
		<imprint>
			<biblScope unit="page">102</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Deep RL by direct NN search/policy gradients/evolution</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Policy-gradient algorithms for partially observable Markov decision processes</title>
		<author>
			<persName><forename type="first">D</forename><surname>References Aberdeen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Australian National University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning algorithms for Markov decision processes with average cost</title>
		<author>
			<persName><forename type="first">J</forename><surname>Abounadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bertsekas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Borkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Control and Optimization</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="681" to="698" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Statistical predictor identification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Akaike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of the Institute of Statistical Mathematics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="203" to="217" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Information theory and an extension of the maximum likelihood principle</title>
		<author>
			<persName><forename type="first">H</forename><surname>Akaike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second intl. symposium on information theory</title>
				<imprint>
			<date type="published" when="1973">1973</date>
			<biblScope unit="page" from="267" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A new look at the statistical model identification</title>
		<author>
			<persName><forename type="first">Akademinai</forename><surname>Kiado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Akaike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="716" to="723" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Application of time-bounded Kolmogorov complexity in complexity theory</title>
		<author>
			<persName><forename type="first">A</forename><surname>Allender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EATCS monographs on theoretical computer science, Kolmogorov complexity and computational complexity</title>
				<editor>
			<persName><forename type="first">O</forename><surname>Watanabe</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="6" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A learning rule for asynchronous perceptrons with feedback in a combinatorial environment</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Almeida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 1st international conference on neural networks</title>
				<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="609" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">On-line step size adaptation</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Langlois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Redol</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">INESC</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Rua Alves Redol</title>
		<imprint>
			<date type="published" when="1000">1000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A theory of adaptive pattern classifiers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Amari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Electronic Computers</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="299" to="307" />
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Natural gradient works efficiently in learning</title>
		<author>
			<persName><forename type="first">S.-I</forename><surname>Amari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="251" to="276" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A new learning algorithm for blind signal separation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Amari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cichocki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Hasselmo</surname></persName>
		</editor>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Statistical theory of learning curves under entropic loss criterion</title>
		<author>
			<persName><forename type="first">S</forename><surname>Amari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Murata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="140" to="153" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Dynamics of a recurrent network of spiking neurons before and following learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Amit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Brunel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Network: Computation in Neural Systems</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="373" to="404" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The effects of adding noise during backpropagation training on a generalization performance</title>
		<author>
			<persName><forename type="first">G</forename><surname>An</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="643" to="674" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Evaluation of secondary structure of proteins from UV circular dichroism spectra using an unsupervised learning neural network</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Andrade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chacon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Merelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Moran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Protein Engineering</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="383" to="390" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Survey and critique of techniques for extracting rules from trained artificial neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Diederich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Tickle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="373" to="389" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Mixing floating-and fixed-point formats for neural network learning on neuroprocessors. Microprocessing and Microprogramming</title>
		<author>
			<persName><forename type="first">D</forename><surname>Anguita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Gomes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="757" to="769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">An efficient implementation of BP on RISC-based workstations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Anguita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Parodi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zunino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="65" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep machine learning-a new frontier in artificial intelligence research</title>
		<author>
			<persName><forename type="first">I</forename><surname>Arel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Karnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computational Intelligence Magazine</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="13" to="18" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Dynamic node creation in backpropagation neural networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connection Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="365" to="375" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Understanding retinal color coding from first principles</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Atick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Redlich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="559" to="572" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">New results on recurrent network training: unifying the algorithms and accelerating convergence</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Atiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Parlos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="697" to="709" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Adaptive dropout for training deep neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Frey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3084" to="3092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Document image defect models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Baird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceddings, IAPR workshop on syntactic and structural pattern recognition</title>
				<meeting>eddings, IAPR workshop on syntactic and structural pattern recognition</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Residual algorithms: Reinforcement learning with function approximation</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Baird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="30" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Gradient descent for general reinforcement learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Baird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="968" to="974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Reinforcement learning with long short-term memory</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bakker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<editor>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Becker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1475" to="1482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Hierarchical reinforcement learning based on subgoal discovery and subpolicy specialization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bakker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">;</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zhumatiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gruener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 IEEE/RSJ international conference on intelligent robots and systems</title>
				<editor>
			<persName><forename type="first">F</forename><surname>Groen</surname></persName>
		</editor>
		<meeting>the 2003 IEEE/RSJ international conference on intelligent robots and systems<address><addrLine>Amsterdam, NL; Bakker, B</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2003">2004. 2003</date>
			<biblScope unit="page" from="430" to="435" />
		</imprint>
	</monogr>
	<note>Proc. 8th conference on intelligent autonomous systems IAS-8</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Gradient descent learning algorithms overview: A general dynamical systems perspective</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="182" to="195" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Autoencoders, unsupervised learning, and deep architectures</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2011 ICML Workshop on Unsupervised and Transfer Learning</title>
				<meeting>2011 ICML Workshop on Unsupervised and Transfer Learning</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="37" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Exploiting the past and the future in protein secondary structure prediction</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brunak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pollastri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Soda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="937" to="946" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Neural networks for fingerprint recognition</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chauvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="402" to="418" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Hybrid modeling, HMM/NN architectures, and protein applications</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chauvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1541" to="1565" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Neural networks and principal component analysis: learning from examples without local minima</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hornik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="53" to="58" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Learning in linear networks: a survey</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hornik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="837" to="858" />
			<date type="published" when="1995">1995. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">The principled design of large-scale recursive neural network architectures-DAG-RNNs and the protein structure prediction problem</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pollastri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="575" to="602" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">The dropout learning algorithm</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sadowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">210</biblScope>
			<biblScope unit="page" from="78" to="122" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Modular learning in neural networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Ballard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI</title>
				<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="279" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Population-based incremental learning: A method for integrating genetic search based function optimization and competitive learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baluja</surname></persName>
		</author>
		<idno>CMU-CS-94-163</idno>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A 15 year perspective on automatic programming</title>
		<author>
			<persName><forename type="first">R</forename><surname>Balzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1257" to="1268" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Unsupervised learning</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Barlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="295" to="311" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Finding minimum entropy codes</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Barlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Kaushal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Mitchison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="412" to="423" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Learning receptive fields</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Barrow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE 1st annual conference on neural networks</title>
				<meeting>the IEEE 1st annual conference on neural networks</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1987">1987</date>
			<biblScope unit="volume">IV</biblScope>
			<biblScope unit="page" from="115" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Recent advances in hierarchical reinforcement learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahadevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Event Dynamic Systems</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="379" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Intrinsically motivated learning of hierarchical collections of skills</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chentanez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of international conference on developmental learning</title>
				<meeting>international conference on developmental learning<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="112" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Neuronlike adaptive elements that can solve difficult learning control problems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Anderson</surname></persName>
		</author>
		<idno>SMC-13</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="page" from="834" to="846" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Accelerated backpropagation learning: two optimization methods</title>
		<author>
			<persName><forename type="first">R</forename><surname>Battiti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Systems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="331" to="342" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">First-and second-order methods for learning: between steepest descent and Newton&apos;s method</title>
		<author>
			<persName><forename type="first">T</forename><surname>Battiti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="141" to="166" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">What size net gives valid generalization?</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Baum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Haussler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="151" to="160" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Statistical inference for probabilistic functions of finite state Markov chains. The Annals of Mathematical Statistics</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Baum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Petrie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966">1966</date>
			<biblScope unit="page" from="1554" to="1563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Infinite-horizon policy-gradient estimation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Baxter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="319" to="350" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Variational inference of latent state sequences using recurrent networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Osendorfer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.1655</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv Preprint</note>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">On fast dropout and its applicability to recurrent networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Osendorfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Van Der Smagt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1311.0701</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv Preprint</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Evolving memory cell structures for sequence learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Togelius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICANN</title>
				<meeting>ICANN</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="755" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">An essay toward solving a problem in the doctrine of chances</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society of London</title>
		<editor>R. Price</editor>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="370" to="418" />
			<date type="published" when="1763">1763</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Unsupervised learning procedures for neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Becker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Neural Systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="17" to="33" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Improving the convergence of back-propagation learning with second order methods</title>
		<author>
			<persName><forename type="first">S</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Le Cun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1988 connectionist models summer school</title>
				<editor>
			<persName><forename type="first">D</forename><surname>Touretzky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">T</forename><surname>Sejnowski</surname></persName>
		</editor>
		<meeting>1988 connectionist models summer school<address><addrLine>San Mateo</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1988">1989. 1988</date>
			<biblScope unit="page" from="29" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Hebbian learning and competition in the neural abstraction pyramid</title>
		<author>
			<persName><forename type="first">S</forename><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international joint conference on neural networks</title>
				<meeting>the international joint conference on neural networks</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1356" to="1361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Learning iterative image reconstruction in the neural abstraction pyramid</title>
		<author>
			<persName><forename type="first">S</forename><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computational Intelligence and Applications</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="427" to="438" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Learning face localization using hierarchical recurrent networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th international conference on artificial neural networks</title>
				<meeting>the 12th international conference on artificial neural networks</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1319" to="1324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Discovering hierarchical speech features using convolutional non-negative matrix factorization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international joint conference on neural networks</title>
				<meeting>the international joint conference on neural networks</meeting>
		<imprint>
			<date type="published" when="2003">2003a</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2758" to="2763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Hierarchical neural networks for image interpretation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LNCS</title>
		<imprint>
			<biblScope unit="volume">2766</biblScope>
			<date type="published" when="2003">2003b</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Face localization and tracking in the neural abstraction pyramid</title>
		<author>
			<persName><forename type="first">S</forename><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="97" to="103" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Neural abstraction pyramid: a hierarchical image understanding architecture</title>
		<author>
			<persName><forename type="first">S</forename><surname>Behnke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rojas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of international joint conference on neural networks</title>
				<meeting>international joint conference on neural networks</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="820" to="825" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">An information-maximization approach to blind separation and blind deconvolution</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1129" to="1159" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">A blind source separation technique using second-order statistics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bellman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Belouchrani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Abed-Meraim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moulines</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="434" to="444" />
			<date type="published" when="1957">1957. 1997</date>
			<publisher>Princeton University Press</publisher>
		</imprint>
	</monogr>
	<note>Dynamic programming</note>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">Artificial neural networks and their application to sequence recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<pubPlace>Montreal, QC, Canada</pubPlace>
		</imprint>
		<respStmt>
			<orgName>McGill University, (Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Foundations and trends in machine learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Now Publishers</publisher>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>Learning deep architectures for AI</note>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Representation learning: a review and new perspectives</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<editor>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Cowan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Tesauro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Alspector</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Learning long-term dependencies with gradient descent is difficult</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="166" />
			<date type="published" when="1994">1994</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Classifying unprompted speech by retraining LSTM nets</title>
		<author>
			<persName><forename type="first">N</forename><surname>Beringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Schiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial neural networks: biological inspirations-ICANN 2005</title>
				<editor>
			<persName><forename type="first">W</forename><surname>Duch</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Kacprzyk</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Oja</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">S</forename><surname>Zadrozny</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3696</biblScope>
			<biblScope unit="page" from="575" to="581" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Parallel and serial neural mechanisms for visual search in macaque area V4</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Tsitsiklis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<editor>Athena Scientific. Bichot, N. P., Rossi, A. F., &amp; Desimone, R.</editor>
		<imprint>
			<biblScope unit="volume">308</biblScope>
			<biblScope unit="page" from="529" to="534" />
			<date type="published" when="1996">2001. 1996. 2005</date>
		</imprint>
		<respStmt>
			<orgName>Athena Scientific. Bertsekas,</orgName>
		</respStmt>
	</monogr>
	<note>Dynamic programming and optimal control</note>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">A learning algorithm for multilayered neural networks based on linear least squares problems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Biegler-König</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bärmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="127" to="131" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Curvature-driven smoothing: A learning algorithm for feedforward networks</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="882" to="884" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title level="m" type="main">Pattern recognition and machine learning</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Analysis of dynamical recognizers</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Blair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Pollack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1127" to="1142" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">A survey of computational complexity results in systems and control</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">D</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1249" to="1274" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">The A2iA Arabic handwritten text recognition system at the OpenHaRT2013 evaluation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bluche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Knibbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Moysset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Benzeghiba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kermorvant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International workshop on document analysis systems</title>
				<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Blum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Rivest</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1992">2014. 1992</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="117" to="127" />
		</imprint>
	</monogr>
	<note>Training a 3-node neural network is NP-complete</note>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Occam&apos;s razor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blumer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ehrenfeucht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Haussler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Warmuth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing Letters</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="377" to="380" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Learning processes in multilayer threshold nets</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bobrowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Context-free and context-sensitive dynamics in recurrent neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bodén</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wiles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connection Science</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="197" to="210" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">The Tempo 2 algorithm: adjusting timedelays by supervised learning</title>
		<author>
			<persName><forename type="first">U</forename><surname>Bodenhausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Waibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Lippman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="155" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Error-backpropagation in temporally encoded networks of spiking neurons</title>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Bohte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>La Poutre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="37" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Leipzig: Barth (collection of Boltzmann&apos;s articles in scientific journals)</title>
		<author>
			<persName><forename type="first">L</forename><surname>Boltzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wissenschaftliche Abhandlungen</title>
				<editor>
			<persName><forename type="first">F</forename><surname>Hasenöhrl</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1909">1909</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title level="m" type="main">Une approche théorique de l&apos;apprentissage connexioniste; applications à la reconnaissance de la parole</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
		<respStmt>
			<orgName>Université de Paris XI</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title level="m" type="main">Connnectionist speech recognition: a hybrid approach</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bourlard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Morgan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>Kluwer Academic Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Computing optimal policies for partially observable Markov decision processes using compact representations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Boutilier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Bradtke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Kaelbling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI</title>
				<meeting>the AAAI</meeting>
		<imprint>
			<date type="published" when="1996">1996. 1996</date>
			<biblScope unit="page" from="22" to="33" />
		</imprint>
	</monogr>
	<note>Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">R-MAX-a general polynomial time algorithm for near-optimal reinforcement learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I</forename><surname>Brafman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tennenholtz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="213" to="231" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Matching recall and storage in sequence learning with spiking neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Senn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="9565" to="9575" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Bagging predictors</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="123" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Simulation of networks of spiking neurons: a review of tools and strategies</title>
		<author>
			<persName><forename type="first">R</forename><surname>Brette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Carnevale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Beeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Bower</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Neuroscience</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="349" to="398" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">High-performance OCR for printed English and Fraktur using LSTM networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ul-Hasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Al-Azawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shafait</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th International conference on document analysis and recognition</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="683" to="687" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Signature verification using a Siamese time delay neural network</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bromley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Bentz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Pattern Recognition and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="669" to="688" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">A class of methods for solving nonlinear simultaneous equations</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Broyden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Computation</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">92</biblScope>
			<biblScope unit="page" from="577" to="593" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Social signal classification using deep BLSTM recurrent neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Brueckner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schulter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 39th IEEE international conference on acoustics, speech, and signal processing</title>
				<meeting>39th IEEE international conference on acoustics, speech, and signal processing</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="4856" to="4860" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Dynamics of sparsely connected networks of excitatory and inhibitory spiking neurons</title>
		<author>
			<persName><forename type="first">N</forename><surname>Brunel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="183" to="208" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">A gradient method for optimizing multi-stage allocation processes</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Bryson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Bryson</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Denham</surname></persName>
		</author>
		<idno>BR-1303</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. Harvard Univ. symposium on digital computers and their applications</title>
				<meeting>Harvard Univ. symposium on digital computers and their applications</meeting>
		<imprint>
			<date type="published" when="1961">1961. 1961</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>A steepest-ascent method for solving optimum programming problems. Raytheon Company, Missle and Space Division</note>
</biblStruct>

<biblStruct xml:id="b125">
	<monogr>
		<title level="m" type="main">Applied optimal control: optimization, estimation, and control</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bryson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969">1969</date>
			<publisher>Blaisdell Pub. Co</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Efficient large-scale sequence comparison by locality-sensitive hashing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Buhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="419" to="428" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Bayesian back-propagation</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Buntine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Weigend</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Systems</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="603" to="643" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">A constructive algorithm that converges for real-valued input patterns</title>
		<author>
			<persName><forename type="first">N</forename><surname>Burgess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Neural Systems</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="66" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">On the performance of orthogonal source separation algorithms</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Cardoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EUSIPCO</title>
				<meeting>EUSIPCO</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="776" to="779" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Continuous latent variable models for dimensionality reduction and sequential data reconstruction</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Carreira-Perpinan</surname></persName>
		</author>
		<author>
			<persName><surname>Sheffield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Nucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1990">2001. 1990</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="340" to="347" />
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
	<note>Operational fault tolerance of CMAC networks</note>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Multitask learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="41" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">The dynamics of discrete-time computation, with application to recurrent neural networks and finite state machine extraction</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Casey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1135" to="1178" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">A fast stochastic error-descent algorithm for supervised learning and optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cauwenberghs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Lippman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">244</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">On the length of programs for computing finite binary sequences</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Kaufmann. Chaitin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="547" to="569" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Incremental training of first order recurrent neural networks to predict a context-sensitive language</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Chalup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Blair</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="955" to="972" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">High performance convolutional neural networks for document processing</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chellapilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Simard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International workshop on Frontiers in handwriting recognition</title>
				<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Learning speaker-specific characteristics with a deep neural architecture</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Salman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1744" to="1756" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<monogr>
		<title level="m" type="main">Foundations and advances in deep learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
		<respStmt>
			<orgName>Aalto University School of Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Tikhonov-type regularization for restricted Boltzmann machines</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ilin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. conf. on artificial neural networks</title>
				<imprint>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Enhanced gradient for training restricted Boltzmann machines</title>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ilin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="805" to="831" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<monogr>
		<title/>
		<author>
			<persName><surname>Processing</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="287" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Transformation of shape information in the ventral pathway</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Brincat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pasupathy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Neurobiology</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="140" to="147" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Recurrent neural networks and robust time series prediction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Atlas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="240" to="254" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">The complexity of theorem-proving procedures</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd annual ACM symposium on the theory of computing</title>
				<meeting>the 3rd annual ACM symposium on the theory of computing<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1971">1971</date>
			<biblScope unit="page" from="151" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">A representation for the adaptive generation of simple sequential programs</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Cramer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of an international conference on genetic algorithms and their applications</title>
				<editor>
			<persName><forename type="first">J</forename><surname>Grefenstette</surname></persName>
		</editor>
		<meeting>an international conference on genetic algorithms and their applications<address><addrLine>Hillsdale, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<date type="published" when="1985">1985</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie-Mellon University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Smoothing noisy data with spline functions: estimating the correct degree of smoothing by the method of generalized crossvalidation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wahba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numerische Mathematik</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="377" to="403" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Intrinsically motivated evolutionary search for vision-based reinforcement learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cuccu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Luciw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gomez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 IEEE conference on development and learning and epigenetic robotics IEEE-ICDL-EPIROB</title>
				<meeting>the 2011 IEEE conference on development and learning and epigenetic robotics IEEE-ICDL-EPIROB</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Improving deep neural networks for LVCSR using rectified linear units and dropout</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International conference on acoustics, speech and signal processing</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="8609" to="8613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Acero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="42" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">A novel generative encoding for exploiting neural network sensor and output geometry</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>D'ambrosio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on genetic and evolutionary computation</title>
				<meeting>the conference on genetic and evolutionary computation</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="974" to="981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Locality-sensitive hashing scheme based on p-stable distributions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Datar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Immorlica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Indyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Mirrokni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th annual symposium on computational geometry</title>
				<meeting>the 20th annual symposium on computational geometry</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="253" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">Feudal reinforcement learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Lippman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Varieties of Helmholtz machine</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1385" to="1403" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">The Helmholtz machine</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="889" to="904" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Competition and multiple cause models</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="565" to="579" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Non-linear feature extraction by redundancy reduction in an unsupervised stochastic neural network</title>
		<author>
			<persName><forename type="first">G</forename><surname>Deco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Parra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="683" to="691" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">Neurodynamics of biased competition and cooperation for attention: a model with spiking neurons</title>
		<author>
			<persName><forename type="first">G</forename><surname>Deco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Rolls</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="295" to="313" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F G</forename><surname>De Freitas</surname></persName>
		</author>
		<title level="m">Bayesian methods for neural networks</title>
				<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>University of Cambridge</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">Explanation-based learning: an alternative view</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dejong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="145" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">Non-linear dimensionality reduction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Demers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cottrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Cowan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">Stimulus-selective properties of inferior temporal neurons in the macaque</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Desimone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Albright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bruce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society B</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2051" to="2062" />
			<date type="published" when="1977">1977. 2014. 1984</date>
			<publisher>NOW Publishers</publisher>
		</imprint>
	</monogr>
	<note>The Journal of Neuroscience</note>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">The loading problem for pyramidal neural networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>De Souto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C P D</forename><surname>Souto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R D</forename><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronic Journal on Mathematics of Computation</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">Spatial frequency selectivity of cells in macaque visual cortex</title>
		<author>
			<persName><forename type="first">De</forename><surname>Valois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Albrecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Thorell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="545" to="559" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">Logic program synthesis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Deville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Logic Programming</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="321" to="350" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">A theory for neural networks with time delays</title>
		<author>
			<persName><forename type="first">B</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Principe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Lippmann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="162" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">How does the brain solve visual object recognition?</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Dicarlo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zoccolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Rust</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="415" to="434" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title level="a" type="main">The seeing passenger car &apos;VaMoRs-P&apos;</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Dickmanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Behringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dickmanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hildebrandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maurer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Thomanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. int. symp. on intelligent vehicles</title>
				<meeting>int. symp. on intelligent vehicles</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="68" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">Der genetische algorithmus: eine implementierung in prolog</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dickmanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Winklhofer</surname></persName>
		</author>
		<ptr target="http://www.idsia.ch/~juergen/geneticprogramming.html" />
	</analytic>
	<monogr>
		<title level="j">Tech. Univ. Munich</title>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report. Inst. of Informatics</note>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Ensemble methods in machine learning</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multiple classifier systems</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000">2000a</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main">Hierarchical reinforcement learning with the MAXQ value function decomposition</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="227" to="303" />
			<date type="published" when="2000">2000b</date>
			<publisher>JAIR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">Deep architectures for protein contact map prediction</title>
		<author>
			<persName><forename type="first">P</forename><surname>Di Lena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nagata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2449" to="2457" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">Automated network design-the frequencydomain case</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Director</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Rohrer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Circuit Theory, CT</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="330" to="337" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">The growing hierarchical selforganizing map</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dittenbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Merkl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rauber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE-INNS-ENNS International joint conference on neural networks</title>
				<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">6015</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<monogr>
		<title level="m" type="main">DeCAF: a deep convolutional activation feature for generic visual recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1310.1531</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv Preprint</note>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title level="a" type="main">Multiple model-based reinforcement learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dorffner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Doya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Samejima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ichi Katagiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kawato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural network world</title>
				<imprint>
			<date type="published" when="1996">1996. 2002</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1347" to="1369" />
		</imprint>
	</monogr>
	<note>Neural networks for time series processing</note>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">The numerical solution of variational problems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Dreyfus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="45" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b177">
	<analytic>
		<title level="a" type="main">The computational solution of optimal control problems with time lag</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Dreyfus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="383" to="385" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main">FUfighters small size 2004, team description</title>
		<author>
			<persName><forename type="first">A</forename><surname>Egorova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gloye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Göktekin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Luft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rojas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RoboCup 2004 symposium: papers and team description papers</title>
				<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>CD edition</note>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">Free-energy based reinforcement learning for vision-based navigation with high-dimensional sensory inputs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Elfwing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Otsuka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Uchibe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Doya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural information processing. theory and algorithms (ICONIP)</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="215" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<monogr>
		<title level="m" type="main">How to build a brain: a neural architecture for biological cognition</title>
		<author>
			<persName><forename type="first">C</forename><surname>Eliasmith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b182">
	<analytic>
		<title level="a" type="main">A large-scale model of the functioning brain</title>
		<author>
			<persName><forename type="first">C</forename><surname>Eliasmith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bekolay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dewolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">338</biblScope>
			<biblScope unit="issue">6111</biblScope>
			<biblScope unit="page" from="1202" to="1205" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b183">
	<analytic>
		<title level="a" type="main">Finding structure in time</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="211" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b184">
	<analytic>
		<title level="a" type="main">Why does unsupervised pre-training help deep learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="625" to="660" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b185">
	<analytic>
		<title level="a" type="main">How to solve classification and regression problems on high-dimensional data with a supervised extension of slow feature analysis</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Escalante-B</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wiskott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="3683" to="3719" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<monogr>
		<title level="m" type="main">Spline smoothing and nonparametric regression</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Eubank</surname></persName>
		</author>
		<editor>S. Farlow</editor>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Marcel Dekker</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>Self-organizing methods in modeling</note>
</biblStruct>

<biblStruct xml:id="b187">
	<analytic>
		<title level="a" type="main">Real-life voice activity detection with LSTM recurrent neural networks and an application to Hollywood movies</title>
		<author>
			<persName><forename type="first">L</forename><surname>Euler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Eyben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Weninger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Squartini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schuller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 38th IEEE international conference on acoustics, speech, and signal processing</title>
				<meeting>38th IEEE international conference on acoustics, speech, and signal processing</meeting>
		<imprint>
			<date type="published" when="1744">1744. 2013</date>
			<biblScope unit="page" from="483" to="487" />
		</imprint>
	</monogr>
	<note>Methodus inveniendi</note>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<title level="a" type="main">Neural network hardware</title>
		<author>
			<persName><forename type="first">F</forename><surname>Faggin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International joint conference on neural networks</title>
				<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">153</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<monogr>
		<title level="m" type="main">An empirical study of learning speed in back-propagation networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Fahlman</surname></persName>
		</author>
		<idno>CMU-CS-88-162</idno>
		<imprint>
			<date type="published" when="1988">1988</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie-Mellon Univ.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b190">
	<analytic>
		<title level="a" type="main">The recurrent cascade-correlation learning algorithm</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Fahlman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Lippmann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="190" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b191">
	<analytic>
		<title level="a" type="main">A simple Hebbian/anti-Hebbian network learns the sparse, independent components of natural images</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Falconbridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Stamps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Badcock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="415" to="429" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b192">
	<analytic>
		<title level="a" type="main">TTS synthesis with bidirectional LSTM based recurrent neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">K</forename><surname>Soong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
				<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b193">
	<analytic>
		<title level="a" type="main">Learning hierarchical features for scene labeling</title>
		<author>
			<persName><forename type="first">C</forename><surname>Farabet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Couprie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Najman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1915" to="1929" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b194">
	<analytic>
		<title level="a" type="main">Simple and conditioned adaptive behavior from Kalman filter trained recurrent networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Farlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Feldkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Prokhorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Eagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Self-organizing methods in modeling: GMDH type algorithms</title>
				<editor>
			<persName><surname>Springer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Feldkamp</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Prokhorov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Feldkamp</surname></persName>
		</editor>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="1984">1984. 1998. 2003</date>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="683" to="689" />
		</imprint>
	</monogr>
	<note>Enhanced multistream Kalman filter training for recurrent networks</note>
</biblStruct>

<biblStruct xml:id="b195">
	<analytic>
		<title level="a" type="main">A signal processing framework based on dynamic neural networks with application to problems in adaptation, filtering, and classification</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Feldkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">V</forename><surname>Puskorius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2259" to="2277" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b196">
	<analytic>
		<title level="a" type="main">Distributed hierarchical processing in the primate cerebral cortex</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Felleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Van Essen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b197">
	<analytic>
		<title level="a" type="main">An application of recurrent neural networks to discriminative keyword spotting</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICANN</title>
				<meeting>ICANN</meeting>
		<imprint>
			<date type="published" when="2007">2007a</date>
			<biblScope unit="page" from="220" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b198">
	<analytic>
		<title level="a" type="main">Sequence labelling in structured domains with hierarchical recurrent neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international joint conference on artificial intelligence</title>
				<meeting>the 20th international joint conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2007">2007b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b199">
	<analytic>
		<title level="a" type="main">Prosody contour prediction with long short-term memory, bi-directional, deep recurrent neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rendel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ramabhadran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hoory</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
				<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b200">
	<analytic>
		<title level="a" type="main">Relations between the statistics of natural images and the response properties of cortical cells</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Optical Society of America</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2379" to="2394" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b201">
	<analytic>
		<title level="a" type="main">What is the goal of sensory coding?</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="559" to="601" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b202">
	<analytic>
		<title level="a" type="main">Realizing biological spiking network models in a configurable wafer-scale hardware system</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fieres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schemmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Meier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International joint conference on neural networks</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="969" to="976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b203">
	<analytic>
		<title level="a" type="main">The hierarchical hidden Markov model: analysis and applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="41" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b204">
	<analytic>
		<title level="a" type="main">Training restricted Boltzmann machines: an introduction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="25" to="39" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b205">
	<analytic>
		<title level="a" type="main">Impulses and physiological states in theoretical models of nerve membrane</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fitzhugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biophysical Journal</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="445" to="466" />
			<date type="published" when="1961">1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b206">
	<analytic>
		<title level="a" type="main">A rapidly convergent descent method for minimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Powell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Computer Journal</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="163" to="168" />
			<date type="published" when="1963">1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b207">
	<analytic>
		<title level="a" type="main">Evolution of spiking neural controllers for autonomous vision-based robots</title>
		<author>
			<persName><forename type="first">D</forename><surname>Floreano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mattiussi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary robotics. From intelligent robotics to artificial life</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="38" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b208">
	<analytic>
		<title level="a" type="main">Evolving neural networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Fogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Fogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Porto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="487" to="493" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b209">
	<monogr>
		<title level="m" type="main">Artificial intelligence through simulated evolution</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Walsh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966">1966</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b210">
	<analytic>
		<title level="a" type="main">Forming sparse representations by local anti-Hebbian learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Földiák</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="165" to="170" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b211">
	<analytic>
		<title level="a" type="main">RNN-based learning of compact maps for efficient robot localization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Földiák</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Förster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">15th European symposium on artificial neural networks</title>
				<editor>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Arbib</surname></persName>
		</editor>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="1995">1995. 2007</date>
			<biblScope unit="page" from="537" to="542" />
		</imprint>
	</monogr>
	<note>The handbook of brain theory and neural networks</note>
</biblStruct>

<biblStruct xml:id="b212">
	<analytic>
		<title level="a" type="main">Slowness and sparseness lead to place, head-direction, and spatial-view cells</title>
		<author>
			<persName><forename type="first">M</forename><surname>Franzius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sprekeler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wiskott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Springer series in statistics</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2007. 2001</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>The elements of statistical learning</note>
</biblStruct>

<biblStruct xml:id="b213">
	<analytic>
		<title level="a" type="main">Long-short term memory neural networks language modeling for handwriting recognition</title>
		<author>
			<persName><forename type="first">V</forename><surname>Frinken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zamora-Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Espana-Boquera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Castro-Bleda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bunke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 21st International conference on pattern recognition</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="701" to="704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b214">
	<analytic>
		<title level="a" type="main">A growing neural gas network learns topologies</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fritzke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<editor>
			<persName><forename type="first">G</forename><surname>Tesauro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Leen</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="625" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b215">
	<monogr>
		<title level="m" type="main">Syntactic pattern recognition and applications</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Fu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977">1977</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b216">
	<analytic>
		<title level="a" type="main">Phoneme boundary estimation using bidirectional recurrent neural networks and its applications</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fukada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sagisaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Systems and Computers in Japan</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="20" to="30" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b217">
	<analytic>
		<title level="a" type="main">Neural network model for a mechanism of pattern recognition unaffected by shift in position-Neocognitron</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fukushima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the IECE</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="658" to="665" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b218">
	<analytic>
		<title level="a" type="main">Neocognitron: A self-organizing neural network for a mechanism of pattern recognition unaffected by shift in position</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fukushima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="193" to="202" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b219">
	<analytic>
		<title level="a" type="main">Increasing robustness against background noise: visual pattern recognition by a neocognitron</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fukushima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="767" to="778" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b220">
	<analytic>
		<title level="a" type="main">Artificial vision by multi-layered neural networks: neocognitron and its advances</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fukushima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="103" to="119" />
			<date type="published" when="2013">2013a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b221">
	<analytic>
		<title level="a" type="main">Training multi-layered neural network neocognitron</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fukushima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="18" to="31" />
			<date type="published" when="2013">2013b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b222">
	<analytic>
		<title level="a" type="main">Theory of communication. Part 1: the analysis of information</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gabor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Institution of Radio and Communication Engineering</title>
		<imprint>
			<biblScope unit="volume">III</biblScope>
			<biblScope unit="issue">26</biblScope>
			<biblScope unit="page" from="429" to="441" />
			<date type="published" when="1946">1946</date>
		</imprint>
	</monogr>
	<note>Electrical Engineers-Part</note>
</biblStruct>

<biblStruct xml:id="b223">
	<analytic>
		<title level="a" type="main">Connectionist expert systems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Gallant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="152" to="169" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b224">
	<monogr>
		<title level="m" type="main">Theoria combinationis observationum erroribus minimis obnoxiae (Theory of the combination of observations least subject to error)</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Gauss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1809">1809</date>
		</imprint>
	</monogr>
	<note>Theoria motus corporum coelestium in sectionibus conicis solem ambientium. Gauss, C. F. (1821)</note>
</biblStruct>

<biblStruct xml:id="b225">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Hang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<title level="m">Stable adaptive neural network control</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b226">
	<analytic>
		<title level="a" type="main">Robust speech recognition using long short-term memory recurrent neural networks for hybrid acoustic modelling</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Weninger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rigoll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. interspeech</title>
				<meeting>interspeech</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b227">
	<analytic>
		<title level="a" type="main">Neural networks and the bias/variance dilemma</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bienenstock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Doursat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="58" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b228">
	<analytic>
		<title level="a" type="main">Recurrent nets that time and count</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE-INNS-ENNS international joint conference on neural networks</title>
				<meeting>the IEEE-INNS-ENNS international joint conference on neural networks</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2000">2000. 2000</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="189" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b229">
	<analytic>
		<title level="a" type="main">LSTM recurrent networks learn simple context free and context sensitive languages</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1333" to="1340" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b230">
	<analytic>
		<title level="a" type="main">Learning to forget: continual prediction with LSTM</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cummins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2451" to="2471" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b231">
	<analytic>
		<title level="a" type="main">Learning precise timing with LSTM recurrent networks</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Schraudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="115" to="143" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b232">
	<analytic>
		<title level="a" type="main">Associative memory in a network of spiking neurons</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gerstner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Kistler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gerstner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Van Hemmen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Network: Computation in Neural Systems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="164" />
			<date type="published" when="1992">2002. 1992</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
	<note>Spiking neuron models</note>
</biblStruct>

<biblStruct xml:id="b233">
	<analytic>
		<title level="a" type="main">Hierarchical policy gradient algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ghavamzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahadevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twentieth conference on machine learning</title>
				<meeting>the twentieth conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="226" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b234">
	<analytic>
		<title level="a" type="main">A learning algorithm for analog fully recurrent neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gherrity</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/INNS International joint conference on neural networks</title>
				<meeting><address><addrLine>San Diego</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="643" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b235">
	<monogr>
		<title level="m" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<idno>arxiv.org/abs/1311.2524</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>UC Berkeley and ICSI</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b236">
	<analytic>
		<title level="a" type="main">Sequential constant size compressor for reinforcement learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gisslen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Luciw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Graziano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. fourth conference on artificial general intelligence</title>
				<meeting>fourth conference on artificial general intelligence</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b237">
	<analytic>
		<title level="a" type="main">A novel approach for the implementation of large scale spiking neural networks on FPGA hardware</title>
		<author>
			<persName><forename type="first">A</forename><surname>Giusti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Ciresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mcginnity</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Maguire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Belatreche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational intelligence and bioinspired systems</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2013. 2005</date>
			<biblScope unit="page" from="552" to="563" />
		</imprint>
	</monogr>
	<note>Proc. ICIP. Glackin,</note>
</biblStruct>

<biblStruct xml:id="b238">
	<analytic>
		<title level="a" type="main">Exponential natural evolution strategies</title>
		<author>
			<persName><forename type="first">T</forename><surname>Glasmachers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the genetic and evolutionary computation conference</title>
				<meeting>the genetic and evolutionary computation conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="393" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b239">
	<analytic>
		<title level="a" type="main">Deep sparse rectifier networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In AISTATS</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="315" to="323" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b240">
	<monogr>
		<title level="m" type="main">Reinforcing the driving quality of soccer playing robots by anticipation. IT-Information Technology</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gloye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wiesel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tenchio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Simon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page">47</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b241">
	<monogr>
		<title level="m" type="main">Über formal unentscheidbare Sätze der Principia Mathematica und verwandter Systeme I. Monatshefte für Mathematik und Physik</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gödel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1931">1931</date>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="173" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b242">
	<monogr>
		<title level="m" type="main">Genetic algorithms in search, optimization and machine learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b243">
	<analytic>
		<title level="a" type="main">A family of variable-metric methods derived by variational means</title>
		<author>
			<persName><forename type="first">D</forename><surname>Goldfarb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">109</biblScope>
			<biblScope unit="page" from="23" to="26" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b244">
	<analytic>
		<title level="a" type="main">Generalized cross-validation as a method for choosing a good ridge parameter</title>
		<author>
			<persName><forename type="first">G</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Heath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wahba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="215" to="224" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b245">
	<monogr>
		<title level="m" type="main">Robust nonlinear control through neuroevolution</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Gomez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Sciences, University of Texas at Austin</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b246">
	<analytic>
		<title level="a" type="main">Active guidance for a finless rocket using neuroevolution</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GECCO</title>
				<meeting>GECCO</meeting>
		<imprint>
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b247">
	<analytic>
		<title level="a" type="main">Co-evolving recurrent neurons learn deep memory POMDPs</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2005 conference on genetic and evolutionary computation</title>
				<meeting>of the 2005 conference on genetic and evolutionary computation<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b248">
	<analytic>
		<title level="a" type="main">Accelerated neural evolution through cooperatively coevolved synapses</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="937" to="965" />
			<date type="published" when="2008-05">2008. May</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b249">
	<analytic>
		<title level="a" type="main">Neural network control for a closed-loop system using feedback-error-learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Gomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kawato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="933" to="946" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b250">
	<analytic>
		<title level="a" type="main">Automatic language identification using long short-term memory recurrent neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gonzalez-Dominguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lopez-Moreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gonzalez-Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Moreno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
				<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b251">
	<monogr>
		<title level="m" type="main">Multi-digit number recognition from street view imagery using deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bulatov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ibarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arnoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6082v4</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv Preprint</note>
</biblStruct>

<biblStruct xml:id="b252">
	<analytic>
		<title level="a" type="main">Spike-and-slab sparse coding for unsupervised feature discovery</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th international conference on machine learning</title>
				<meeting>the 29th international conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2011">2011. 2012</date>
		</imprint>
	</monogr>
	<note>NIPS Workshop on challenges in learning hierarchical models</note>
</biblStruct>

<biblStruct xml:id="b253">
	<analytic>
		<title level="a" type="main">An empirical investigation of catastrophic forgetting in gradient-based neural</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">networks.TR.arXiv:1312.6211v2</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<date type="published" when="2013">2014. 2013</date>
		</imprint>
	</monogr>
	<note>Maxout networks</note>
</biblStruct>

<biblStruct xml:id="b254">
	<analytic>
		<title level="a" type="main">Practical variational inference for neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2348" to="2356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b255">
	<analytic>
		<title level="a" type="main">Isolated digit recognition with LSTM recurrent networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Beringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First international workshop on biologically inspired approaches to advanced information technology</title>
				<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b256">
	<analytic>
		<title level="a" type="main">Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural nets</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML&apos;06: Proceedings of the 23rd international conference on machine learning</title>
				<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="369" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b257">
	<analytic>
		<title level="a" type="main">Unconstrained on-line handwriting recognition with recurrent neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liwicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bunke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">J</forename><surname>Platt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">S</forename><surname>Roweis</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="577" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b258">
	<analytic>
		<title level="a" type="main">Towards end-to-end speech recognition with recurrent neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 31st International conference on machine learning</title>
				<meeting>31st International conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1764" to="1772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b259">
	<analytic>
		<title level="a" type="main">A novel connectionist system for improved unconstrained handwriting recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liwicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bertolami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bunke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b260">
	<analytic>
		<title level="a" type="main">Speech recognition with deep recurrent neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-R</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International conference on acoustics, speech and signal processing</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="6645" to="6649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b261">
	<analytic>
		<title level="a" type="main">Framewise phoneme classification with bidirectional LSTM and other neural network architectures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="602" to="610" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b262">
	<analytic>
		<title level="a" type="main">Offline handwriting recognition with multidimensional recurrent neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="545" to="552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b263">
	<monogr>
		<title level="m" type="main">The intelligent movement machine: an ethological perspective on the primate motor system</title>
		<author>
			<persName><forename type="first">M</forename><surname>Graziano</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b264">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Griewank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Documenta Mathematica-Extra</title>
		<imprint>
			<biblScope unit="volume">ISMP</biblScope>
			<biblScope unit="page" from="389" to="400" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b265">
	<analytic>
		<title level="a" type="main">A survey of actor-critic reinforcement learning: standard and natural policy gradients</title>
		<author>
			<persName><forename type="first">I</forename><surname>Grondman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Busoniu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A D</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Babuska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics Part C: Applications and Reviews</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1291" to="1307" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b266">
	<analytic>
		<title level="a" type="main">Some networks that can learn, remember, and reproduce any number of complicated space-time patterns</title>
		<author>
			<persName><forename type="first">S</forename><surname>Grossberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">I. Journal of Mathematics and Mechanics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="53" to="91" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b267">
	<analytic>
		<title level="a" type="main">Adaptive pattern classification and universal recoding, 1: parallel development and coding of neural feature detectors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Grossberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="187" to="202" />
			<date type="published" when="1976">1976a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b268">
	<analytic>
		<title level="a" type="main">Adaptive pattern classification and universal recoding, 2: feedback, expectation, olfaction, and illusions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Grossberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="1976">1976b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b269">
	<monogr>
		<title level="m" type="main">A comparison between cellular encoding and direct encoding for genetic neural networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gruau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whitley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pyeatt</surname></persName>
		</author>
		<idno>NC-TR- 96-048</idno>
		<imprint>
			<date type="published" when="1996">1996. NeuroCOLT 8556</date>
		</imprint>
		<respStmt>
			<orgName>ESPRIT Working Group in Neural and Computational Learning</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">NeuroCOLT Technical report</note>
</biblStruct>

<biblStruct xml:id="b270">
	<monogr>
		<title level="m" type="main">Advances in minimum description length: theory and applications</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Grünwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Myung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Pitt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b271">
	<analytic>
		<title level="a" type="main">Multi-dimensional deep memory atari-go players for parameter exploring policy gradients</title>
		<author>
			<persName><forename type="first">M</forename><surname>Grüttner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sehnke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on artificial neural networks ICANN</title>
				<meeting>the international conference on artificial neural networks ICANN</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="114" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b272">
	<analytic>
		<title level="a" type="main">Deep learning for real-time Atari game play using offline Monte-Carlo tree search planning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b273">
	<analytic>
		<title level="a" type="main">Structural risk minimization for character recognition</title>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Solla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Lippman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="471" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b274">
	<monogr>
		<title level="m" type="main">Mémoire sur le problème d&apos;analyse relatif à l&apos;équilibre des plaques élastiques encastrées. Mémoires présentés par divers savants à l&apos;Académie des sciences de l&apos;Institut de France: Éxtrait</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hadamard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1908">1908</date>
		</imprint>
	</monogr>
	<note>Imprimerie nationale</note>
</biblStruct>

<biblStruct xml:id="b275">
	<analytic>
		<title level="a" type="main">Evolving spiking neural network controllers for autonomous robots</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">;</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pounds-Cornish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Colley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Callaghan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. computer vision and pattern recognition conference</title>
				<meeting>computer vision and pattern recognition conference<address><addrLine>Hagras, H</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2004">2006. 2004</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="4620" to="4626" />
		</imprint>
	</monogr>
	<note>IEEE International conference on robotics and automation</note>
</biblStruct>

<biblStruct xml:id="b276">
	<analytic>
		<title level="a" type="main">Reducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation (CMA-ES)</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Koumoutsakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b277">
	<analytic>
		<title level="a" type="main">Completely derandomized self-adaptation in evolution strategies</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ostermeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="195" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b278">
	<analytic>
		<title level="a" type="main">A stochastic version of the delta rule</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D: Nonlinear Phenomena</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="265" to="272" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b279">
	<analytic>
		<title level="a" type="main">Comparing biases for minimal network construction with back-propagation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y</forename><surname>Pratt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Murre</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">M</forename></persName>
		</editor>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1989">1989. 1994</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="985" to="1004" />
		</imprint>
	</monogr>
	<note>Design and evolution of modular neural network architectures</note>
</biblStruct>

<biblStruct xml:id="b280">
	<analytic>
		<title level="a" type="main">Improving model accuracy using optimal linear combinations of trained neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hashem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schmeiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="792" to="794" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b281">
	<analytic>
		<title level="a" type="main">Second order derivatives for network pruning: optimal brain surgeon</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hassibi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Stork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Lippman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="164" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b282">
	<monogr>
		<title/>
		<author>
			<persName><surname>Kaufmann</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b283">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Tibshirani</surname></persName>
		</author>
		<title level="m">Monographs on statisics and applied probability</title>
				<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">43</biblScope>
		</imprint>
	</monogr>
	<note>Generalized additive models</note>
</biblStruct>

<biblStruct xml:id="b284">
	<monogr>
		<title level="m" type="main">Springer series in statistics. The elements of statistical learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b285">
	<monogr>
		<title level="m" type="main">Hierarchical temporal memory-concepts, theory, and terminology</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>George</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Numenta Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b286">
	<monogr>
		<title level="m" type="main">Kalman filtering and neural networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Haykin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1949">2001. 1949</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>The organization of behavior</note>
</biblStruct>

<biblStruct xml:id="b287">
	<analytic>
		<title level="a" type="main">Theory of the backpropagation neural network</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hecht-Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International joint conference on neural networks</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="593" to="605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b288">
	<monogr>
		<title level="m" type="main">Overview of neural hardware. In Neurocomputers for brainstyle processing. Design, implementation and application</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Heemskerk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b289">
	<analytic>
		<title level="a" type="main">Actor-critic reinforcement learning with energy-based policies</title>
		<author>
			<persName><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European workshop on reinforcement learning</title>
				<meeting>European workshop on reinforcement learning</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="43" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b290">
	<analytic>
		<title level="a" type="main">Neuroevolution strategies for episodic reinforcement learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Heidrich-Meisner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Algorithms</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="152" to="168" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b291">
	<analytic>
		<title level="a" type="main">A hierarchical unsupervised growing neural network for clustering gene expression patterns</title>
		<author>
			<persName><forename type="first">J</forename><surname>Herrero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Valencia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dopazo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="126" to="136" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b292">
	<monogr>
		<title level="m" type="main">Introduction to the theory of neural computation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Palmer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Redwood City</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b293">
	<analytic>
		<title level="a" type="main">Methods of conjugate gradients for solving linear systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Hestenes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Stiefel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Research of the National Bureau of Standards</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="409" to="436" />
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b294">
	<analytic>
		<title level="a" type="main">Hierarchical recurrent neural networks for long-term dependencies</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Hihi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Hasselmo</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="493" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b295">
	<analytic>
		<title level="a" type="main">Connectionist learning procedures</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="185" to="234" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b296">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1771" to="1800" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b297">
	<analytic>
		<title level="a" type="main">The wake-sleep algorithm for unsupervised neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">268</biblScope>
			<biblScope unit="page" from="1158" to="1160" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b298">
	<analytic>
		<title level="a" type="main">Deep neural networks for acoustic modeling in speech recognition: the shared views of four research groups</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="97" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b299">
	<analytic>
		<title level="a" type="main">Generative models for discovering sparse distributed representations</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B</title>
		<imprint>
			<biblScope unit="volume">352</biblScope>
			<biblScope unit="page" from="1177" to="1190" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b300">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b301">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b302">
	<analytic>
		<title level="a" type="main">Learning and relearning in Boltzmann machines</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel distributed processing</title>
				<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="282" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b303">
	<monogr>
		<title level="m" type="main">Improving neural networks by preventing co-adaptation of feature detectors</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1207.0580</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b304">
	<analytic>
		<title level="a" type="main">Keeping neural networks simple</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Van Camp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on artificial neural networks</title>
				<meeting>the international conference on artificial neural networks<address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b305">
	<monogr>
		<title level="m" type="main">Untersuchungen zu dynamischen neuronalen Netzen (Diploma thesis)</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<editor>J. Schmidhuber</editor>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
		<respStmt>
			<orgName>Institut für Informatik, Lehrstuhl Prof. Brauer, Technische Universität München</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b306">
	<analytic>
		<title level="a" type="main">Gradient flow in recurrent nets: the difficulty of learning long-term dependencies</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Obermayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spatiotemporal models in biological and artificial systems</title>
				<editor>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Silva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Principe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Almeida</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam, Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press. Hochreiter, S., &amp; Schmidhuber</publisher>
			<date type="published" when="1996">2001. 2005. 1996. 1997a</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1" to="42" />
		</imprint>
	</monogr>
	<note>Neural Computation</note>
</biblStruct>

<biblStruct xml:id="b307">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno>on TR FKI-207-95</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1995">1997b. 1995</date>
		</imprint>
	</monogr>
	<note>TUM</note>
</biblStruct>

<biblStruct xml:id="b308">
	<analytic>
		<title level="a" type="main">Feature extraction through LOCOCODE</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="679" to="714" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b309">
	<analytic>
		<title level="a" type="main">Learning to learn using gradient descent</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Younger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Conwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. intl. conf. on artificial neural networks</title>
		<title level="s">Lecture notes on comp. sci.</title>
		<meeting>intl. conf. on artificial neural networks<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">2130</biblScope>
			<biblScope unit="page" from="87" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b310">
	<analytic>
		<title level="a" type="main">A quantitative description of membrane current and its application to conduction and excitation in nerve</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Hodgkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Huxley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Physiology</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">500</biblScope>
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b311">
	<analytic>
		<title level="a" type="main">Emergence of complex computational structures from chaotic neural networks through rewardmodulated Hebbian learning</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Hoerzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Legenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="677" to="690" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b312">
	<monogr>
		<title level="m" type="main">On the theory of generalization and self-structuring in linearly weighted connectionist networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Holden</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
		<respStmt>
			<orgName>Cambridge University, Engineering Department</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b313">
	<monogr>
		<title level="m" type="main">Adaptation in natural and artificial systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Holland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>University of Michigan Press</publisher>
			<pubPlace>Ann Arbor</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b314">
	<analytic>
		<title level="a" type="main">A network of neuron-like units that learns to perceive by generation as well as reweighting of its links</title>
		<author>
			<persName><forename type="first">V</forename><surname>Honavar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Uhr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 1988 connectionist models summer school</title>
				<editor>
			<persName><forename type="first">D</forename><surname>Touretzky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">T</forename><surname>Sejnowski</surname></persName>
		</editor>
		<meeting>of the 1988 connectionist models summer school<address><addrLine>San Mateo</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufman</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="472" to="484" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b315">
	<analytic>
		<title level="a" type="main">Generative learning structures and processes for generalized connectionist networks</title>
		<author>
			<persName><forename type="first">V</forename><surname>Honavar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Uhr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="75" to="108" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b316">
	<analytic>
		<title level="a" type="main">Neural networks and physical systems with emergent collective computational abilities</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hopfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="2554" to="2558" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b317">
	<analytic>
		<title level="a" type="main">Multilayer feedforward networks are universal approximators</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hornik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stinchcombe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="359" to="366" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b318">
	<analytic>
		<title level="a" type="main">Receptive fields, binocular interaction, and functional architecture in the cat&apos;s visual cortex</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Hubel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wiesel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Physiology</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="page" from="106" to="154" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b319">
	<analytic>
		<title level="a" type="main">Receptive fields and functional architecture of monkey striate cortex</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Hubel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Wiesel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Physiology</title>
		<imprint>
			<biblScope unit="volume">195</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="215" to="243" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b320">
	<analytic>
		<title level="a" type="main">A method for construction of minimum-redundancy codes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Huffman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings IRE</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="1098" to="1101" />
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b321">
	<analytic>
		<title level="a" type="main">Fast readout of object identity from macaque inferior temporal cortex</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kreiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Dicarlo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="issue">5749</biblScope>
			<biblScope unit="page" from="863" to="866" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b322">
	<analytic>
		<title level="a" type="main">The fastest and shortest algorithm for all well-defined problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Foundations of Computer Science</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="20" to="61847" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>Schmidhuber&apos;s SNF grant</note>
</biblStruct>

<biblStruct xml:id="b323">
	<analytic>
		<title level="a" type="main">Universal artificial intelligence: sequential decisions based on algorithmic probability</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">On J. Schmidhuber&apos;s SNF grant</title>
		<imprint>
			<biblScope unit="page" from="20" to="61847" />
			<date type="published" when="2005">2005</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b324">
	<analytic>
		<title level="a" type="main">Sparse code shrinkage: denoising by maximum likelihood estimation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">M</forename><surname>Kearns</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Solla</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Cohn</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b325">
	<monogr>
		<title level="m" type="main">IPAL laboratory and TRIBVN company and pitie-salpetriere hospital and</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Karhunen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
		<ptr target="http://ipal.cnrs.fr/ICPR2012/" />
		<imprint>
			<date type="published" when="2001">2001. 2012. 2012</date>
			<publisher>John Wiley &amp; Sons. ICPR</publisher>
		</imprint>
		<respStmt>
			<orgName>CIALAB of Ohio State Univ</orgName>
		</respStmt>
	</monogr>
	<note>Contest on Mitosis Detection in Breast Cancer Histological Images</note>
</biblStruct>

<biblStruct xml:id="b326">
	<analytic>
		<title level="a" type="main">Neuroevolution for reinforcement learning using evolution strategies</title>
		<author>
			<persName><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Congress on evolutionary computation</title>
				<editor>
			<persName><forename type="first">R</forename><surname>Reynolds</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Abbass</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Tan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Mckay</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Essam</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Gedeon</surname></persName>
		</editor>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2588" to="2595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b327">
	<analytic>
		<title level="a" type="main">Empirical evaluation of the improved Rprop learning algorithm</title>
		<author>
			<persName><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hüsken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">C</biblScope>
			<biblScope unit="page" from="105" to="123" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b328">
	<analytic>
		<title level="a" type="main">Sequential GMDH algorithm and its application to river flow prediction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ikeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ochiai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sawaragi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="473" to="479" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b329">
	<analytic>
		<title level="a" type="main">Mode detection in online handwritten documents using BLSTM neural networks</title>
		<author>
			<persName><forename type="first">E</forename><surname>Indermuhle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Frinken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bunke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Frontiers in handwriting recognition (ICFHR), 2012 international conference on</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="302" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b330">
	<analytic>
		<title level="a" type="main">Keyword spotting in online handwritten documents containing text and non-text using BLSTM neural networks</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ieee. Indermuhle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Frinken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bunke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Document analysis and recognition (ICDAR), 2011 international conference on</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="73" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b331">
	<analytic>
		<title level="a" type="main">Neuromorphic silicon neuron circuits</title>
		<author>
			<persName><forename type="first">G</forename><surname>Indiveri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Linares-Barranco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Schaik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Etienne-Cummings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Delbruck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">73</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b332">
	<analytic>
		<title level="a" type="main">The group method of data handling-a rival of the method of stochastic approximation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Ivakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soviet Automatic Control</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="43" to="55" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b333">
	<analytic>
		<title level="a" type="main">Polynomial theory of complex systems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Ivakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="364" to="378" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b334">
	<monogr>
		<title level="m" type="main">The review of problems solvable by algorithms of the group method of data handling (GMDH)</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Ivakhnenko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="527" to="535" />
		</imprint>
	</monogr>
	<note>Pattern Recognition and Image Analysis/Raspoznavaniye Obrazov I Analiz Izobrazhenii</note>
</biblStruct>

<biblStruct xml:id="b335">
	<monogr>
		<title level="m" type="main">Cybernetic predicting devices</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Ivakhnenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">G</forename><surname>Lapa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1965">1965</date>
			<publisher>CCM Information Corporation</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b336">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Ivakhnenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">G</forename><surname>Lapa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Mcdonough</surname></persName>
		</author>
		<title level="m">Cybernetics and forecasting techniques</title>
				<meeting><address><addrLine>NY</addrLine></address></meeting>
		<imprint>
			<publisher>American Elsevier</publisher>
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b337">
	<analytic>
		<title level="a" type="main">Simple model of spiking neurons</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Izhikevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1569" to="1572" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b338">
	<analytic>
		<title level="a" type="main">Reinforcement learning algorithm for partially observable Markov decision problems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<editor>
			<persName><forename type="first">G</forename><surname>Tesauro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Leen</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="345" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b339">
	<analytic>
		<title level="a" type="main">VLSI implementation of electronic neural networks: and example in character recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jackel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Graf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE international conference on systems, man, and cybernetics</title>
				<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="320" to="322" />
		</imprint>
	</monogr>
	<note>IEEE</note>
</biblStruct>

<biblStruct xml:id="b340">
	<analytic>
		<title level="a" type="main">Genetic L-system programming</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lindenmayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rozenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lecture notes in computer science. Parallel problem solving from nature III</title>
				<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b341">
	<analytic>
		<title level="a" type="main">Increased rates of convergence through learning rate adaptation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="295" to="307" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b342">
	<monogr>
		<title level="m" type="main">The &apos;&apos;echo state&apos;&apos; approach to analysing and training recurrent neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jaeger</surname></persName>
		</author>
		<idno>148</idno>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>German National Research Center for Information Technology</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report GMD Report</note>
</biblStruct>

<biblStruct xml:id="b343">
	<analytic>
		<title level="a" type="main">Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">304</biblScope>
			<biblScope unit="page" from="78" to="80" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b344">
	<analytic>
		<title level="a" type="main">Delayed reinforcement learning with multiple time scale hierarchical backpropagated adaptive critics</title>
		<author>
			<persName><forename type="first">V</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc. Jameson</publisher>
			<date type="published" when="1991">2009. 1991</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="769" to="776" />
		</imprint>
	</monogr>
	<note>Neural networks for control</note>
</biblStruct>

<biblStruct xml:id="b345">
	<analytic>
		<title level="a" type="main">3D convolutional neural networks for human action recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="221" to="231" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b346">
	<analytic>
		<title level="a" type="main">Effects of noise on convergence and generalization in recurrent networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Horne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">G</forename><surname>Tesauro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Touretzky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Leen</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">649</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b347">
	<analytic>
		<title level="a" type="main">Modeling spiking neural networks on SpiNNaker</title>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lujan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Plana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Temple</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Furber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Science and Engineering</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="91" to="97" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b348">
	<analytic>
		<title level="a" type="main">Closed-loop learning of visual control policies</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Jodogne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Piater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="349" to="391" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b349">
	<analytic>
		<title level="a" type="main">An evaluation of the two-dimensional Gabor filter model of simple receptive fields in cat striate cortex</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1233" to="1258" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b350">
	<monogr>
		<title level="m" type="main">Serial order: a parallel distributed processing approach</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<idno>ICS report 8604</idno>
		<imprint>
			<date type="published" when="1986">1986</date>
			<pubPlace>San Diego</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Institute for Cognitive Science, University of California</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b351">
	<monogr>
		<title level="m" type="main">Supervised learning and systems with excess degrees of freedom</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<idno>COINS TR 88-27</idno>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Massachusetts Institute of Technology</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b352">
	<analytic>
		<title level="a" type="main">Serial order: a parallel distributed processing approach</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Psychology</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="471" to="495" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b353">
	<monogr>
		<title level="m" type="main">Supervised learning with a distal teacher</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
		<respStmt>
			<orgName>Center for Cog. Sci., Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>Occasional Paper #40</note>
</biblStruct>

<biblStruct xml:id="b354">
	<monogr>
		<title level="m" type="main">Graphical models: foundations of neural computation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b355">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Joseph</surname></persName>
		</author>
		<title level="m">Contributions to perceptron theory</title>
				<imprint>
			<date type="published" when="1961">1961</date>
		</imprint>
		<respStmt>
			<orgName>Cornell Univ</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b356">
	<analytic>
		<title level="a" type="main">A hybrid of genetic algorithm and particle swarm optimization for recurrent network design</title>
		<author>
			<persName><forename type="first">C.-F</forename><surname>Juang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="997" to="1006" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>Part B: Cybernetics</note>
</biblStruct>

<biblStruct xml:id="b357">
	<monogr>
		<title level="m" type="main">Neural network modeling and connectionism. Neural network design and the complexity of learning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Judd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b358">
	<analytic>
		<title level="a" type="main">Blind separation of sources, part I: an adaptive algorithm based on neuromimetic architecture</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jutten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Herault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b359">
	<monogr>
		<title level="m" type="main">Planning and acting in partially observable stochastic domains</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Kaelbling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Cassandra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<pubPlace>Providence RI</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Brown University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b360">
	<analytic>
		<title level="a" type="main">Reinforcement learning: A survey</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Kaelbling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of AI Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="237" to="285" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b361">
	<analytic>
		<title level="a" type="main">Data mining using surface and deep agents based on neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AMCIS 2010 proceedings</title>
				<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b362">
	<analytic>
		<title level="a" type="main">Computation in recurrent neural networks: from counters to iterated function systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kalinke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Australian joint conference on artificial intelligence</title>
				<editor>
			<persName><forename type="first">G</forename><surname>Antoniou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Slaney</surname></persName>
		</editor>
		<meeting>the 11th Australian joint conference on artificial intelligence<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">LNAI</biblScope>
		</imprint>
	</monogr>
	<note>Advanced topics in artificial intelligence</note>
</biblStruct>

<biblStruct xml:id="b363">
	<analytic>
		<title level="a" type="main">A new approach to linear filtering and prediction problems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kalman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Basic Engineering</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="35" to="45" />
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b364">
	<analytic>
		<title level="a" type="main">Generalizations of principal component analysis, optimization problems, and neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Karhunen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Joutsensalo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="549" to="562" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b365">
	<analytic>
		<title level="a" type="main">Large-scale video classification with convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Toderici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE conference on computer vision and pattern recognition</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b366">
	<analytic>
		<title level="a" type="main">Neucube: a spiking neural network architecture for mapping, learning and understanding of spatio-temporal brain data</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Kasabov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b367">
	<analytic>
		<title level="a" type="main">Gradient theory of optimal flight paths</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Kelley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ARS Journal</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="947" to="954" />
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b368">
	<analytic>
		<title level="a" type="main">Hebbian learning and spiking neurons</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kempter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gerstner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Van Hemmen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">4498</biblScope>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b369">
	<analytic>
		<title level="a" type="main">Robustness in multilayer perceptrons</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kerlirzin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vallet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="473" to="482" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b370">
	<analytic>
		<title level="a" type="main">Automatic feature learning for robust shadow detection</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bennamoun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sohel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Togneri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE conference on computer vision and pattern recognition</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b371">
	<analytic>
		<title level="a" type="main">Evolution of neural networks using Cartesian Genetic Programming</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE congress on evolutionary computation</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b372">
	<analytic>
		<title level="a" type="main">SpiNNaker: mapping neural networks onto a massively-parallel chip multiprocessor</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Plana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Painkras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International joint conference on neural networks</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="2849" to="2856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b373">
	<analytic>
		<title level="a" type="main">Reinforcement learning in POMDPs with function approximation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kimura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Miyazaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kobayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="152" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b374">
	<analytic>
		<title level="a" type="main">Reduction of the Hodgkin-Huxley equations to a single-variable threshold model</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Kistler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gerstner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Van Hemmen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1015" to="1045" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b375">
	<analytic>
		<title level="a" type="main">Designing neural networks using genetic algorithms with graph generation system</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kitano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Systems</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="461" to="476" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b376">
	<analytic>
		<title level="a" type="main">Emergence of dynamic memory traces in cortical microcircuit models through STDP</title>
		<author>
			<persName><forename type="first">S</forename><surname>Klampfl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">28</biblScope>
			<biblScope unit="page" from="11515" to="11529" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b377">
	<analytic>
		<title level="a" type="main">Unsupervised learning in LSTM recurrent neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Klapper-Rybicka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Schraudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. intl. conf. on artificial neural networks</title>
		<title level="s">Lecture Notes on Comp. Sci.</title>
		<meeting>intl. conf. on artificial neural networks<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">2130</biblScope>
			<biblScope unit="page" from="684" to="691" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b378">
	<analytic>
		<title level="a" type="main">Neuronal selectivities to complex object features in the ventral visual pathway of the macaque cerebral cortex</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kobatake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tanaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="856" to="867" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b379">
	<analytic>
		<title level="a" type="main">Policy gradient reinforcement learning for fast quadrupedal locomotion</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. ICRA&apos;04. 2004 IEEE international conference on</title>
				<meeting>ICRA&apos;04. 2004 IEEE international conference on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2619" to="2624" />
		</imprint>
	</monogr>
	<note>Robotics and automation</note>
</biblStruct>

<biblStruct xml:id="b380">
	<analytic>
		<title level="a" type="main">Correlation matrix memories</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kohonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="353" to="359" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b381">
	<analytic>
		<title level="a" type="main">Self-organized formation of topologically correct feature maps</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kohonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="69" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b382">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Kohonen</surname></persName>
		</author>
		<title level="m">Self-organization and associative memory</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
	<note>2nd ed</note>
</biblStruct>

<biblStruct xml:id="b383">
	<analytic>
		<title level="a" type="main">Self-organizing hierarchical feature maps</title>
		<author>
			<persName><forename type="first">P</forename><surname>Koikkalainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International joint conference on neural networks</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="279" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b384">
	<analytic>
		<title level="a" type="main">On the representation of continuous functions of several variables by superposition of continuous functions of one variable and addition</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Kolmogorov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Doklady Akademii Nauk SSSR</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="679" to="681" />
			<date type="published" when="1965">1965a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b385">
	<analytic>
		<title level="a" type="main">Three approaches to the quantitative definition of information</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Kolmogorov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Problems of Information Transmission</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="1965">1965b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b386">
	<analytic>
		<title level="a" type="main">Incremental slow feature analysis: Adaptive low-complexity slow feature updating from highdimensional input streams</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Kompella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Luciw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2994" to="3024" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b387">
	<analytic>
		<title level="a" type="main">GMDH neural network algorithm using the heuristic selforganization method and its application to the pattern identification problem</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kondo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th SICE annual conference</title>
				<meeting>the 37th SICE annual conference</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="1143" to="1148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b388">
	<analytic>
		<title level="a" type="main">Multi-layered GMDH-type neural network selfselecting optimum neural network architecture and its application to 3-dimensional medical image recognition of blood vessels</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kondo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ueno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Innovative Computing, Information and Control</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="175" to="187" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b389">
	<analytic>
		<title level="a" type="main">Modified GMDH method and models quality evaluation by visualization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kordík</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Náplava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Snorek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Genyk-Berezovskyj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Control Systems and Computers</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="68" to="75" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b390">
	<monogr>
		<title level="m" type="main">CBM (CAM-Brain Machine)-a hardware tool which evolves a neural net module in a fraction of a second and runs a million neuron artificial brain in real time</title>
		<author>
			<persName><forename type="first">M</forename><surname>Korkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>De Garis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hemmi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b391">
	<analytic>
		<title level="a" type="main">Unsupervised learning in noise</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kosko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="57" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b392">
	<analytic>
		<title level="a" type="main">Evolving large-scale neural networks for vision-based reinforcement learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Koutník</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cuccu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gomez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th annual conference on genetic and evolutionary computation</title>
				<editor>
			<persName><forename type="first">Acm</forename><surname>Koutník</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gomez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Schmidhuber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename></persName>
		</editor>
		<meeting>the 12th annual conference on genetic and evolutionary computation<address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2013. 2010</date>
			<biblScope unit="page" from="619" to="626" />
		</imprint>
	</monogr>
	<note>Proceedings of the genetic and evolutionary computation conference</note>
</biblStruct>

<biblStruct xml:id="b393">
	<analytic>
		<title level="a" type="main">A clockwork RNN</title>
		<author>
			<persName><forename type="first">J</forename><surname>Koutník</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1402.3511[cs.NE]</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31th international conference on machine learning</title>
				<meeting>the 31th international conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1845" to="1853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b394">
	<monogr>
		<title level="m" type="main">Genetic programming-on the programming of computers by means of natural selection</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Koza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b395">
	<analytic>
		<title level="a" type="main">Nonlinear principal component analysis using autoassociative neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kramer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIChE Journal</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="233" to="243" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b396">
	<analytic>
		<title level="a" type="main">Matching categorical object representations in inferior temporal cortex of man and monkey</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Kremer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Kolen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kriegeskorte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bodurka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Esteky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1126" to="1141" />
			<date type="published" when="2001">2001. 2008</date>
			<publisher>Wiley-IEEE Press</publisher>
		</imprint>
	</monogr>
	<note>Field guide to dynamical recurrent networks</note>
</biblStruct>

<biblStruct xml:id="b397">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b398">
	<analytic>
		<title level="a" type="main">A simple weight decay can improve generalization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Hertz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Lippman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="950" to="957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b399">
	<analytic>
		<title level="a" type="main">Deep hierarchies in the primate visual cortex: what can we learn for computer vision?</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kruger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Janssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kalkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lappe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Piater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1847" to="1871" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b400">
	<analytic>
		<title level="a" type="main">On information and sufficiency</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kullback</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Leibler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Annals of Mathematical Statistics</title>
				<imprint>
			<date type="published" when="1951">1951</date>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b401">
	<analytic>
		<title level="a" type="main">How to create a mind: the secret of human thought revealed</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kurzweil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Lagoudakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Parr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1107" to="1149" />
			<date type="published" when="2003">2012. 2003</date>
		</imprint>
	</monogr>
	<note>Least-squares policy iteration</note>
</biblStruct>

<biblStruct xml:id="b402">
	<analytic>
		<title level="a" type="main">Clustering properties of hierarchical self-organizing maps</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="261" to="272" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b403">
	<analytic>
		<title level="a" type="main">A time-delay neural network architecture for isolated word recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Waibel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="23" to="43" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b404">
	<analytic>
		<title level="a" type="main">Deep auto-encoder neural networks in reinforcement learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks, The 2010 international joint conference on</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b405">
	<analytic>
		<title level="a" type="main">A self-optimizing, nonsymmetrical neural net for content addressable memory and pattern recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lapedes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Farber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="247" to="259" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b406">
	<analytic>
		<title level="a" type="main">Mémoire sur la probabilité des causes par les évènements</title>
		<author>
			<persName><forename type="first">P</forename><surname>Laplace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mémoires de l&apos;Academie Royale des Sciences Presentés par Divers Savan</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="621" to="656" />
			<date type="published" when="1774">1774</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b407">
	<monogr>
		<title level="m" type="main">Estimation of distribution algorithms: a new tool for evolutionary computation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Larraanaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Lozano</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Norwell, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b408">
	<analytic>
		<title level="a" type="main">Building high-level features using large scale unsupervised learning</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of cognitiva 85</title>
				<meeting>cognitiva 85<address><addrLine>LeCun, Y</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1985">2012. 1985</date>
			<biblScope unit="page" from="599" to="604" />
		</imprint>
	</monogr>
	<note>Proc. ICML&apos;12</note>
</biblStruct>

<biblStruct xml:id="b409">
	<analytic>
		<title level="a" type="main">A theoretical framework for back-propagation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1988 connectionist models summer school</title>
				<editor>
			<persName><forename type="first">D</forename><surname>Touretzky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">T</forename><surname>Sejnowski</surname></persName>
		</editor>
		<meeting>the 1988 connectionist models summer school<address><addrLine>Pittsburgh, Pa</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="21" to="28" />
		</imprint>
		<respStmt>
			<orgName>CMU</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b410">
	<analytic>
		<title level="a" type="main">Back-propagation applied to handwritten zip code recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hubbard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="541" to="551" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b411">
	<analytic>
		<title level="a" type="main">Handwritten digit recognition with a back-propagation network</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hubbard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="396" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b412">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b413">
	<analytic>
		<title level="a" type="main">Optimal brain damage</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Solla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="598" to="605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b414">
	<analytic>
		<title level="a" type="main">Off-road obstacle avoidance through end-to-end learning</title>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cosatto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Flepp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2005">2006. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b415">
	<analytic>
		<title level="a" type="main">Automatic learning rate maximization by on-line estimation of the Hessian&apos;s eigenvectors</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pearlmutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<editor>
			<persName><forename type="first">S</forename><surname>Hanson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Cowan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</editor>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers</publisher>
			<date type="published" when="1992">1993. 1992</date>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b416">
	<monogr>
		<title level="m" type="main">Learning of context-free languages: a survey of the literature</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<idno>TR-12-96</idno>
		<imprint>
			<date type="published" when="1996">1996</date>
			<pubPlace>Cambridge, Massachusetts</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Center for Research in Computing Technology, Harvard University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b417">
	<analytic>
		<title level="a" type="main">Efficient sparse coding algorithms</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Battle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="801" to="808" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b418">
	<analytic>
		<title level="a" type="main">Sparse deep belief net model for visual area V2</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ekanadham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="873" to="880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b419">
	<analytic>
		<title level="a" type="main">Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th international conference on machine learning</title>
				<meeting>the 26th international conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="609" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b420">
	<analytic>
		<title level="a" type="main">A Gaussian potential function network with hierarchically self-organizing learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Kil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="207" to="224" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b421">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning for audio classification using convolutional deep belief networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Largman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
				<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1096" to="1104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b422">
	<analytic>
		<title level="a" type="main">Neural circuits for pattern recognition with small total wire length</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Legendre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Didot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Legenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">287</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="239" to="249" />
			<date type="published" when="1805">1805. 2002</date>
		</imprint>
	</monogr>
	<note>Nouvelles méthodes pour la détermination des orbites des cometes</note>
</biblStruct>

<biblStruct xml:id="b423">
	<analytic>
		<title level="a" type="main">Reinforcement learning on slow features of high-dimensional input streams</title>
		<author>
			<persName><forename type="first">R</forename><surname>Legenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wiskott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b424">
	<monogr>
		<title level="m" type="main">Memoir using the chain rule</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Leibniz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1676">1676. 2010</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2" to="3" />
		</imprint>
	</monogr>
	<note>cited in TMME</note>
</biblStruct>

<biblStruct xml:id="b425">
	<analytic>
		<title level="a" type="main">Nova methodus pro maximis et minimis, itemque tangentibus, quae nec fractas, nec irrationales quantitates moratur, et singulare pro illis calculi genus</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Leibniz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Eruditorum</title>
		<imprint>
			<biblScope unit="page" from="467" to="473" />
			<date type="published" when="1684">1684</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b426">
	<analytic>
		<title level="a" type="main">Theory formation by heuristic search</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Lenat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Lenat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1983">1983. 1984</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="269" to="294" />
		</imprint>
	</monogr>
	<note>Why AM an EURISKO appear to work</note>
</biblStruct>

<biblStruct xml:id="b427">
	<analytic>
		<title level="a" type="main">Coding of color and form in the geniculostriate visual pathway</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lennie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Movshon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Optical Society of America A</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2013" to="2033" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b428">
	<analytic>
		<title level="a" type="main">A method for the solution of certain problems in least squares</title>
		<author>
			<persName><forename type="first">K</forename><surname>Levenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quarterly of Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="164" to="168" />
			<date type="published" when="1944">1944</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b429">
	<analytic>
		<title level="a" type="main">On the notion of a random sequence</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Levin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soviet Mathematics Doklady</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1413" to="1416" />
			<date type="published" when="1973">1973a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b430">
	<monogr>
		<title level="m" type="main">Universal sequential search problems. Problems of Information Transmission</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Levin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973">1973b</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="265" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b431">
	<analytic>
		<title level="a" type="main">Fast pruning using principal components</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">U</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Leen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b432">
	<analytic>
		<title level="a" type="main">Control of nonlinear dynamical systems using neural networks. II. Observability, identification, and control</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">U</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Narendra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="42" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b433">
	<analytic>
		<title level="a" type="main">Inferring sparse, overcomplete image codes using an efficient coding framework</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Lewicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Olshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Kearns</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Solla</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="815" to="821" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b434">
	<monogr>
		<title level="m" type="main">Analyse des infiniment petits, pour l&apos;intelligence des lignes courbes</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F A</forename><surname>L'hôpital</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1696">1696</date>
			<publisher>L&apos;Imprimerie Royale</publisher>
			<pubPlace>Paris</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b435">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M B</forename><surname>Vitányi</surname></persName>
		</author>
		<title level="m">An introduction to Kolmogorov complexity and its applications</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b436">
	<analytic>
		<title level="a" type="main">Deep learning based imaging data completion for improved brain disease diagnosis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-I</forename><surname>Suk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
				<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b437">
	<monogr>
		<title level="m" type="main">Reinforcement learning for robots using neural networks</title>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Carnegie Mellon University</publisher>
			<pubPlace>Pittsburgh</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b438">
	<analytic>
		<title level="a" type="main">Learning long-term dependencies in NARX recurrent neural networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Horne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1329" to="1338" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b439">
	<analytic>
		<title level="a" type="main">Mathematical models for cellular interaction in development</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lindenmayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Theoretical Biology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="280" to="315" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b440">
	<analytic>
		<title level="a" type="main">Comparison of two unsupervised neural network models for redundancy reduction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lindstädt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 1993 connectionist models summer school</title>
				<editor>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Smolensky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Elman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Weigend</surname></persName>
		</editor>
		<meeting>of the 1993 connectionist models summer school<address><addrLine>Hillsdale, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Erlbaum Associates</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="308" to="315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b441">
	<analytic>
		<title level="a" type="main">The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors (Master&apos;s thesis)</title>
		<author>
			<persName><forename type="first">S</forename><surname>Linnainmaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">BIT Numerical Mathematics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="146" to="160" />
			<date type="published" when="1970">1970. 1976</date>
		</imprint>
		<respStmt>
			<orgName>Univ. Helsinki. Linnainmaa, S.</orgName>
		</respStmt>
	</monogr>
	<note>Taylor expansion of the accumulated rounding error</note>
</biblStruct>

<biblStruct xml:id="b442">
	<analytic>
		<title level="a" type="main">Self-organization in a perceptual network</title>
		<author>
			<persName><forename type="first">R</forename><surname>Linsker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="105" to="117" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b443">
	<analytic>
		<title level="a" type="main">Learning policies for partially observable environments: scaling up</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Cassandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Kaelbling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine learning: proceedings of the twelfth international conference</title>
				<editor>
			<persName><forename type="first">A</forename><surname>Prieditis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">S</forename><surname>Russell</surname></persName>
		</editor>
		<meeting><address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="362" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b444">
	<analytic>
		<title level="a" type="main">Orientation-selective aVLSI spiking neurons</title>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Indiveri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Delbrück</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Burg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Douglas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6-7</biblScope>
			<biblScope unit="page" from="629" to="643" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b445">
	<monogr>
		<title level="m" type="main">System identification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ljung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b446">
	<analytic>
		<title level="a" type="main">Shape representation in the inferior temporal cortex of monkeys</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Logothetis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pauls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="552" to="563" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b447">
	<monogr>
		<title level="m" type="main">Simulated car racing championship competition software manual</title>
		<author>
			<persName><forename type="first">D</forename><surname>Loiacono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cardamone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Lanzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>Italy: Dipartimento di Elettronica e Informazione. Politecnico di Milano</note>
</biblStruct>

<biblStruct xml:id="b448">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Loiacono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Lanzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Togelius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Onieva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Pelta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Butz</surname></persName>
		</author>
		<title level="m">The 2009 simulated car racing championship</title>
				<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b449">
	<analytic>
		<title level="a" type="main">Object recognition from local scale-invariant features</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Proceedings of the seventh IEEE international conference on computer vision</title>
				<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b450">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant key-points</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b451">
	<analytic>
		<title level="a" type="main">An intrinsic value system for developing multiple invariant representations with incremental slowness learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Luciw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Kompella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kazerounian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neurorobotics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b452">
	<analytic>
		<title level="a" type="main">Deep architectures and deep learning in chemoinformatics: the prediction of aqueous solubility for drug-like molecules</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lusci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pollastri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Information and Modeling</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1563" to="1575" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b453">
	<analytic>
		<title level="a" type="main">Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b454">
	<analytic>
		<title level="a" type="main">Lower bounds for the computational power of networks of spiking neurons</title>
		<author>
			<persName><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="40" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b455">
	<analytic>
		<title level="a" type="main">Networks of spiking neurons: the third generation of neural network models</title>
		<author>
			<persName><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1659" to="1671" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b456">
	<analytic>
		<title level="a" type="main">On the computational power of winner-take-all</title>
		<author>
			<persName><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2519" to="2535" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b457">
	<analytic>
		<title level="a" type="main">Real-time computing without stable states: A new framework for neural computation based on perturbations</title>
		<author>
			<persName><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Natschläger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Markram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2531" to="2560" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b458">
	<analytic>
		<title level="a" type="main">A practical Bayesian framework for backprop networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J C</forename><surname>Mackay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="448" to="472" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b459">
	<analytic>
		<title level="a" type="main">Analysis of Linsker&apos;s simulation of Hebbian rules</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J C</forename><surname>Mackay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="173" to="187" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b460">
	<analytic>
		<title level="a" type="main">Using knowledge-based neural networks to improve algorithms: Refining the Chou-Fasman algorithm for protein folding</title>
		<author>
			<persName><forename type="first">R</forename><surname>Maclin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Shavlik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="195" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b461">
	<analytic>
		<title level="a" type="main">Combining the predictions of multiple classifiers: Using competitive learning to initialize neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Maclin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Shavlik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCAI</title>
				<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="524" to="531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b462">
	<monogr>
		<title level="m" type="main">Inductive learning algorithms for complex systems modeling</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Madala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Ivakhnenko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>CRC Press</publisher>
			<pubPlace>Boca Raton</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b463">
	<analytic>
		<title level="a" type="main">On the undecidability of probabilistic planning and related stochastic optimization problems</title>
		<author>
			<persName><forename type="first">O</forename><surname>Madani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hanks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Condon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="34" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b464">
	<analytic>
		<title level="a" type="main">GQ(λ): A general gradient algorithm for temporaldifference prediction learning with eligibility traces</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Maei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the third conference on artificial general intelligence</title>
				<meeting>the third conference on artificial general intelligence</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="91" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b465">
	<analytic>
		<title level="a" type="main">Model circuit of spiking neurons generating directional selectivity in simple cells</title>
		<author>
			<persName><forename type="first">R</forename><surname>Maex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Orban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1515" to="1545" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b466">
	<analytic>
		<title level="a" type="main">Average reward reinforcement learning: Foundations, algorithms, and empirical results</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mahadevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">159</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b467">
	<analytic>
		<title level="a" type="main">Preattentive texture discrimination with early vision mechanisms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Optical Society of America A</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="923" to="932" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b468">
	<analytic>
		<title level="a" type="main">Genetic evolution of the topology and weight distribution of neural networks</title>
		<author>
			<persName><forename type="first">V</forename><surname>Maniezzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="53" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b469">
	<analytic>
		<title level="a" type="main">First-order recurrent neural networks and deterministic finite state automata</title>
		<author>
			<persName><forename type="first">P</forename><surname>Manolios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fanelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1155" to="1173" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b470">
	<analytic>
		<title level="a" type="main">Multi-resolution linear prediction based features for audio onset detection with bidirectional LSTM neural networks</title>
		<author>
			<persName><forename type="first">E</forename><surname>Marchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ferroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Eyben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gabrielli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Squartini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schuller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 39th IEEE international conference on acoustics, speech, and signal processing</title>
				<meeting>39th IEEE international conference on acoustics, speech, and signal processing</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2183" to="2187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b471">
	<analytic>
		<title level="a" type="main">The human brain project</title>
		<author>
			<persName><forename type="first">H</forename><surname>Markram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific American</title>
		<imprint>
			<biblScope unit="volume">306</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="50" to="55" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b472">
	<analytic>
		<title level="a" type="main">An algorithm for least-squares estimation of nonlinear parameters</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Marquardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Society for Industrial &amp; Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="431" to="441" />
			<date type="published" when="1963">1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b473">
	<analytic>
		<title level="a" type="main">Deep learning via Hessian-free optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th international conference on machine learning</title>
				<editor>
			<persName><forename type="first">J</forename><surname>Fürnkranz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</editor>
		<meeting>the 27th international conference on machine learning<address><addrLine>Haifa, Israel</addrLine></address></meeting>
		<imprint>
			<publisher>OmniPress</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="735" to="742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b474">
	<analytic>
		<title level="a" type="main">Learning recurrent neural networks with Hessianfree optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th international conference on machine learning</title>
				<meeting>the 28th international conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1033" to="1040" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b475">
	<analytic>
		<title level="a" type="main">Three-dimensional neural net for learning visuomotor coordination of a robot arm</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Martinetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Schulten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="131" to="136" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b476">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for image segmentation with max-pooling convolutional networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Giusti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Ciresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fricout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on image processing</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2713" to="2717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b477">
	<analytic>
		<title level="a" type="main">Noise injection into inputs in back-propagation learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Matsuoka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="436" to="440" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b478">
	<analytic>
		<title level="a" type="main">A system for robotic heart surgery that learns to tie knots using recurrent neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Nagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Knoll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advanced Robotics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1521" to="1537" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b479">
	<analytic>
		<title level="a" type="main">Learning to use selective attention and short-term memory in sequential tasks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">From animals to animats 4: proceedings of the fourth international conference on simulation of adaptive behavior</title>
				<editor>
			<persName><forename type="first">W</forename><surname>Mcculloch</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Pitts</surname></persName>
		</editor>
		<imprint>
			<publisher>Bradford Books</publisher>
			<date type="published" when="1943">1996. 1943</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="115" to="133" />
		</imprint>
	</monogr>
	<note>A logical calculus of the ideas immanent in nervous activity</note>
</biblStruct>

<biblStruct xml:id="b480">
	<analytic>
		<title level="a" type="main">RAAM for infinite context-free languages</title>
		<author>
			<persName><forename type="first">O</forename><surname>Melnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Pollack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCNN (5)</title>
				<meeting>IJCNN (5)</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="585" to="590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b481">
	<analytic>
		<title level="a" type="main">Learning to represent spatial transformations with factored higher-order Boltzmann machines</title>
		<author>
			<persName><forename type="first">R</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1473" to="1492" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b482">
	<analytic>
		<title level="a" type="main">Q -cut-dynamic discovery of subgoals in reinforcement learning</title>
		<author>
			<persName><forename type="first">I</forename><surname>Menache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mannor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shimkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECML&apos;02</title>
				<meeting>ECML&apos;02</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="295" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b483">
	<analytic>
		<title level="a" type="main">A million spiking-neuron integrated circuit with a scalable communication network and interface</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Merolla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Alvarez-Icaza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Cassidy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sawada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Akopyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">345</biblScope>
			<biblScope unit="issue">6197</biblScope>
			<biblScope unit="page" from="668" to="673" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b484">
	<analytic>
		<title level="a" type="main">Unsupervised and transfer learning challenge: a deep learning approach</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mesnil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">W&amp;CP: proc. unsupervised and transfer learning</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b485">
	<analytic>
		<title level="a" type="main">Learning finite state controllers for partially observable environments</title>
		<author>
			<persName><forename type="first">N</forename><surname>Meuleau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peshkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Kaelbling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">15th international conference of uncertainty in AI</title>
				<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="427" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b486">
	<analytic>
		<title level="a" type="main">Evolving mobile robots in simulated and real environments</title>
		<author>
			<persName><forename type="first">O</forename><surname>Miglino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nolfi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Life</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="417" to="434" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b487">
	<analytic>
		<title level="a" type="main">A model for the development of simple cell receptive fields and the ordered arrangement of orientation columns through activity-dependent competition between on-and off-center inputs</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="409" to="441" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b488">
	<analytic>
		<title level="a" type="main">Cartesian genetic programming</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Harding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th annual conference companion on genetic and evolutionary computation conference: late breaking papers</title>
				<meeting>the 11th annual conference companion on genetic and evolutionary computation conference: late breaking papers</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="3489" to="3512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b489">
	<analytic>
		<title level="a" type="main">Cartesian genetic programming</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Thomson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic programming</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="121" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b490">
	<analytic>
		<title level="a" type="main">Designing neural networks using genetic algorithms</title>
		<author>
			<persName><forename type="first">G</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hedge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd international conference on genetic algorithms</title>
				<meeting>the 3rd international conference on genetic algorithms</meeting>
		<imprint>
			<publisher>Morgan Kauffman</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="379" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b491">
	<analytic>
		<title level="a" type="main">Perturbation response in feedforward networks</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<editor>Minai, A. A., &amp; Williams, R. D.</editor>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="783" to="796" />
			<date type="published" when="1994">1995. 1994</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
	<note>Neural networks for control</note>
</biblStruct>

<biblStruct xml:id="b492">
	<analytic>
		<title level="a" type="main">Steps toward artificial intelligence</title>
		<author>
			<persName><forename type="first">M</forename><surname>Minsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computers and thought</title>
				<editor>
			<persName><forename type="first">E</forename><surname>Feigenbaum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Feldman</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1963">1963</date>
			<biblScope unit="page" from="406" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b493">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Minsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Papert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perceptrons. Cambridge</title>
		<imprint>
			<date type="published" when="1969">1969</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b494">
	<analytic>
		<title level="a" type="main">Explanation-based learning: A problem solving perspective</title>
		<author>
			<persName><forename type="first">S</forename><surname>Minton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Knoblock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Kuokka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="118" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b495">
	<monogr>
		<title level="m" type="main">Machine learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>McGraw Hill</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b496">
	<analytic>
		<title level="a" type="main">Explanation-based generalization: A unifying view</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Kedar-Cabelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="80" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b497">
	<monogr>
		<title level="m" type="main">Playing Atari with deep reinforcement learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.5602[cs.LG]</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report. Deepmind Technologies</note>
</biblStruct>

<biblStruct xml:id="b498">
	<analytic>
		<title level="a" type="main">Phone recognition using restricted Boltzmann machines</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE international conference on acoustics, speech and signal processing</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="4354" to="4357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b499">
	<analytic>
		<title level="a" type="main">Separation of independent signals using time-delayed correlations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Molgedey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Schuster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="3634" to="3637" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b500">
	<monogr>
		<title level="m" type="main">Exact calculation of the product of the Hessian matrix of feedforward network error functions and a vector in O(N) time</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Møller</surname></persName>
		</author>
		<idno>PB- 432</idno>
		<imprint>
			<date type="published" when="1993">1993</date>
			<pubPlace>Denmark</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computer Science Department, Aarhus University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b501">
	<analytic>
		<title level="a" type="main">Training feedforward neural networks using genetic algorithms</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Montana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th international joint conference on artificial intelligence</title>
				<meeting>the 11th international joint conference on artificial intelligence<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="762" to="767" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b502">
	<analytic>
		<title level="a" type="main">Neural networks: tricks of the trade</title>
		<author>
			<persName><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science Series. LNCS</title>
		<imprint>
			<biblScope unit="volume">7700</biblScope>
			<date type="published" when="2012">2012</date>
			<publisher>Springer Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b503">
	<analytic>
		<title level="a" type="main">Fast learning in multi-resolution hierarchies</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="29" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b504">
	<analytic>
		<title level="a" type="main">The effective number of parameters: An analysis of generalization and regularization in nonlinear learning systems</title>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Lippman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="847" to="854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b505">
	<analytic>
		<title level="a" type="main">Architecture selection strategies for neural networks: Application to corporate bond rating prediction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Utans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks in the capital markets</title>
				<editor>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Refenes</surname></persName>
		</editor>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b506">
	<analytic>
		<title level="a" type="main">Prioritized sweeping: Reinforcement learning with less data and less time</title>
		<author>
			<persName><forename type="first">A</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Atkeson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="103" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b507">
	<analytic>
		<title level="a" type="main">The parti-game algorithm for variable resolution reinforcement learning in multidimensional state-spaces</title>
		<author>
			<persName><forename type="first">A</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Atkeson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="199" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b508">
	<analytic>
		<title level="a" type="main">Symbiotic evolution of neural networks in sequential decision tasks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Moriarty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Miikkulainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="11" to="32" />
			<date type="published" when="1996">1997. 1996</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Sciences, The University of Texas at Austin. Moriarty,</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
	<note>Efficient reinforcement learning through symbiotic evolution</note>
</biblStruct>

<biblStruct xml:id="b509">
	<analytic>
		<title level="a" type="main">Robust reinforcement learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Morimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Doya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Leen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Tresp</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1061" to="1067" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b510">
	<analytic>
		<title level="a" type="main">Data analysis, including statistics</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mosteller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of social psychology</title>
				<editor>
			<persName><forename type="first">G</forename><surname>Lindzey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">E</forename><surname>Aronson</surname></persName>
		</editor>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1968">1968</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b511">
	<analytic>
		<title level="a" type="main">A focused back-propagation algorithm for temporal sequence recognition</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Systems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="349" to="381" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b512">
	<analytic>
		<title level="a" type="main">Discovering discrete distributed representations with iterative competitive learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<editor>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Lippmann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="627" to="634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b513">
	<analytic>
		<title level="a" type="main">Induction of multiscale temporal structure</title>
		<author>
			<persName><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Lippman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="275" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b514">
	<analytic>
		<title level="a" type="main">Skeletonization: A technique for trimming the fat from a network via relevance assessment</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smolensky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="107" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b515">
	<analytic>
		<title level="a" type="main">Fast neural net simulation with a DSP processor array</title>
		<author>
			<persName><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">A</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gunzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Guggenbühl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="203" to="213" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b516">
	<analytic>
		<title level="a" type="main">A dual back-propagation scheme for scalar reinforcement learning</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Munro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ninth annual conference of the cognitive science society</title>
				<meeting>the ninth annual conference of the cognitive science society</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="165" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b517">
	<analytic>
		<title level="a" type="main">Synaptic weight noise during MLP learning enhances fault-tolerance, generalisation and learning trajectory</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Edwards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Cowan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</editor>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="491" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b518">
	<analytic>
		<title level="a" type="main">Non-linear neurons in the low noise limit: a factorial code maximises information transfer</title>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Nadal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="565" to="581" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b519">
	<analytic>
		<title level="a" type="main">An active pulse transmission line simulating nerve axon</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nagumo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yoshizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IRE</title>
				<meeting>the IRE</meeting>
		<imprint>
			<date type="published" when="1962">1962</date>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="2061" to="2070" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b520">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted Boltzmann machines</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b521">
	<analytic>
		<title level="a" type="main">Identification and control of dynamical systems using neural networks</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Narendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Parthasarathy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="27" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b522">
	<analytic>
		<title level="a" type="main">Learning automata-a survey</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Narendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A L</forename><surname>Thathatchar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="323" to="334" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b523">
	<analytic>
		<title level="a" type="main">Classification with Bayesian neural networks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine learning challenges. Evaluating predictive uncertainty, visual object classification, and recognising textual entailment</title>
		<title level="s">Lecture notes in computer science</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Quinonero-Candela</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Magnini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Dagan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>D'alche-Buc</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1995">1995. 2006</date>
			<biblScope unit="volume">3944</biblScope>
			<biblScope unit="page" from="28" to="32" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
	<note>Bayesian learning for neural networks</note>
</biblStruct>

<biblStruct xml:id="b524">
	<analytic>
		<title level="a" type="main">High dimensional classification with Bayesian neural networks and Dirichlet diffusion trees</title>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Studies in fuzziness and soft computing, Feature extraction: foundations and applications</title>
				<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Gunn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Nikravesh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="265" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b525">
	<analytic>
		<title level="a" type="main">Eventdriven contrastive divergence for spiking neuromorphic systems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Neftci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pedroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kreutz-Delgado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cauwenberghs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">272</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b526">
	<analytic>
		<title level="a" type="main">Minitaur, an event-driven FPGA-based spiking network accelerator</title>
		<author>
			<persName><forename type="first">D</forename><surname>Neil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Very Large Scale Integration (VLSI) Systems</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b527">
	<analytic>
		<title level="a" type="main">Bayesian computation emerges in generic cortical microcircuits through spike-timing-dependent plasticity</title>
		<author>
			<persName><forename type="first">B</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Buesing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">e1003037</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b528">
	<analytic>
		<title level="a" type="main">Maximally fault tolerant neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Neti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="14" to="23" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b529">
	<analytic>
		<title level="a" type="main">How to train neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Neuneier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-G</forename><surname>Zimmermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks: tricks of the trade</title>
		<title level="s">Lecture notes in computer science</title>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Orr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp; K.-R</forename><surname>Müller</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">1524</biblScope>
			<biblScope unit="page" from="373" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b530">
	<analytic>
		<title level="a" type="main">The truck backer-upper: An example of self learning in neural networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Newton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Widrow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international joint conference on neural networks</title>
				<meeting>the international joint conference on neural networks<address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="1687">1687. 1989</date>
			<biblScope unit="page" from="357" to="363" />
		</imprint>
	</monogr>
	<note>Philosophiae naturalis principia mathematica</note>
</biblStruct>

<biblStruct xml:id="b531">
	<analytic>
		<title level="a" type="main">How to evolve autonomous robots: Different approaches in evolutionary robotics</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nolfi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Floreano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Miglino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mondada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourth international workshop on the synthesis and simulation of living systems (artificial life IV)</title>
				<editor>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Brooks</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Maes</surname></persName>
		</editor>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT</publisher>
			<date type="published" when="1980">1980. 1994</date>
			<biblScope unit="page" from="190" to="197" />
		</imprint>
	</monogr>
	<note>Principles of artificial intelligence</note>
</biblStruct>

<biblStruct xml:id="b532">
	<analytic>
		<title level="a" type="main">Learning and evolution in neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nolfi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Parisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adaptive Behavior</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="28" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b533">
	<analytic>
		<title level="a" type="main">Sampling strategies for bag-of-features image classification</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
				<meeting>ECCV</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="page" from="490" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b534">
	<analytic>
		<title level="a" type="main">Simplifying neural networks by soft weight sharing</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Nowlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="173" to="193" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b535">
	<analytic>
		<title level="a" type="main">Real-time classification and sensor fusion with a spiking deep belief network</title>
		<author>
			<persName><forename type="first">P</forename><surname>O'connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Neil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Delbruck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pfeiffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">178</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b536">
	<analytic>
		<title level="a" type="main">GPU implementation of neural networks</title>
		<author>
			<persName><forename type="first">K.-S</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1311" to="1314" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b537">
	<analytic>
		<title level="a" type="main">Neural networks, principal components, and subspaces</title>
		<author>
			<persName><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Neural Systems</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="68" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b538">
	<analytic>
		<title level="a" type="main">Data compression, feature extraction, and autoassociation in feedforward neural networks</title>
		<author>
			<persName><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial neural networks</title>
				<editor>
			<persName><forename type="first">T</forename><surname>Kohonen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Mäkisara</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><surname>Simula</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Kangas</surname></persName>
		</editor>
		<meeting><address><addrLine>North-Holland</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier Science Publishers BV</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="737" to="745" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b539">
	<analytic>
		<title level="a" type="main">Emergence of simple-cell receptive field properties by learning a sparse code for natural images</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">381</biblScope>
			<biblScope unit="issue">6583</biblScope>
			<biblScope unit="page" from="607" to="609" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b540">
	<analytic>
		<title level="a" type="main">Extraction of rules from discrete-time recurrent neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Omlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="52" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b541">
	<monogr>
		<title level="m" type="main">Learning and transferring mid-level image representations using convolutional neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Oquab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<idno>hal- 00911179</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b542">
	<analytic>
		<title level="a" type="main">Biologically plausible error-driven learning using local activation differences: The generalized recirculation algorithm</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>O'reilly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="895" to="938" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b543">
	<monogr>
		<title level="m" type="main">Making working memory work: A computational model of learning in the prefrontal cortex and basal ganglia</title>
		<author>
			<persName><forename type="first">R</forename><surname>O'reilly</surname></persName>
		</author>
		<idno>ICS-03-03. ICS</idno>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b544">
	<analytic>
		<title level="a" type="main">Recurrent processing during object recognition</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>O'reilly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wyatte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Herd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mingus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Jilk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">124</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b545">
	<analytic>
		<author>
			<persName><forename type="first">G</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks: tricks of the trade</title>
		<title level="s">Lecture Notes in Computer Science Series. LNCS</title>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">1524</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b546">
	<analytic>
		<title level="a" type="main">Über die Berechnung von Ableitungen</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Ostrovskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">M</forename><surname>Volin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Borisov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wissenschaftliche Zeitschrift der Technischen Hochschule für Chemie</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="382" to="384" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b547">
	<monogr>
		<title level="m" type="main">Goal-oriented representation of the external world: a free-energybased approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Otsuka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>Nara Institute of Science and Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b548">
	<analytic>
		<title level="a" type="main">Free-energy-based reinforcement learning in a partially observable environment</title>
		<author>
			<persName><forename type="first">M</forename><surname>Otsuka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yoshimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Doya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ESANN</title>
				<meeting>ESANN</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b549">
	<analytic>
		<title level="a" type="main">Local feature based online mode detection with recurrent neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Otte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krechel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liwicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 international conference on Frontiers in handwriting recognition</title>
				<meeting>the 2012 international conference on Frontiers in handwriting recognition</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="533" to="537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b550">
	<analytic>
		<title level="a" type="main">Intrinsically motivated learning of real world sensorimotor skills with developmental constraints</title>
		<author>
			<persName><forename type="first">P.-Y</forename><surname>Oudeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Baranes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kaplan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intrinsically motivated learning in natural and artificial systems</title>
				<editor>
			<persName><forename type="first">G</forename><surname>Baldassarre</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Mirolli</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b551">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Pachitariu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sahani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.5650</idno>
		<title level="m">Regularization and nonlinearities for neural language models: when are they needed?</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv Preprint</note>
</biblStruct>

<biblStruct xml:id="b552">
	<analytic>
		<title level="a" type="main">On the information storage capacity of local learning rules</title>
		<author>
			<persName><forename type="first">G</forename><surname>Palm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="703" to="711" />
			<date type="published" when="1980">1980. 1992</date>
		</imprint>
	</monogr>
	<note>Neural Computation</note>
</biblStruct>

<biblStruct xml:id="b553">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b554">
	<analytic>
		<title level="a" type="main">Constructive neural network learning algorithms for multi-category pattern classification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Parekh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Honavar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="436" to="451" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b555">
	<analytic>
		<title level="a" type="main">Learning-logic</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Parker</surname></persName>
		</author>
		<idno>TR-47</idno>
	</analytic>
	<monogr>
		<title level="j">Research in Economics and Management Sci</title>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>MIT</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b556">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6026</idno>
		<title level="m">How to construct deep recurrent neural networks</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv Preprint</note>
</biblStruct>

<biblStruct xml:id="b557">
	<analytic>
		<title level="a" type="main">On the difficulty of training recurrent neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML&apos;13: JMLR: W&amp;CP</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b558">
	<analytic>
		<title level="a" type="main">Evolving structure and function of neurocontrollers</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pasemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Steinmetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Dieckman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the congress on evolutionary computation</title>
				<editor>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Angeline</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">A</forename><surname>Zalzala</surname></persName>
		</editor>
		<meeting>the congress on evolutionary computation<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1973" to="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b559">
	<analytic>
		<title level="a" type="main">Learning state space trajectories in recurrent neural networks</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Pearlmutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="269" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b560">
	<analytic>
		<title level="a" type="main">Fast exact multiplication by the Hessian</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Pearlmutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="147" to="160" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b561">
	<analytic>
		<title level="a" type="main">Gradient calculations for dynamic recurrent neural networks: A survey</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Pearlmutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1212" to="1228" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b562">
	<analytic>
		<title level="a" type="main">G-maximization: An unsupervised learning procedure for discovering regularities</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Pearlmutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks for computing: American institute of physics conference proceedings 151</title>
				<editor>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="333" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b563">
	<analytic>
		<title level="a" type="main">Incremental multi-step Q-learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="283" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b564">
	<analytic>
		<title level="a" type="main">Kalman filters improve LSTM network performance in problems unsolvable by traditional recurrent nets</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Pérez-Ortiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="241" to="250" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b565">
	<monogr>
		<title level="m" type="main">Organization and functions of cells responsive to faces in the temporal cortex</title>
		<author>
			<persName><forename type="first">D</forename><surname>Perrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hietanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Oram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rolls</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
	<note>and discussion</note>
</biblStruct>

<biblStruct xml:id="b566">
	<analytic>
		<title level="a" type="main">Visual neurones responsive to faces in the monkey temporal cortex</title>
		<author>
			<persName><forename type="first">D</forename><surname>Perrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rolls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Caan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Experimental Brain Research</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="329" to="342" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b567">
	<monogr>
		<title level="m" type="main">Policy gradient methods</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Scholarpedia</publisher>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">3698</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b568">
	<analytic>
		<title level="a" type="main">Natural actor-critic</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schaal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="1180" to="1190" />
			<date type="published" when="2008">2008a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b569">
	<analytic>
		<title level="a" type="main">Reinforcement learning of motor skills with policy gradients</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schaal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="682" to="697" />
			<date type="published" when="2008">2008b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b570">
	<monogr>
		<title level="m" type="main">Dropout improves recurrent neural networks for handwriting recognition</title>
		<author>
			<persName><forename type="first">V</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kermorvant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Louradour</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.4569</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv Preprint</note>
</biblStruct>

<biblStruct xml:id="b571">
	<analytic>
		<title level="a" type="main">Generalization of back-propagation to recurrent neural networks</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Pineda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">59</biblScope>
			<biblScope unit="page" from="2229" to="2232" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b572">
	<analytic>
		<title level="a" type="main">Holographic recurrent networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Plate</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Cowan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="34" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b573">
	<monogr>
		<title level="m" type="main">On information theory and unsupervised neural networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Plumbley</surname></persName>
		</author>
		<idno>CUED/F-INFENG/TR.78</idno>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
		<respStmt>
			<orgName>Engineering Department, Cambridge University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b574">
	<analytic>
		<title level="a" type="main">Implications of recursive distributed representations</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Pollack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
				<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="527" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b575">
	<analytic>
		<title level="a" type="main">Recursive distributed representation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Pollack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="77" to="105" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b576">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Pontryagin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">G</forename><surname>Boltyanskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>Gamrelidze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Mishchenko</surname></persName>
		</author>
		<title level="m">The mathematical theory of optimal processes</title>
				<imprint>
			<date type="published" when="1961">1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b577">
	<analytic>
		<title level="a" type="main">Sum-product networks: A new deep architecture</title>
		<author>
			<persName><forename type="first">H</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International conference on computer vision workshops</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="689" to="690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b578">
	<analytic>
		<title level="a" type="main">Finite combinatory processes-formulation 1</title>
		<author>
			<persName><surname>Ieee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Post</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Symbolic Logic</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="103" to="105" />
			<date type="published" when="1936">1936</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b579">
	<analytic>
		<title level="a" type="main">Voxel classification based on triplanar convolutional neural networks applied to cartilage segmentation in knee MRI</title>
		<author>
			<persName><forename type="first">A</forename><surname>Prasoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lauze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LNCS</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">8150</biblScope>
			<biblScope unit="page" from="246" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b580">
	<analytic>
		<title level="a" type="main">Multi-time models for temporally abstract planning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Precup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="1050" to="1056" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b581">
	<analytic>
		<title level="a" type="main">A convolutional learning system for object classification in 3-D LIDAR data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Prokhorov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="858" to="863" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b582">
	<analytic>
		<title level="a" type="main">Adaptive behavior with fixed weights in RNN: an overview</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Prokhorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Feldkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">Y</forename><surname>Tyukin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international joint conference on neural networks</title>
				<meeting>the IEEE international joint conference on neural networks</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="2018" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b583">
	<analytic>
		<title level="a" type="main">Dynamical neural networks for control</title>
		<author>
			<persName><forename type="first">D</forename><surname>Prokhorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Puskorius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Feldkamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A field guide to dynamical recurrent networks</title>
				<editor>
			<persName><forename type="first">J</forename><surname>Kolen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">S</forename><surname>Kremer</surname></persName>
		</editor>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="23" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b584">
	<analytic>
		<title level="a" type="main">Adaptive critic design</title>
		<author>
			<persName><forename type="first">D</forename><surname>Prokhorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wunsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="997" to="1007" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b585">
	<analytic>
		<title level="a" type="main">Neurocontrol of nonlinear dynamical systems with Kalman filter trained recurrent networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">V</forename><surname>Puskorius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Feldkamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="279" to="297" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b586">
	<analytic>
		<title level="a" type="main">Deep learning made easier by linear transformations in perceptrons</title>
		<author>
			<persName><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on artificial intelligence and statistics</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="924" to="932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b587">
	<analytic>
		<title level="a" type="main">Large-scale deep unsupervised learning using graphics processors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Raina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madhavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual International conference on machine learning</title>
				<meeting>the 26th annual International conference on machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="873" to="880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b588">
	<analytic>
		<title level="a" type="main">Multiprocessor and memory architecture of the neurocomputer SYNAPSE-1</title>
		<author>
			<persName><forename type="first">U</forename><surname>Ramacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Raab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Anlauf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Hachmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Beichter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bruels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Neural Systems</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="333" to="336" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b589">
	<analytic>
		<title level="a" type="main">Unsupervised learning of invariant feature hierarchies with applications to object recognition</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. computer vision and pattern recognition conference</title>
				<meeting>computer vision and pattern recognition conference</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b590">
	<analytic>
		<title level="a" type="main">Efficient learning of sparse representations with an energy-based model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Poultney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<editor>
			<persName><forename type="first">J</forename><surname>Platt</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b591">
	<analytic>
		<title level="a" type="main">The growing hierarchical self-organizing map: exploratory analysis of high-dimensional data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Merkl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dittenbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1331" to="1341" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b592">
	<monogr>
		<title level="m" type="main">CNN features off-theshelf: an astounding baseline for recognition</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Razavian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Azizpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carlsson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1403.6382</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv Preprint</note>
</biblStruct>

<biblStruct xml:id="b593">
	<monogr>
		<title level="m" type="main">Evolutionsstrategie-optimierung technischer systeme nach prinzipien der biologischen evolution (Dissertation)</title>
		<author>
			<persName><forename type="first">I</forename><surname>Rechenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
	<note>Published 1973 by Fromman-Holzboog</note>
</biblStruct>

<biblStruct xml:id="b594">
	<analytic>
		<title level="a" type="main">Redundancy reduction as a strategy for unsupervised learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Redlich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="289" to="304" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b595">
	<analytic>
		<title level="a" type="main">Stock performance modeling using neural networks: a comparative study with regression models</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Refenes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zapranis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Francis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="375" to="388" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b596">
	<analytic>
		<title level="a" type="main">Stochastic variational learning in recurrent spiking networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gerstner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Computational Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">38</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b597">
	<analytic>
		<title level="a" type="main">Neural fitted Q iteration-first experiences with a data efficient neural reinforcement learning method</title>
		<author>
			<persName><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECML-2005</title>
				<meeting>ECML-2005<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="317" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b598">
	<analytic>
		<title level="a" type="main">A direct adaptive method for faster backpropagation learning: The Rprop algorithm</title>
		<author>
			<persName><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Braun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCNN</title>
				<meeting>IJCNN</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="586" to="591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b599">
	<analytic>
		<title level="a" type="main">Autonomous reinforcement learning on raw visual input data in a real world application</title>
		<author>
			<persName><surname>Ieee Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Voigtlaender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International joint conference on neural networks</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b600">
	<analytic>
		<title level="a" type="main">Hierarchical models of object recognition in cortex</title>
		<author>
			<persName><forename type="first">M</forename><surname>Riesenhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1019" to="1025" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b601">
	<analytic>
		<title level="a" type="main">Contractive autoencoders: Explicit invariance during feature extraction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th international conference on machine learning</title>
				<meeting>the 28th international conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="833" to="840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b602">
	<analytic>
		<title level="a" type="main">Incremental development of complex behaviors through automatic construction of sensory-motor hierarchies</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Ring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine learning: proceedings of the eighth international workshop</title>
				<editor>
			<persName><forename type="first">L</forename><surname>Birnbaum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Collins</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="343" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b603">
	<analytic>
		<title level="a" type="main">Learning sequential tasks by incrementally adding higher orders</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Ring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<editor>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Cowan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="115" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b604">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Ring</surname></persName>
		</author>
		<title level="m">Continual learning in reinforcement environments</title>
				<meeting><address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">78712</biblScope>
		</imprint>
		<respStmt>
			<orgName>University of Texas at Austin</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b605">
	<analytic>
		<title level="a" type="main">The two-dimensional organization of behavior</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the first joint conference on development learning and on epigenetic robotics</title>
				<meeting>the first joint conference on development learning and on epigenetic robotics</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b606">
	<analytic>
		<title level="a" type="main">A unified approach to evolving plasticity and neural geometry</title>
		<author>
			<persName><forename type="first">S</forename><surname>Risi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International joint conference on neural networks</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b607">
	<analytic>
		<title level="a" type="main">Stochastic complexity and modeling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rissanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1080" to="1100" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b608">
	<analytic>
		<title level="a" type="main">Self-organizing semantic maps</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kohonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="241" to="254" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b609">
	<analytic>
		<title level="a" type="main">Dynamic reinforcement driven error propagation networks with application to game playing</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fallside</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fallside</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename></persName>
		</author>
		<idno>CUED/F-INFENG/TR.1</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th conference of the cognitive science society</title>
				<meeting>the 11th conference of the cognitive science society</meeting>
		<imprint>
			<date type="published" when="1987">1987. 1989</date>
			<biblScope unit="page" from="836" to="843" />
		</imprint>
		<respStmt>
			<orgName>Cambridge University Engineering Department. Robinson,</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>The utility driven dynamic error propagation network</note>
</biblStruct>

<biblStruct xml:id="b610">
	<analytic>
		<title level="a" type="main">Recurrent neural networks can learn to implement symbol-sensitive counting</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wiles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="87" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b611">
	<analytic>
		<title level="a" type="main">A recurrent neural network that learns to count</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wiles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connection Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="40" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b612">
	<analytic>
		<title level="a" type="main">Hardware spiking neural network with run-time reconfigurable connectivity in an autonomous robot</title>
		<author>
			<persName><forename type="first">D</forename><surname>Roggen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Thoma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Floreano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NASA/DoD conference on evolvable hardware</title>
				<meeting>NASA/DoD conference on evolvable hardware</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="189" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b613">
	<analytic>
		<title level="a" type="main">The &apos;moving targets&apos; training method</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rohwer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of &apos;distributed adaptive neural information processing</title>
				<editor>
			<persName><forename type="first">J</forename><surname>Kindermann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">A</forename><surname>Linden</surname></persName>
		</editor>
		<meeting>&apos;distributed adaptive neural information processing</meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b614">
	<analytic>
		<title level="a" type="main">The perceptron: a probabilistic model for information storage and organization in the brain</title>
		<author>
			<persName><surname>Oldenbourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rosenblatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">386</biblScope>
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b615">
	<monogr>
		<title level="m" type="main">Principles of neurodynamics</title>
		<author>
			<persName><forename type="first">F</forename><surname>Rosenblatt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962">1962</date>
			<publisher>Spartan</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b616">
	<analytic>
		<title level="a" type="main">Mitosis detection in breast cancer histological images-an ICPR 2012 contest</title>
		<author>
			<persName><forename type="first">L</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Racoceanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lomenie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kulikova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Irshad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Klossa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Pathology Informatics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b617">
	<analytic>
		<title level="a" type="main">Development of feature detectors by selforganization: A network model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rubner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schulten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="193" to="199" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b618">
	<analytic>
		<title level="a" type="main">State-dependent exploration for policy gradient methods</title>
		<author>
			<persName><forename type="first">T</forename><surname>Rückstieß</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Felder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LNAI</title>
				<editor>
			<persName><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="volume">5212</biblScope>
			<biblScope unit="page" from="234" to="249" />
		</imprint>
	</monogr>
	<note>part II</note>
</biblStruct>

<biblStruct xml:id="b619">
	<analytic>
		<title level="a" type="main">Learning internal representations by error propagation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel distributed processing</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="318" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b620">
	<analytic>
		<title level="a" type="main">Feature discovery by competitive learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zipser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel distributed processing</title>
				<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="151" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b621">
	<monogr>
		<title level="m" type="main">On-line Q-learning using connectionist sytems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rummery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Niranjan</surname></persName>
		</author>
		<idno>CUED/F-INFENG-TR 166</idno>
		<imprint>
			<date type="published" when="1994">1994</date>
			<pubPlace>UK</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Cambridge University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b622">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Norvig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Canny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Edwards</surname></persName>
		</author>
		<title level="m">Artificial intelligence: a modern approach</title>
				<meeting><address><addrLine>Englewood Cliffs</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b623">
	<analytic>
		<title level="a" type="main">Partial BFGS update and efficient step-length calculation for three-layer neural networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nakano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="123" to="141" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b624">
	<analytic>
		<title level="a" type="main">Long short-term memory recurrent neural network architectures for large scale acoustic modeling</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Beaufays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. interspeech</title>
				<meeting>interspeech</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b625">
	<analytic>
		<title level="a" type="main">Sequence discriminative distributed training of long short-term memory recurrent neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
				<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b626">
	<analytic>
		<title level="a" type="main">Semantic hashing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Approximate Reasoning</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="969" to="978" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b627">
	<analytic>
		<title level="a" type="main">Reinforcement learning with factored states and actions</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sallans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1063" to="1088" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b628">
	<analytic>
		<title level="a" type="main">Probabilistic incremental program evolution</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Sałustowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="141" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b629">
	<analytic>
		<title level="a" type="main">Inter-module credit assignment in modular reinforcement learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Samejima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Doya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kawato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="985" to="994" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b630">
	<analytic>
		<title level="a" type="main">Some studies in machine learning using the game of checkers</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Samuel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="210" to="229" />
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b631">
	<analytic>
		<title level="a" type="main">An optimality principle for unsupervised learning</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Sanger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="11" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b632">
	<analytic>
		<title level="a" type="main">Experiments with reinforcement learning in problems with continuous state and action spaces</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Santamaría</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adaptive Behavior</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="163" to="217" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b633">
	<analytic>
		<title level="a" type="main">Evolving neural control systems</title>
		<author>
			<persName><forename type="first">N</forename><surname>Saravanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Fogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Expert</title>
		<imprint>
			<biblScope unit="page" from="23" to="27" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b634">
	<analytic>
		<title level="a" type="main">Unsupervised learning of mixtures of multiple causes in binary data</title>
		<author>
			<persName><forename type="first">E</forename><surname>Saund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Cowan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Tesauro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Alspector</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="27" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b635">
	<analytic>
		<title level="a" type="main">Learning long term dependencies with recurrent neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Schaback</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Werner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Udluft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-G</forename><surname>Zimmermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICANN</title>
		<editor>S. D. Kollias, A. Stafylopatis, W. Duch, &amp; E. Oja</editor>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="80" />
			<date type="published" when="1992">1992. 2006</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>Numerische mathematik</note>
</biblStruct>

<biblStruct xml:id="b636">
	<analytic>
		<title level="a" type="main">The strength of weak learnability</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="197" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b637">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Metalearning. Scholarpedia</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">4650</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b638">
	<analytic>
		<title level="a" type="main">No more pesky learning rates</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 30th International conference on machine learning</title>
				<meeting>30th International conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b639">
	<analytic>
		<title level="a" type="main">Implementing synaptic plasticity in a VLSI spiking neural network model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schemmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Grubl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International joint conference on neural networks</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b640">
	<analytic>
		<title level="a" type="main">Evaluation of pooling operations in convolutional architectures for object recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International conference on artificial neural networks</title>
				<meeting>International conference on artificial neural networks</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="92" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b641">
	<analytic>
		<title level="a" type="main">Evolutionary principles in self-referential learning, or on learning how to learn: the meta-meta-... hook (Diploma thesis)</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<ptr target="http://www.idsia.ch/~juergen/diploma.html" />
	</analytic>
	<monogr>
		<title level="j">Inst. f. Inf., Tech. Univ. Munich</title>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b642">
	<analytic>
		<title level="a" type="main">Accelerated learning in back-propagation nets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Connectionism in perspective</title>
				<editor>
			<persName><forename type="first">R</forename><surname>Pfeifer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Schreter</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Fogelman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Steels</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam; North-Holland</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1989">1989a</date>
			<biblScope unit="page" from="429" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b643">
	<analytic>
		<title level="a" type="main">A local learning algorithm for dynamic feedforward and recurrent networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connection Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="403" to="412" />
			<date type="published" when="1989">1989b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b644">
	<analytic>
		<title level="a" type="main">Dynamic neural nets and the fundamental spatiotemporal credit assignment problem.) (Dissertation)</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Dynamische neuronale Netze und das fundamentale raumzeitliche Lernproblem</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Elman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan</publisher>
			<date type="published" when="1990">1990a. 1990b</date>
			<biblScope unit="page" from="52" to="61" />
		</imprint>
	</monogr>
	<note>Proc. of the 1990 connectionist models summer school</note>
</biblStruct>

<biblStruct xml:id="b645">
	<analytic>
		<title level="a" type="main">University of Colorado at Boulder (1992), and Z. Li&apos;s NIPS*94 workshop on unsupervised learning</title>
		<author>
			<persName><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. conference on neural information processing</title>
				<imprint>
			<date type="published" when="1990">1990c. 1990. 1996</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="194" to="197" />
		</imprint>
	</monogr>
	<note>Talks at TU Munich</note>
</biblStruct>

<biblStruct xml:id="b646">
	<analytic>
		<title level="a" type="main">An on-line algorithm for dynamic reinforcement learning and planning in reactive environments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/INNS international joint conference on neural networks</title>
				<meeting>IEEE/INNS international joint conference on neural networks</meeting>
		<imprint>
			<date type="published" when="1990">1990d</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="253" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b647">
	<analytic>
		<title level="a" type="main">Learning to generate sub-goals for action sequences</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international joint conference on neural networks</title>
				<editor>
			<persName><forename type="first">T</forename><surname>Kohonen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Mäkisara</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><surname>Simula</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Kangas</surname></persName>
		</editor>
		<meeting>the international joint conference on neural networks<address><addrLine>Schmidhuber, J.; North-Holland</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier Science Publishers BV</publisher>
			<date type="published" when="1991">1991a. 1991b</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="967" to="972" />
		</imprint>
	</monogr>
	<note>Artificial neural networks</note>
</biblStruct>

<biblStruct xml:id="b648">
	<analytic>
		<title level="a" type="main">Reinforcement learning in Markovian and non-Markovian environments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Lippman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan</publisher>
			<date type="published" when="1991">1991c</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="500" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b649">
	<monogr>
		<title/>
		<author>
			<persName><surname>Kaufmann</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b650">
	<analytic>
		<title level="a" type="main">A fixed size storage O(n 3 ) time complexity learning algorithm for fully recurrent continually running networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="243" to="248" />
			<date type="published" when="1992">1992a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b651">
	<analytic>
		<title level="a" type="main">Learning complex, extended sequences using the principle of history compression</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno>on TR FKI- 148-91</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="863" to="879" />
			<date type="published" when="1991">1992b. 1991. 1992c</date>
		</imprint>
	</monogr>
	<note>Neural Computation</note>
</biblStruct>

<biblStruct xml:id="b652">
	<analytic>
		<title level="a" type="main">An introspective network that can learn to run its own weight change algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the intl. conf. on artificial neural networks</title>
				<meeting>of the intl. conf. on artificial neural networks<address><addrLine>Brighton</addrLine></address></meeting>
		<imprint>
			<publisher>IEE</publisher>
			<date type="published" when="1993">1993a</date>
			<biblScope unit="page" from="191" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b653">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<title level="m">Netzwerkarchitekturen, Zielfunktionen und Kettenregel. (Network architectures, objective functions, and chain rule</title>
				<imprint>
			<date type="published" when="1993">1993b</date>
		</imprint>
		<respStmt>
			<orgName>Inst. f. Inf., Tech. Univ. Munich</orgName>
		</respStmt>
	</monogr>
	<note>Habilitation thesis</note>
</biblStruct>

<biblStruct xml:id="b654">
	<analytic>
		<title level="a" type="main">Discovering neural nets with low Kolmogorov complexity and high generalization capability</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="857" to="873" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b655">
	<analytic>
		<title level="a" type="main">The speed prior: a new simplicity measure yielding nearoptimal computable predictions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lecture notes in artificial intelligence, Proceedings of the 15th annual conference on computational learning theory</title>
				<editor>
			<persName><forename type="first">J</forename><surname>Kivinen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Sloan</surname></persName>
		</editor>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="216" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b656">
	<analytic>
		<title level="a" type="main">Optimal ordered problem solver</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="211" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b657">
	<analytic>
		<title level="a" type="main">Developmental robotics, optimal artificial curiosity, creativity, music, and the fine arts</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connection Science</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="187" />
			<date type="published" when="2006">2006a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b658">
	<analytic>
		<title level="a" type="main">Gödel machines: Fully self-referential optimal universal self-improvers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:cs.LO/0309048</idno>
	</analytic>
	<monogr>
		<title level="m">Artificial general intelligence</title>
				<editor>
			<persName><forename type="first">B</forename><surname>Goertzel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Pennachin</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2006">2006b</date>
			<biblScope unit="page" from="199" to="226" />
		</imprint>
	</monogr>
	<note>Variant available as</note>
</biblStruct>

<biblStruct xml:id="b659">
	<analytic>
		<title level="a" type="main">Prototype resilient, self-modeling robots</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">316</biblScope>
			<biblScope unit="issue">5825</biblScope>
			<biblScope unit="page">688</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b660">
	<analytic>
		<title level="a" type="main">Self-delimiting neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1210.0118v1[cs.NE]</idno>
	</analytic>
	<monogr>
		<title level="m">The Swiss AI Lab IDSIA</title>
				<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b661">
	<analytic>
		<title level="a" type="main">My first deep learning system of 1991 + deep learning timeline 1962-2013</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.5548v1[cs.NE]</idno>
	</analytic>
	<monogr>
		<title level="m">The Swiss AI Lab IDSIA</title>
				<imprint>
			<date type="published" when="2013">2013a</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b662">
	<analytic>
		<title level="a" type="main">PowerPlay: training an increasingly general problem solver by continually searching for the simplest still unsolvable problem</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<date type="published" when="2013">2013b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b663">
	<analytic>
		<title level="a" type="main">On fast deep nets for AGI vision</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ciresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. fourth conference on artificial general intelligence</title>
				<meeting>fourth conference on artificial general intelligence</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="243" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b664">
	<analytic>
		<title level="a" type="main">Semilinear predictability minimization produces well-known feature detectors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eldracher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Foltin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="773" to="786" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b665">
	<analytic>
		<title level="a" type="main">Learning to generate artificial fovea trajectories for target detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Neural Systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="135" to="141" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b666">
	<analytic>
		<title level="a" type="main">Continuous history compression</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Prelinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of intl. workshop on neural networks</title>
				<editor>
			<persName><forename type="first">H</forename><surname>Hüning</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Neuhauser</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Raus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">W</forename><surname>Ritschel</surname></persName>
		</editor>
		<meeting>of intl. workshop on neural networks<address><addrLine>Augustinus; Aachen</addrLine></address></meeting>
		<imprint>
			<publisher>RWTH</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="87" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b667">
	<analytic>
		<title level="a" type="main">Discovering predictable classifications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Prelinger</surname></persName>
		</author>
		<idno>CU-CS-626-92</idno>
	</analytic>
	<monogr>
		<title level="j">Dept. of Comp. Sci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="625" to="635" />
			<date type="published" when="1992">1992. 1993</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>Neural Computation</note>
</biblStruct>

<biblStruct xml:id="b668">
	<analytic>
		<title level="a" type="main">Planning simple trajectories using neural subgoal generators</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wahnsiedler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2nd international conference on simulation of adaptive behavior</title>
				<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Meyer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Roitblat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Wilson</surname></persName>
		</editor>
		<meeting>of the 2nd international conference on simulation of adaptive behavior</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="196" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b669">
	<analytic>
		<title level="a" type="main">Training recurrent networks by Evolino</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gagliolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Gomez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="757" to="779" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b670">
	<analytic>
		<title level="a" type="main">Reinforcement learning with self-modifying policies</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Schraudolph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning to learn</title>
				<editor>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Pratt</surname></persName>
		</editor>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="293" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b671">
	<analytic>
		<title level="a" type="main">Shifting inductive bias with successstory algorithm, adaptive Levin search, and incremental self-improvement</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wiering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="105" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b672">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName><surname>Smola</surname></persName>
		</author>
		<title level="m">Advances in kernel methodssupport vector learning</title>
				<editor>
			<persName><forename type="first">A</forename><forename type="middle">J</forename></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b673">
	<analytic>
		<title level="a" type="main">Fast curvature matrix-vector products for second-order gradient descent</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Schraudolph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1723" to="1738" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b674">
	<analytic>
		<title level="a" type="main">Unsupervised discrimination of clustered data via optimization of binary information gain</title>
		<author>
			<persName><forename type="first">N</forename><surname>Schraudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<editor>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Cowan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</editor>
		<meeting><address><addrLine>San Mateo</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="499" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b675">
	<analytic>
		<title level="a" type="main">Tempering backpropagation networks: not all weights are created equal</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Schraudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Hasselmo</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="563" to="569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b676">
	<analytic>
		<title level="a" type="main">An overview of reservoir computing: theory, applications and implementations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schrauwen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Verstraeten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Campenhout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th European symposium on artificial neural networks</title>
				<meeting>the 15th European symposium on artificial neural networks</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="471" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b677">
	<analytic>
		<title level="a" type="main">Learning by maximization the information transfer through nonlinear noisy neurons and &apos;&apos;noise breakdown</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Schuster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review A</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2131" to="2138" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b678">
	<analytic>
		<title level="a" type="main">On supervised learning from sequential data with applications for speech recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<editor>Nara Institute of Science and Technolog. Schuster, M., &amp; Paliwal, K. K.</editor>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="2673" to="2681" />
			<date type="published" when="1997">1999. 1997</date>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
	<note>Bidirectional recurrent neural networks</note>
</biblStruct>

<biblStruct xml:id="b679">
	<analytic>
		<title level="a" type="main">A reinforcement learning method for maximizing undiscounted rewards</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
				<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="298" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b680">
	<monogr>
		<title level="m" type="main">Numerische optimierung von computer-modellen (Dissertation), Published 1977 by Birkhäuser, Basel. Segmentation of Neuronal Structures in EM Stacks Challenge</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Schwefel</surname></persName>
		</author>
		<ptr target="http://tinyurl.com/d2fgh7g" />
		<imprint>
			<date type="published" when="1974">1974. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b681">
	<analytic>
		<title level="a" type="main">Parameter-exploring policy gradients</title>
		<author>
			<persName><forename type="first">F</forename><surname>Sehnke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Osendorfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rückstieß</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="551" to="559" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b682">
	<monogr>
		<title level="m" type="main">Over-Feat: integrated recognition, localization and detection using convolutional networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6229</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv Preprint</note>
</biblStruct>

<biblStruct xml:id="b683">
	<analytic>
		<title level="a" type="main">Traffic sign recognition with multi-scale convolutional networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of international joint conference on neural networks</title>
				<meeting>international joint conference on neural networks</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2809" to="2813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b684">
	<analytic>
		<title level="a" type="main">Caviar: A 45 k neuron, 5 m synapse, 12 g connects/s AER hardware sensory-processing-learning-actuating system for high-speed visual object recognition and tracking</title>
		<author>
			<persName><forename type="first">R</forename><surname>Serrano-Gotarredona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Oster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lichtsteiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Linares-Barranco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Paz-Vicente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gómez-Rodríguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1417" to="1438" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b685">
	<analytic>
		<title level="a" type="main">On the role of object-specific features for real world object recognition in biological vision</title>
		<author>
			<persName><forename type="first">T</forename><surname>Serre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riesenhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Louie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biologically motivated computer vision</title>
				<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="387" to="397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b686">
	<analytic>
		<title level="a" type="main">Learning in spiking neural networks by reinforcement of stochastic synaptic transmission</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1063" to="1073" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b687">
	<analytic>
		<title level="a" type="main">Efficient visual coding: From retina to V2</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cottrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Cottrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6077</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. international conference on learning representations</title>
				<meeting>international conference on learning representations</meeting>
		<imprint>
			<date type="published" when="2007">2014. 2007</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">1273</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv Preprint</note>
	<note>Advances in neural information processing systems (NIPS)</note>
</biblStruct>

<biblStruct xml:id="b688">
	<analytic>
		<title level="a" type="main">Conditioning of quasi-Newton methods for function minimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Shanno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">111</biblScope>
			<biblScope unit="page" from="647" to="656" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b689">
	<analytic>
		<title level="a" type="main">A mathematical theory of communication (parts I and II)</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell System Technical Journal</title>
		<imprint>
			<biblScope unit="volume">XXVII</biblScope>
			<biblScope unit="page" from="379" to="423" />
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b690">
	<analytic>
		<title level="a" type="main">Learning deep and wide: A spectral method for learning deep networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems. Shavlik</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="321" to="331" />
			<date type="published" when="1994">2014. 1994</date>
		</imprint>
	</monogr>
	<note>Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b691">
	<analytic>
		<title level="a" type="main">Combining explanation-based and neural learning: An algorithm and empirical results</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Shavlik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Towell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connection Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="233" to="255" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b692">
	<analytic>
		<title level="a" type="main">Theoretical foundations of recurrent neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Siegelmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The State of New Jersey: Rutgers</title>
				<meeting><address><addrLine>New Brunswick Rutgers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b693">
	<analytic>
		<title level="a" type="main">Turing computability with neural nets</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Siegelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Sontag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics Letters</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="77" to="80" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b694">
	<analytic>
		<title level="a" type="main">Speeding up back-propagation</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Almeida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced neural computers</title>
				<editor>
			<persName><forename type="first">R</forename><surname>Eckmiller</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="151" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b695">
	<analytic>
		<title level="a" type="main">Loading deep networks is hard</title>
		<author>
			<persName><forename type="first">J</forename><surname>Síma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="842" to="850" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b696">
	<analytic>
		<title level="a" type="main">Training a single sigmoidal neuron is hard</title>
		<author>
			<persName><forename type="first">J</forename><surname>Síma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2709" to="2728" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b697">
	<analytic>
		<title level="a" type="main">Best practices for convolutional neural networks applied to visual document analysis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Steinkraus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh international conference on document analysis and recognition</title>
				<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="958" to="963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b698">
	<analytic>
		<title level="a" type="main">Evolving virtual creatures</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH, Proceedings of SIGGRAPH &apos;94, computer graphics proceedings, annual conference</title>
				<editor>
			<persName><forename type="first">A</forename><surname>Glassner</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="15" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b699">
	<analytic>
		<title level="a" type="main">Skill characterization based on betweenness</title>
		<author>
			<persName><forename type="first">Ö</forename><surname>Simsek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;08</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1497" to="1504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b700">
	<analytic>
		<title level="a" type="main">Reinforcement learning algorithms for average-payoff Markovian decision processes</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">National conference on artificial intelligence</title>
				<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="700" to="705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b701">
	<analytic>
		<title level="a" type="main">Intrinsically motivated reinforcement learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chentanez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b702">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Cambridge</surname></persName>
		</author>
		<imprint>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b703">
	<monogr>
		<title level="m" type="main">A learning system based on genetic adaptive algorithms</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
		</imprint>
		<respStmt>
			<orgName>Univ. Pittsburgh</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b704">
	<analytic>
		<title level="a" type="main">Parallel distributed processing: Explorations in the microstructure of cognition</title>
		<author>
			<persName><forename type="first">P</forename><surname>Smolensky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information processing in dynamical systems: foundations of harmony theory</title>
				<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="194" to="281" />
		</imprint>
	</monogr>
	<note>Chapter</note>
</biblStruct>

<biblStruct xml:id="b705">
	<analytic>
		<title level="a" type="main">Accelerated learning in layered neural networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Solla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="625" to="640" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b706">
	<analytic>
		<title level="a" type="main">A formal theory of inductive inference</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Solomonoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Part I. Information and Control</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b707">
	<analytic>
		<title level="a" type="main">Complexity-based induction systems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Solomonoff</surname></persName>
		</author>
		<idno>IT-24</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="422" to="432" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b708">
	<analytic>
		<title level="a" type="main">Learning to program = learning to construct mechanisms and explanations</title>
		<author>
			<persName><forename type="first">E</forename><surname>Soloway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="850" to="858" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b709">
	<analytic>
		<title level="a" type="main">Competitive Hebbian learning through spike-timing-dependent synaptic plasticity</title>
		<author>
			<persName><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Abbott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="919" to="926" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b710">
	<monogr>
		<title level="m" type="main">Compiling fast partial derivatives of functions given by algorithms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Speelpenning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
			<pubPlace>Urbana-Champaign</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Illinois</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b711">
	<analytic>
		<title level="a" type="main">Compete to compute</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kazerounian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2310" to="2318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b712">
	<analytic>
		<title level="a" type="main">The German traffic sign recognition benchmark: A multi-class classification competition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Stallkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schlipsing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Salmen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International joint conference on neural networks</title>
				<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1453" to="1460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b713">
	<analytic>
		<title level="a" type="main">Man vs. computer: benchmarking machine learning algorithms for traffic sign recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Stallkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schlipsing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Salmen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="323" to="332" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b714">
	<analytic>
		<title level="a" type="main">A hypercube-based encoding for evolving large-scale neural networks</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>D'ambrosio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gauci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Life</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="185" to="212" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b715">
	<analytic>
		<title level="a" type="main">Evolving neural networks through augmenting topologies</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="99" to="127" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b716">
	<analytic>
		<title level="a" type="main">A recurrent network that performs a contextsensitive prediction task</title>
		<author>
			<persName><forename type="first">M</forename><surname>Steijvers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Grunwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th annual conference of the cognitive science society</title>
				<meeting>the 18th annual conference of the cognitive science society</meeting>
		<imprint>
			<publisher>Erlbaum</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b717">
	<analytic>
		<title level="a" type="main">Online reservoir adaptation by intrinsic plasticity for backpropagation-decorrelation and echo state learning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Steil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="353" to="364" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b718">
	<analytic>
		<title level="a" type="main">A single spike suffices: the simplest form of stochastic resonance in model neurons</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stemmler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Network: Computation in Neural Systems</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="687" to="716" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b719">
	<analytic>
		<title level="a" type="main">Emergence of a &apos;visual number sense&apos; in hierarchical generative models</title>
		<author>
			<persName><forename type="first">I</forename><surname>Stoianov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zorzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="194" to="196" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b720">
	<analytic>
		<title level="a" type="main">Cross-validatory choice and assessment of statistical predictions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society B</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="111" to="147" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b721">
	<analytic>
		<title level="a" type="main">When pyramidal neurons lock, when they respond chaotically, and when they like to synchronize</title>
		<author>
			<persName><forename type="first">R</forename><surname>Stoop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bunimovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroscience Research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="91" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b722">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Stratonovich</surname></persName>
		</author>
		<title level="m">Conditional Markov processes. Theory of Probability and Its Applications</title>
				<imprint>
			<date type="published" when="1960">1960</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="156" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b723">
	<analytic>
		<title level="a" type="main">Time warping invariant neural networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Cowan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="180" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b724">
	<monogr>
		<title level="m" type="main">The neural network pushdown automaton: Model, stack and learning simulations</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<idno>CS-TR-3118</idno>
		<imprint>
			<date type="published" when="1993">1993</date>
			<pubPlace>College Park</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Maryland</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b725">
	<analytic>
		<title level="a" type="main">A linear time natural evolution strategy for non-separable functions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the genetic and evolutionary computation conference</title>
				<meeting>the genetic and evolutionary computation conference<address><addrLine>Amsterdam, NL</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page">61</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b726">
	<analytic>
		<title level="a" type="main">Efficient natural evolution strategies</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th genetic and evolutionary computation conference</title>
				<meeting>11th genetic and evolutionary computation conference</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="539" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b727">
	<analytic>
		<title level="a" type="main">The recurrent temporal restricted Boltzmann machine</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="volume">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b728">
	<monogr>
		<title level="m" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.3215[cs.CL]Google.NIPS</idno>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b729">
	<analytic>
		<title level="a" type="main">Policy gradient methods for reinforcement learning with function approximation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1998">1998. 1999</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1057" to="1063" />
		</imprint>
	</monogr>
	<note>Reinforcement learning: An introduction</note>
</biblStruct>

<biblStruct xml:id="b730">
	<analytic>
		<title level="a" type="main">Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Precup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="181" to="211" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b731">
	<analytic>
		<title level="a" type="main">A convergent O(n) algorithm for off-policy temporal-difference learning with linear function approximation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szepesvári</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Maei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS&apos;08)</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1609" to="1616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b732">
	<analytic>
		<title level="a" type="main">Cross-entropy optimization for independent process analysis</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Szabó</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Póczos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lőrincz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Independent component analysis and blind signal separation</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="909" to="916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b733">
	<monogr>
		<title level="m" type="main">Going deeper with convolutions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.4842[cs.CV]</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Google</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b734">
	<monogr>
		<title level="m" type="main">Deep neural networks for object detection</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2553" to="2561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b735">
	<analytic>
		<title level="a" type="main">Learning invariance through imitation</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Spiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bregler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on computer vision and pattern recognition</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2729" to="2736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b736">
	<analytic>
		<title level="a" type="main">NNcon: improved protein contact map prediction using 2D-recursive neural networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Tegge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eickholt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="W515" to="W518" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>Suppl 2</note>
</biblStruct>

<biblStruct xml:id="b737">
	<analytic>
		<title level="a" type="main">Learning invariance from natural images inspired by observations in the primary visual cortex</title>
		<author>
			<persName><forename type="first">M</forename><surname>Teichmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wiltschut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hamker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1271" to="1296" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b738">
	<analytic>
		<title level="a" type="main">The evolution of mental models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Teller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in genetic programming</title>
				<editor>
			<persName><forename type="first">E</forename><surname>Kenneth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">J</forename><surname>Kinnear</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="199" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b739">
	<analytic>
		<title level="a" type="main">Learning via task decomposition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tenenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Whitehead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">From animals to animats 2: proceedings of the second international conference on simulation of adaptive behavior</title>
				<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Meyer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Roitblat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">S</forename><surname>Wilson</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="337" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b740">
	<analytic>
		<title level="a" type="main">TD-gammon, a self-teaching backgammon program, achieves master-level play</title>
		<author>
			<persName><forename type="first">G</forename><surname>Tesauro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="215" to="219" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b741">
	<analytic>
		<title level="a" type="main">Lecture 6.5-RmsProp: Divide the gradient by a running average of its recent magnitude</title>
		<author>
			<persName><forename type="first">T</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Tikhonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">I</forename><surname>Arsenin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>John</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. international joint conference on artificial intelligence</title>
				<editor>
			<persName><surname>Winston</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Ting</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</editor>
		<meeting>international joint conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="1977">2012. 1977. 1997</date>
		</imprint>
	</monogr>
	<note>Stacked generalization: when does it work?</note>
</biblStruct>

<biblStruct xml:id="b742">
	<analytic>
		<title level="a" type="main">Architectural bias in recurrent neural networks: Fractal analysis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tiňo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1931" to="1957" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b743">
	<analytic>
		<title level="a" type="main">Learning a context-free task with a recurrent neural network: An analysis of stability</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tonkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wiles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth Biennial conference of the Australasian cognitive science society</title>
				<meeting>the fourth Biennial conference of the Australasian cognitive science society</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b744">
	<analytic>
		<title level="a" type="main">Knowledge-based artificial neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Towell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Shavlik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="119" to="165" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b745">
	<analytic>
		<title level="a" type="main">Feature-based methods for large scale dynamic programming</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="59" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b746">
	<analytic>
		<title level="a" type="main">Neural networks with dynamic synapses</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tsodyks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pawelzik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Markram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="821" to="835" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b747">
	<analytic>
		<title level="a" type="main">Population dynamics and theta rhythm phase precession of hippocampal place cell firing: a spiking neuron model</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Tsodyks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Skaggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Mcnaughton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hippocampus</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="271" to="280" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b748">
	<analytic>
		<title level="a" type="main">Convolutional networks can learn to generate affinity graphs for image segmentation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Turaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Helmstaedter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Briggman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="511" to="538" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b749">
	<analytic>
		<title level="a" type="main">On computable numbers, with an application to the Entscheidungsproblem</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Turing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the London Mathematical Society</title>
				<meeting>the London Mathematical Society</meeting>
		<imprint>
			<date type="published" when="1936">1936</date>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="230" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b750">
	<analytic>
		<title level="a" type="main">Cartesian genetic programming encoded artificial neural networks: A comparison using three benchmarks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on genetic and evolutionary computation</title>
				<meeting>the conference on genetic and evolutionary computation</meeting>
		<imprint>
			<publisher>GECCO</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1005" to="1012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b751">
	<analytic>
		<title level="a" type="main">Optimal linear combination of neural networks for improving classification performance</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ueda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="207" to="215" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b752">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Urlbe</surname></persName>
		</author>
		<title level="m">Structure-adaptable digital neural networks</title>
				<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>Universidad del Valle</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b753">
	<analytic>
		<title level="a" type="main">Many-layered learning</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Utgoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Stracuzzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2497" to="2529" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b754">
	<analytic>
		<title level="a" type="main">A machine learning method for extracting symbolic knowledge from recurrent neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vahed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Omlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="71" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b755">
	<analytic>
		<title level="a" type="main">Original approach for the localisation of objects in images</title>
		<author>
			<persName><forename type="first">R</forename><surname>Vaillant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Monrocq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GECCO 2013: proceedings of the genetic and evolutionary computation conference</title>
				<editor>
			<persName><forename type="first">T</forename><surname>Berg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Whiteson</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1994">1994. 2013</date>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="page" from="759" to="766" />
		</imprint>
	</monogr>
	<note>IEE Proceedings Vision, Image, and Signal Processing</note>
</biblStruct>

<biblStruct xml:id="b756">
	<analytic>
		<title level="a" type="main">Reinforcement learning in continuous state and action spaces</title>
		<author>
			<persName><forename type="first">H</forename><surname>Van Hasselt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Reinforcement learning</title>
				<editor>
			<persName><forename type="first">M</forename><surname>Wiering</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Van Otterlo</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="207" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b757">
	<analytic>
		<title level="a" type="main">Principles of risk minimization for learning theory</title>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Lippman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="831" to="838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b758">
	<monogr>
		<title level="m" type="main">The nature of statistical learning theory</title>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b759">
	<analytic>
		<title level="a" type="main">Learning fine motion by using the hierarchical extended Kohonen map</title>
		<author>
			<persName><forename type="first">C</forename><surname>Versino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. intl. conf. on artificial neural networks</title>
				<meeting>intl. conf. on artificial neural networks</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="221" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b760">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Veta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Viergever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pluim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Stathonikos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Van Diest</surname></persName>
		</author>
		<title level="m">MICCAI 2013 grand challenge on mitosis detection</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b761">
	<analytic>
		<title level="a" type="main">A training algorithm for classification of highdimensional data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vieira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Barradas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="461" to="472" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b762">
	<monogr>
		<title level="m" type="main">Adaptive, learning, and pattern recognition systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Viglione</surname></persName>
		</author>
		<editor>J. M. Mendel, &amp; K. S. Fu</editor>
		<imprint>
			<date type="published" when="1970">1970</date>
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
	<note>Applications of pattern recognition technology</note>
</biblStruct>

<biblStruct xml:id="b763">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hugo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
				<meeting>the 25th international conference on Machine learning<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b764">
	<analytic>
		<title level="a" type="main">On the computational complexity of stochastic controller optimization in POMDPs</title>
		<author>
			<persName><forename type="first">N</forename><surname>Vlassis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computation Theory</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b765">
	<analytic>
		<title level="a" type="main">Self-organization of orientation sensitive cells in the striate cortex</title>
		<author>
			<persName><forename type="first">T</forename><surname>Vogl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mangis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Alkon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="85" to="100" />
			<date type="published" when="1973">1988. 1973</date>
		</imprint>
	</monogr>
	<note>Kybernetik</note>
</biblStruct>

<biblStruct xml:id="b766">
	<analytic>
		<title level="a" type="main">PROW: a step toward automatic program writing</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Waldinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C T</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st international joint conference on artificial intelligence</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Walker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Norton</surname></persName>
		</editor>
		<meeting>the 1st international joint conference on artificial intelligence</meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1969">1969</date>
			<biblScope unit="page" from="241" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b767">
	<analytic>
		<title level="a" type="main">An information theoretic measure for classification</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Boulton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Computer Journal</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="185" to="194" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b768">
	<analytic>
		<title level="a" type="main">Time series prediction by using a connectionist network with internal delay lines</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Time series prediction: forecasting the future and understanding the past</title>
				<editor>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Weigend</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Gershenfeld</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="265" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b769">
	<monogr>
		<title/>
		<author>
			<persName><surname>Addison-Wesley</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b770">
	<analytic>
		<title level="a" type="main">Fast dropout training</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th international conference on machine learning</title>
				<meeting>the 30th international conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="118" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b771">
	<analytic>
		<title level="a" type="main">Optimal stopping and effective machine complexity in learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Judd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS&apos;6)</title>
				<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="303" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b772">
	<monogr>
		<title level="m" type="main">Pattern recognition: human and mechanical</title>
		<author>
			<persName><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b773">
	<analytic>
		<title level="a" type="main">Kolmogorov complexity and computational complexity</title>
		<author>
			<persName><forename type="first">O</forename><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EATCS monographs on theoretical computer science</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b774">
	<analytic>
		<title level="a" type="main">Q-learning</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J C H</forename><surname>Watkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning from delayed rewards</title>
				<editor>
			<persName><surname>King's College</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">J C H</forename><surname>Watkins</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</editor>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989">1989. 1992</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="279" to="292" />
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
	<note>Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b775">
	<analytic>
		<title level="a" type="main">Induction of finite-state automata using second-order recurrent networks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Watrous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Lippman</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="309" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b776">
	<analytic>
		<title level="a" type="main">Unsupervised learning of individuals and categories from images</title>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Waydo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1165" to="1178" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b777">
	<analytic>
		<title level="a" type="main">Results of the time series prediction competition at the Santa Fe Institute</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Weigend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Gershenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE international conference on</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1993">1993. 1993</date>
			<biblScope unit="page" from="1786" to="1793" />
		</imprint>
	</monogr>
	<note>Neural networks</note>
</biblStruct>

<biblStruct xml:id="b778">
	<analytic>
		<title level="a" type="main">Generalization by weight-elimination with application to forecasting</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Weigend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Huberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Lippmann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moody</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="875" to="882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b779">
	<analytic>
		<title level="a" type="main">Cresceptron: a self-organizing neural network which grows adaptively</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">;</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th national conference on artificial intelligence</title>
				<meeting>the 12th national conference on artificial intelligence<address><addrLine>Weng, J</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1992">1994. 1992</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="576" to="581" />
		</imprint>
	</monogr>
	<note>International joint conference on neural networks</note>
</biblStruct>

<biblStruct xml:id="b780">
	<analytic>
		<title level="a" type="main">Learning recognition and segmentation using the cresceptron</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="143" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b781">
	<monogr>
		<title level="m" type="main">Beyond regression: new tools for prediction and analysis in the behavioral sciences</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974">1974</date>
			<pubPlace>Harvard University</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b782">
	<analytic>
		<title level="a" type="main">Applications of advances in nonlinear sensitivity analysis</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th IFIP conference</title>
				<meeting>the 10th IFIP conference<address><addrLine>NYC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="762" to="770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b783">
	<analytic>
		<title level="a" type="main">Building and understanding adaptive systems: A statistical/numerical approach to factory automation and brain research</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="page">17</biblScope>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b784">
	<analytic>
		<title level="a" type="main">Generalization of backpropagation with application to a recurrent gas market model</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b785">
	<analytic>
		<title level="a" type="main">Backpropagation and neurocontrol: A review and prospectus</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/INNS International joint conference on neural networks</title>
				<imprint>
			<date type="published" when="1989">1989a</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="209" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b786">
	<analytic>
		<title level="a" type="main">Neural networks for control and system identification</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE/CDC Tampa</title>
				<meeting>IEEE/CDC Tampa</meeting>
		<imprint>
			<date type="published" when="1989">1989b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b787">
	<analytic>
		<title level="a" type="main">Neural networks, system identification, and control in the chemical industries</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of intelligent control: neural, fuzzy, and adaptive approaches</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>White</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Sofge</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="283" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b788">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Thomson</forename><surname>Learning</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b789">
	<analytic>
		<title level="a" type="main">Backwards differentiation in AD and neural nets: Past links and new opportunities</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic differentiation: applications, theory, and implementations</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="15" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b790">
	<analytic>
		<title level="a" type="main">Adaptive back-propagation in on-line learning of multilayer networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H L</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Saad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Mozer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Hasselmo</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="323" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b791">
	<analytic>
		<title level="a" type="main">Learning in artificial neural networks: A statistical perspective</title>
		<author>
			<persName><forename type="first">H</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="425" to="464" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b792">
	<monogr>
		<title level="m" type="main">Reinforcement learning for the adaptive control of perception and action</title>
		<author>
			<persName><forename type="first">S</forename><surname>Whitehead</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
		<respStmt>
			<orgName>University of Rochester</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b793">
	<monogr>
		<title level="m" type="main">Evolutionary computation for reinforcement learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Whiteson</surname></persName>
		</author>
		<editor>M. Wiering, &amp; M. van Otterlo</editor>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="325" to="355" />
			<pubPlace>Berlin, Germany</pubPlace>
		</imprint>
	</monogr>
	<note>Reinforcement learning</note>
</biblStruct>

<biblStruct xml:id="b794">
	<analytic>
		<title level="a" type="main">Evolving keepaway soccer players through task decomposition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Whiteson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="5" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b795">
	<analytic>
		<title level="a" type="main">Evolutionary function approximation for reinforcement learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Whiteson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="877" to="917" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b796">
	<analytic>
		<title level="a" type="main">Associative storage and retrieval of digital information in networks of adaptive neurons. Biological Prototypes and Synthetic Systems, 1, 160</title>
		<author>
			<persName><forename type="first">B</forename><surname>Widrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Widrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Lehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks: Applications in industry, business and science</title>
				<imprint>
			<date type="published" when="1962">1962. 1994</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="93" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b797">
	<analytic>
		<title level="a" type="main">Evolving neural network controllers for unstable systems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Wieland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International joint conference on neural networks</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="667" to="673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b798">
	<analytic>
		<title level="a" type="main">Solving POMDPs with Levin search and EIRA</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wiering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine learning: proceedings of the thirteenth international conference</title>
				<editor>
			<persName><forename type="first">L</forename><surname>Saitta</surname></persName>
		</editor>
		<meeting><address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="534" to="542" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b799">
	<analytic>
		<title level="a" type="main">HQ-learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wiering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adaptive Behavior</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="219" to="246" />
			<date type="published" when="1998">1998a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b800">
	<analytic>
		<title level="a" type="main">Fast online Q(λ)</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Wiering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="1998">1998b</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="105" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b801">
	<analytic>
		<title level="a" type="main">Recurrent policy gradients</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wiering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Otterlo</surname></persName>
		</author>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Foerster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Logic Journal of IGPL</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="620" to="634" />
			<date type="published" when="2010">2012. 2010</date>
		</imprint>
	</monogr>
	<note>Reinforcement learning</note>
</biblStruct>

<biblStruct xml:id="b802">
	<analytic>
		<title level="a" type="main">Natural evolution strategies</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Congress of evolutionary computation</title>
				<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b803">
	<analytic>
		<title level="a" type="main">Receptive fields of single neurones in the cat&apos;s striate cortex</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Wiesel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Hubel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Physiology</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page" from="574" to="591" />
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b804">
	<analytic>
		<title level="a" type="main">Learning to count without a counter: A case study of dynamics and activation landscapes in recurrent networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wiles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the seventeenth annual conference of the cognitive science society</title>
				<editor>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Cambridge</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Wilkinson</surname></persName>
		</editor>
		<meeting>the seventeenth annual conference of the cognitive science society<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press, Inc</publisher>
			<date type="published" when="1965">1995. 1965</date>
			<biblScope unit="page" from="482" to="487" />
		</imprint>
	</monogr>
	<note>The algebraic eigenvalue problem</note>
</biblStruct>

<biblStruct xml:id="b805">
	<monogr>
		<title level="m" type="main">Reinforcement-learning in connectionist networks: A mathematical analysis</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<idno>8605</idno>
		<imprint>
			<date type="published" when="1986">1986</date>
			<pubPlace>San Diego</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Institute for Cognitive Science, University of California</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b806">
	<monogr>
		<title level="m" type="main">Toward a theory of reinforcement-learning connectionist systems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<idno>NU-CCS-88-3</idno>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>College of Comp. Sci., Northeastern University</publisher>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b807">
	<monogr>
		<title level="m" type="main">Complexity of exact gradient computation algorithms for recurrent neural networks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<idno>NU-CCS-89-27</idno>
		<imprint>
			<date type="published" when="1989">1989</date>
			<pubPlace>Boston</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Northeastern University, College of Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b808">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="1992">1992a</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="229" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b809">
	<analytic>
		<title level="a" type="main">Training recurrent networks using the extended Kalman filter</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International joint conference on neural networks</title>
				<imprint>
			<date type="published" when="1992">1992b</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="241" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b810">
	<analytic>
		<title level="a" type="main">An efficient gradient-based algorithm for on-line training of recurrent network trajectories</title>
		<author>
			<persName><surname>Ieee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="491" to="501" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b811">
	<analytic>
		<title level="a" type="main">A learning algorithm for continually running fully recurrent networks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zipser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zipser</surname></persName>
		</author>
		<idno>ICS report 8805</idno>
	</analytic>
	<monogr>
		<title level="j">Connection Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="87" to="111" />
			<date type="published" when="1988">1988. 1989a</date>
		</imprint>
		<respStmt>
			<orgName>Univ. of California</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>Experimental analysis of the real-time recurrent learning algorithm</note>
</biblStruct>

<biblStruct xml:id="b812">
	<analytic>
		<title level="a" type="main">A learning algorithm for continually running fully recurrent networks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zipser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="270" to="280" />
			<date type="published" when="1989">1989b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b813">
	<analytic>
		<title level="a" type="main">How patterned neural connections can be set up by self-organization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Willshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Malsburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proceedings of the Royal Society of London. Series B</title>
		<imprint>
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="page" from="431" to="445" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b814">
	<analytic>
		<title level="a" type="main">Loading deep networks is hard: The pyramidal case</title>
		<author>
			<persName><forename type="first">D</forename><surname>Windisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="487" to="502" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b815">
	<analytic>
		<title level="a" type="main">Slow feature analysis: Unsupervised learning of invariances</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wiskott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="715" to="770" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b816">
	<analytic>
		<title level="a" type="main">A GMDH neural network-based approach to robust fault diagnosis: Application to the DAMADICS benchmark problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Witczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Korbicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mrugalski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Patton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Control Engineering Practice</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="671" to="683" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b817">
	<analytic>
		<title level="a" type="main">On-line driver distraction detection using long short-term memory</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wöllmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blaschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schindl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Färber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems (TITS)</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="574" to="582" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b818">
	<analytic>
		<title level="a" type="main">Keyword spotting exploiting long short-term memory</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wöllmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rigoll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="252" to="265" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b819">
	<analytic>
		<title level="a" type="main">Stacked generalization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Wolpert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="241" to="259" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b820">
	<analytic>
		<title level="a" type="main">Bayesian backpropagation over i-o functions rather than weights</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Wolpert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<editor>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Cowan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Tesauro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Alspector</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="200" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b821">
	<analytic>
		<title level="a" type="main">Learning to play go using recursive neural networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1392" to="1400" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b822">
	<analytic>
		<title level="a" type="main">Leveraging hierarchical parametric networks for skeletal joints based action segmentation and recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. conference on computer vision and pattern recognition</title>
				<meeting>conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b823">
	<analytic>
		<title level="a" type="main">The limits of feedforward vision: Recurrent processing promotes robust object recognition when objects are degraded</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wyatte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>O'reilly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2248" to="2261" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b824">
	<analytic>
		<title level="a" type="main">Evolving spiking neural networks for audiovisual information processing</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Wysoski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Benuskova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kasabov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="819" to="835" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b825">
	<analytic>
		<title level="a" type="main">Sequential behavior and learning in evolved dynamical neural networks</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Yamauchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Beer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adaptive Behavior</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="219" to="246" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b826">
	<analytic>
		<title level="a" type="main">Hierarchical modular optimization of convolutional networks achieves representations similar to macaque IT and human ventral stream</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yamins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cadieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Dicarlo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b827">
	<analytic>
		<title level="a" type="main">Detecting human actions in surveillance videos</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC video retrieval evaluation workshop</title>
				<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b828">
	<analytic>
		<title level="a" type="main">A review of evolutionary artificial neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="203" to="222" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b829">
	<analytic>
		<title level="a" type="main">A developmental approach to structural selforganization in reservoir computing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Autonomous Mental Development</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="273" to="289" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b830">
	<analytic>
		<title level="a" type="main">ICDAR 2013 Chinese handwriting recognition competition</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q.-F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th international conference on document analysis and recognition</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1464" to="1470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b831">
	<analytic>
		<title level="a" type="main">Hierarchical spatiotemporal feature extraction using recurrent online clustering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mishtal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Arel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="115" to="123" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b832">
	<analytic>
		<title level="a" type="main">Dynamic learning rate optimization of the backpropagation algorithm</title>
		<author>
			<persName><forename type="first">X.-H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="669" to="677" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b833">
	<analytic>
		<title level="a" type="main">Neural network language models for off-line handwriting recognition</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zamora-Martínez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Frinken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>España-Boquera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Castro-Bleda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bunke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1642" to="1652" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b834">
	<monogr>
		<title level="m" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1311.2901[cs.CV]</idno>
		<imprint>
			<date type="published" when="2012">2012. 2013</date>
		</imprint>
		<respStmt>
			<orgName>NYU</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>ADADELTA: an adaptive learning rate method</note>
</biblStruct>

<biblStruct xml:id="b835">
	<monogr>
		<title level="m" type="main">A minimum description length framework for unsupervised learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b836">
	<analytic>
		<title level="a" type="main">Developing population codes by minimizing description length</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<editor>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Cowan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Tesauro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Alspector</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b837">
	<analytic>
		<title level="a" type="main">Discrete recurrent neural networks for grammatical inference</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b838">
	<analytic>
		<title level="a" type="main">Forecasting with recurrent neural networks: 12 tricks</title>
		<author>
			<persName><forename type="first">H.-G</forename><surname>Zimmermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tietz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grothmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks: tricks of the trade</title>
		<title level="s">Lecture notes in computer science</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Montavon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Orr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp; K.-R</forename><surname>Müller</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">7700</biblScope>
			<biblScope unit="page" from="687" to="707" />
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b839">
	<analytic>
		<title level="a" type="main">A spiking network model of short-term active memory</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zipser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kehoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Littlewort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fuster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3406" to="3420" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
